Set CUDA current device to: 1 (should be 1)
/workspace/compute-aware-arch-search/distill_videet.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
After Trainer init: Student model on cuda:1, expected cuda:1
Final check - Student model device: cuda:1
Final check - Trainer args.device: cuda:0 (read-only property)
Final check - CUDA current device: 1
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  0%|                                                                                              | 0/1000 [00:00<?, ?it/s]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None

[Step 1] ========== MEMORY DEBUG ==========
[Step 1] Model device: cuda:1
[Step 1] Input device: cuda:1
[Step 1] Teacher model device: cuda:0
[Step 1] GPU 0 memory: 3.44 GB (reserved: 3.45 GB)
[Step 1] GPU 1 memory: 8.31 GB (reserved: 8.43 GB)
  warnings.warn(
[Step 1] Student logits device: cuda:1, shape: torch.Size([2, 463, 151936]), dtype: torch.float32
[Step 1] Student model device: cuda:1
[Step 1] GPU 0 memory before teacher forward: 3.44 GB
[Step 1] GPU 0 memory after moving inputs: 3.44 GB
[Step 1] GPU 0 memory after teacher forward: 3.73 GB
[Step 1] Teacher logits shape: torch.Size([2, 463, 151936]), dtype: torch.float16
[Step 1] Teacher logits device before move: cuda:0
[Step 1] Target device (student_logits.device): cuda:1
[Step 1] GPU 0 memory after moving logits to GPU 1: 3.73 GB
[Step 1] Teacher logits device after move: cuda:1, shape: torch.Size([2, 463, 151936])
[Step 1] GPU 0 memory after del: 3.45 GB
[Step 1] GPU 0 memory after cache clear: 3.45 GB (reserved: 3.47 GB)
[Step 1] Before log_softmax - GPU 0: 3.45 GB, GPU 1: 10.87 GB
[Step 1] student_logits device: cuda:1, teacher_logits device: cuda:1

[Step 11] ========== MEMORY DEBUG ==========
[Step 11] Model device: cuda:1
[Step 11] Input device: cuda:1
[Step 11] Teacher model device: cuda:0
[Step 11] GPU 0 memory: 3.45 GB (reserved: 3.47 GB)
[Step 11] GPU 1 memory: 16.65 GB (reserved: 29.03 GB)
[Step 11] Student logits device: cuda:1, shape: torch.Size([2, 382, 151936]), dtype: torch.float32
[Step 11] Student model device: cuda:1
[Step 11] GPU 0 memory before teacher forward: 3.45 GB
[Step 11] GPU 0 memory after moving inputs: 3.45 GB
[Step 11] GPU 0 memory after teacher forward: 3.68 GB
[Step 11] Teacher logits shape: torch.Size([2, 382, 151936]), dtype: torch.float16
[Step 11] Teacher logits device before move: cuda:0
[Step 11] Target device (student_logits.device): cuda:1
[Step 11] GPU 0 memory after moving logits to GPU 1: 3.68 GB
[Step 11] Teacher logits device after move: cuda:1, shape: torch.Size([2, 382, 151936])
[Step 11] GPU 0 memory after del: 3.45 GB
[Step 11] GPU 0 memory after cache clear: 3.45 GB (reserved: 3.47 GB)
[Step 11] Before log_softmax - GPU 0: 3.45 GB, GPU 1: 18.85 GB
[Step 11] student_logits device: cuda:1, teacher_logits device: cuda:1
  0%|                                                                                    | 1/1000 [00:23<6:35:31, 23.76s/it]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(

[Step 21] ========== MEMORY DEBUG ==========
[Step 21] Model device: cuda:1
[Step 21] Input device: cuda:1
[Step 21] Teacher model device: cuda:0
[Step 21] GPU 0 memory: 3.45 GB (reserved: 3.47 GB)
[Step 21] GPU 1 memory: 33.27 GB (reserved: 48.66 GB)
[Step 21] Student logits device: cuda:1, shape: torch.Size([2, 965, 151936]), dtype: torch.float32
[Step 21] Student model device: cuda:1
[Step 21] GPU 0 memory before teacher forward: 3.45 GB
[Step 21] GPU 0 memory after moving inputs: 3.45 GB
[Step 21] GPU 0 memory after teacher forward: 4.04 GB
[Step 21] Teacher logits shape: torch.Size([2, 965, 151936]), dtype: torch.float16
[Step 21] Teacher logits device before move: cuda:0
[Step 21] Target device (student_logits.device): cuda:1
[Step 21] GPU 0 memory after moving logits to GPU 1: 4.04 GB
[Step 21] Teacher logits device after move: cuda:1, shape: torch.Size([2, 965, 151936])
[Step 21] GPU 0 memory after del: 3.45 GB
[Step 21] GPU 0 memory after cache clear: 3.45 GB (reserved: 3.47 GB)
[Step 21] Before log_softmax - GPU 0: 3.45 GB, GPU 1: 37.91 GB
[Step 21] student_logits device: cuda:1, teacher_logits device: cuda:1
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(

[Step 31] ========== MEMORY DEBUG ==========
[Step 31] Model device: cuda:1
[Step 31] Input device: cuda:1
[Step 31] Teacher model device: cuda:0
[Step 31] GPU 0 memory: 3.45 GB (reserved: 3.47 GB)
[Step 31] GPU 1 memory: 33.27 GB (reserved: 48.80 GB)
[Step 31] Student logits device: cuda:1, shape: torch.Size([2, 693, 151936]), dtype: torch.float32
[Step 31] Student model device: cuda:1
[Step 31] GPU 0 memory before teacher forward: 3.45 GB
[Step 31] GPU 0 memory after moving inputs: 3.45 GB
[Step 31] GPU 0 memory after teacher forward: 3.87 GB
[Step 31] Teacher logits shape: torch.Size([2, 693, 151936]), dtype: torch.float16
[Step 31] Teacher logits device before move: cuda:0
[Step 31] Target device (student_logits.device): cuda:1
[Step 31] GPU 0 memory after moving logits to GPU 1: 3.87 GB
[Step 31] Teacher logits device after move: cuda:1, shape: torch.Size([2, 693, 151936])
[Step 31] GPU 0 memory after del: 3.45 GB
[Step 31] GPU 0 memory after cache clear: 3.45 GB (reserved: 3.47 GB)
[Step 31] Before log_softmax - GPU 0: 3.45 GB, GPU 1: 36.77 GB
[Step 31] student_logits device: cuda:1, teacher_logits device: cuda:1
  0%|▏                                                                                  | 2/1000 [01:10<10:15:41, 37.02s/it]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(

[Step 41] ========== MEMORY DEBUG ==========
[Step 41] Model device: cuda:1
[Step 41] Input device: cuda:1
[Step 41] Teacher model device: cuda:0
[Step 41] GPU 0 memory: 3.45 GB (reserved: 3.47 GB)
[Step 41] GPU 1 memory: 33.27 GB (reserved: 47.77 GB)
[Step 41] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 41] Student model device: cuda:1
[Step 41] GPU 0 memory before teacher forward: 3.45 GB
[Step 41] GPU 0 memory after moving inputs: 3.45 GB
[Step 41] GPU 0 memory after teacher forward: 4.07 GB
[Step 41] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 41] Teacher logits device before move: cuda:0
[Step 41] Target device (student_logits.device): cuda:1
[Step 41] GPU 0 memory after moving logits to GPU 1: 4.07 GB
[Step 41] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 41] GPU 0 memory after del: 3.45 GB
[Step 41] GPU 0 memory after cache clear: 3.45 GB (reserved: 3.47 GB)
[Step 41] Before log_softmax - GPU 0: 3.45 GB, GPU 1: 38.15 GB
[Step 41] student_logits device: cuda:1, teacher_logits device: cuda:1
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|▎                                                                                   | 3/1000 [01:29<7:59:31, 28.86s/it]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(

[Step 51] ========== MEMORY DEBUG ==========
[Step 51] Model device: cuda:1
[Step 51] Input device: cuda:1
[Step 51] Teacher model device: cuda:0
[Step 51] GPU 0 memory: 3.45 GB (reserved: 3.47 GB)
[Step 51] GPU 1 memory: 33.29 GB (reserved: 47.46 GB)
[Step 51] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 51] Student model device: cuda:1
[Step 51] GPU 0 memory before teacher forward: 3.45 GB
[Step 51] GPU 0 memory after moving inputs: 3.45 GB
[Step 51] GPU 0 memory after teacher forward: 4.07 GB
[Step 51] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 51] Teacher logits device before move: cuda:0
[Step 51] Target device (student_logits.device): cuda:1
[Step 51] GPU 0 memory after moving logits to GPU 1: 4.07 GB
[Step 51] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 51] GPU 0 memory after del: 3.45 GB
[Step 51] GPU 0 memory after cache clear: 3.45 GB (reserved: 3.47 GB)
[Step 51] Before log_softmax - GPU 0: 3.45 GB, GPU 1: 38.17 GB
[Step 51] student_logits device: cuda:1, teacher_logits device: cuda:1
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Traceback (most recent call last):
  File "/workspace/compute-aware-arch-search/distill_videet.py", line 357, in <module>
    trainer.train()
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2685, in _inner_training_loop
    raise ValueError(
ValueError: Calculated loss must be on the original device: cuda:0 but device in use is cuda:1
