Set CUDA current device to: 1 (should be 1)
/workspace/compute-aware-arch-search/distill_kl_trick.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  0%|                                                                                                                               | 0/10000 [00:00<?, ?it/s]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
                                                                                                                                                              
{'loss': 52.5069, 'grad_norm': 6708.36572265625, 'learning_rate': 0.0, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 57.1396, 'grad_norm': 8970.638671875, 'learning_rate': 2.5000000000000004e-07, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 50.3206, 'grad_norm': 3562.5009765625, 'learning_rate': 5.000000000000001e-07, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 52.732, 'grad_norm': 6848.32666015625, 'learning_rate': 7.5e-07, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 51.3371, 'grad_norm': 1955.9656982421875, 'learning_rate': 1.0000000000000002e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 51.9335, 'grad_norm': 3294.816162109375, 'learning_rate': 1.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 52.7217, 'grad_norm': 5467.79931640625, 'learning_rate': 1.5e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 50.3611, 'grad_norm': 28119.671875, 'learning_rate': 1.7500000000000002e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 50.4724, 'grad_norm': 5737.16748046875, 'learning_rate': 2.0000000000000003e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 47.6876, 'grad_norm': 3894.24755859375, 'learning_rate': 2.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 48.2062, 'grad_norm': 2073.416748046875, 'learning_rate': 2.5e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 46.7322, 'grad_norm': 3700.860107421875, 'learning_rate': 2.7500000000000004e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 48.1038, 'grad_norm': 6782.89013671875, 'learning_rate': 3e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 43.1114, 'grad_norm': 2324.349365234375, 'learning_rate': 3.2500000000000002e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 42.6695, 'grad_norm': 3176.95166015625, 'learning_rate': 3.5000000000000004e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 42.4579, 'grad_norm': 2640.627197265625, 'learning_rate': 3.75e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 41.5417, 'grad_norm': 5167.337890625, 'learning_rate': 4.000000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 38.7741, 'grad_norm': 778.6045532226562, 'learning_rate': 4.250000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 37.4123, 'grad_norm': 821.9388427734375, 'learning_rate': 4.5e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 37.718, 'grad_norm': 2814.783935546875, 'learning_rate': 4.75e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 35.3783, 'grad_norm': 1193.6370849609375, 'learning_rate': 5e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 36.0733, 'grad_norm': 1314.397705078125, 'learning_rate': 5.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 33.3108, 'grad_norm': 2622.41064453125, 'learning_rate': 5.500000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 34.37, 'grad_norm': 1246.5177001953125, 'learning_rate': 5.750000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 33.8889, 'grad_norm': 1093.42333984375, 'learning_rate': 6e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 32.2028, 'grad_norm': 1198.703369140625, 'learning_rate': 6.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 31.7666, 'grad_norm': 713.9248657226562, 'learning_rate': 6.5000000000000004e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 31.7938, 'grad_norm': 5181.92529296875, 'learning_rate': 6.750000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 30.7412, 'grad_norm': 1598.7042236328125, 'learning_rate': 7.000000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 29.6675, 'grad_norm': 573.1666259765625, 'learning_rate': 7.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 28.2974, 'grad_norm': 1110.5906982421875, 'learning_rate': 7.5e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 26.6164, 'grad_norm': 837.2857666015625, 'learning_rate': 7.75e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 22.9002, 'grad_norm': 17979.498046875, 'learning_rate': 8.000000000000001e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 18.2006, 'grad_norm': 1424.7310791015625, 'learning_rate': 8.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 16.1868, 'grad_norm': 2548.539306640625, 'learning_rate': 8.500000000000002e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 16.0258, 'grad_norm': 694.9976806640625, 'learning_rate': 8.75e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 11.4431, 'grad_norm': 967.3220825195312, 'learning_rate': 9e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 10.7724, 'grad_norm': 3218.59814453125, 'learning_rate': 9.25e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 8.9324, 'grad_norm': 393.79766845703125, 'learning_rate': 9.5e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 8.6462, 'grad_norm': 2610.6259765625, 'learning_rate': 9.750000000000002e-06, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 9.537, 'grad_norm': 2018.4212646484375, 'learning_rate': 1e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 6.0333, 'grad_norm': 920.7701416015625, 'learning_rate': 1.025e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 6.2341, 'grad_norm': 776.4581909179688, 'learning_rate': 1.05e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 6.5723, 'grad_norm': 2603.47021484375, 'learning_rate': 1.075e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 5.4019, 'grad_norm': 643.7971801757812, 'learning_rate': 1.1000000000000001e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 6.0071, 'grad_norm': 452.9717712402344, 'learning_rate': 1.125e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 5.5558, 'grad_norm': 2884.695556640625, 'learning_rate': 1.1500000000000002e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 4.1723, 'grad_norm': 749.0643920898438, 'learning_rate': 1.175e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 5.4733, 'grad_norm': 565.979248046875, 'learning_rate': 1.2e-05, 'skipped_batches': 0, 'epoch': 0.0}
{'loss': 4.2224, 'grad_norm': 936.8056030273438, 'learning_rate': 1.225e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.4573, 'grad_norm': 1099.0693359375, 'learning_rate': 1.25e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 4.0521, 'grad_norm': 2319.37548828125, 'learning_rate': 1.2750000000000002e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.2538, 'grad_norm': 421.86895751953125, 'learning_rate': 1.3000000000000001e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 4.0515, 'grad_norm': 614.9774169921875, 'learning_rate': 1.3250000000000002e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 4.0345, 'grad_norm': 356.10467529296875, 'learning_rate': 1.3500000000000001e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.3665, 'grad_norm': 332.7799377441406, 'learning_rate': 1.3750000000000002e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.872, 'grad_norm': 2128.462158203125, 'learning_rate': 1.4000000000000001e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.6713, 'grad_norm': 232.9198760986328, 'learning_rate': 1.4249999999999999e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.6562, 'grad_norm': 342.7095031738281, 'learning_rate': 1.45e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.4274, 'grad_norm': 9353.171875, 'learning_rate': 1.475e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.5994, 'grad_norm': 343.92010498046875, 'learning_rate': 1.5e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.3146, 'grad_norm': 201.08993530273438, 'learning_rate': 1.525e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.3793, 'grad_norm': 199.1126251220703, 'learning_rate': 1.55e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 1.9017, 'grad_norm': 135.7906036376953, 'learning_rate': 1.575e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 1.769, 'grad_norm': 272.58953857421875, 'learning_rate': 1.6000000000000003e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.1427, 'grad_norm': 281.81707763671875, 'learning_rate': 1.6250000000000002e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.5038, 'grad_norm': 133.79971313476562, 'learning_rate': 1.65e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.7637, 'grad_norm': 419.36614990234375, 'learning_rate': 1.675e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 1.8738, 'grad_norm': 177.22401428222656, 'learning_rate': 1.7000000000000003e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.1294, 'grad_norm': 106.5698471069336, 'learning_rate': 1.725e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 1.941, 'grad_norm': 689.944091796875, 'learning_rate': 1.75e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 3.0398, 'grad_norm': 363.2701110839844, 'learning_rate': 1.775e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 2.0838, 'grad_norm': 206.70350646972656, 'learning_rate': 1.8e-05, 'skipped_batches': 0, 'epoch': 0.01}
{'loss': 1.8241, 'grad_norm': 108.48158264160156, 'learning_rate': 1.825e-05, 'skipped_batches': 0, 'epoch': 0.01}
