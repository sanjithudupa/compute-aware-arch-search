Set CUDA current device to: 1 (should be 1)
/workspace/compute-aware-arch-search/distill_videet.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
After Trainer init: Student model on cuda:1, expected cuda:1
Final check - Student model device: cuda:1
Final check - Trainer args.device: cuda:0 (read-only property)
Final check - CUDA current device: 1
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  0%|                                                                            | 0/10000 [00:00<?, ?it/s]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None

[Step 1] ========== MEMORY DEBUG ==========
[Step 1] Model device: cuda:1
[Step 1] Input device: cuda:1
[Step 1] Teacher model device: cuda:0
[Step 1] GPU 0 memory: 16.38 GB (reserved: 16.54 GB)
[Step 1] GPU 1 memory: 8.44 GB (reserved: 8.55 GB)
  warnings.warn(
[Step 1] Student logits device: cuda:1, shape: torch.Size([2, 463, 151936]), dtype: torch.float32
[Step 1] Student model device: cuda:1
[Step 1] GPU 0 memory before teacher forward: 16.38 GB
[Step 1] GPU 0 memory after moving inputs: 16.38 GB
[Step 1] GPU 0 memory after teacher forward: 16.67 GB
[Step 1] Teacher logits shape: torch.Size([2, 463, 151936]), dtype: torch.float16
[Step 1] Teacher logits device before move: cuda:0
[Step 1] Target device (student_logits.device): cuda:1
[Step 1] GPU 0 memory after moving logits to GPU 1: 16.67 GB
[Step 1] Teacher logits device after move: cuda:1, shape: torch.Size([2, 463, 151936])
[Step 1] GPU 0 memory after del: 16.39 GB
[Step 1] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 10.71 GB
[Step 1] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1] Sequence length: 463, Batch size: 2
[Step 1] After KL computation - GPU 1: 11.83 GB
[Step 1] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(

[Step 11] ========== MEMORY DEBUG ==========
[Step 11] Model device: cuda:1
[Step 11] Input device: cuda:1
[Step 11] Teacher model device: cuda:0
[Step 11] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 11] GPU 1 memory: 16.89 GB (reserved: 28.79 GB)
[Step 11] Student logits device: cuda:1, shape: torch.Size([2, 382, 151936]), dtype: torch.float32
[Step 11] Student model device: cuda:1
[Step 11] GPU 0 memory before teacher forward: 16.39 GB
[Step 11] GPU 0 memory after moving inputs: 16.39 GB
[Step 11] GPU 0 memory after teacher forward: 16.62 GB
[Step 11] Teacher logits shape: torch.Size([2, 382, 151936]), dtype: torch.float16
[Step 11] Teacher logits device before move: cuda:0
[Step 11] Target device (student_logits.device): cuda:1
[Step 11] GPU 0 memory after moving logits to GPU 1: 16.62 GB
[Step 11] Teacher logits device after move: cuda:1, shape: torch.Size([2, 382, 151936])
[Step 11] GPU 0 memory after del: 16.39 GB
[Step 11] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 11] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 18.87 GB
[Step 11] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 11] Sequence length: 382, Batch size: 2
[Step 11] After KL computation - GPU 1: 19.80 GB
[Step 11] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
  0%|                                                                 | 1/10000 [00:22<62:14:46, 22.41s/it]

[Step 21] ========== MEMORY DEBUG ==========
[Step 21] Model device: cuda:1
[Step 21] Input device: cuda:1
[Step 21] Teacher model device: cuda:0
[Step 21] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 21] GPU 1 memory: 33.76 GB (reserved: 47.64 GB)
[Step 21] Student logits device: cuda:1, shape: torch.Size([2, 965, 151936]), dtype: torch.float32
[Step 21] Student model device: cuda:1
[Step 21] GPU 0 memory before teacher forward: 16.39 GB
[Step 21] GPU 0 memory after moving inputs: 16.39 GB
[Step 21] GPU 0 memory after teacher forward: 16.98 GB
[Step 21] Teacher logits shape: torch.Size([2, 965, 151936]), dtype: torch.float16
[Step 21] Teacher logits device before move: cuda:0
[Step 21] Target device (student_logits.device): cuda:1
[Step 21] GPU 0 memory after moving logits to GPU 1: 16.98 GB
[Step 21] Teacher logits device after move: cuda:1, shape: torch.Size([2, 965, 151936])
[Step 21] GPU 0 memory after del: 16.39 GB
[Step 21] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 21] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.81 GB
[Step 21] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 21] Sequence length: 965, Batch size: 2
[Step 21] After KL computation - GPU 1: 40.15 GB
[Step 21] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 31] ========== MEMORY DEBUG ==========
[Step 31] Model device: cuda:1
[Step 31] Input device: cuda:1
[Step 31] Teacher model device: cuda:0
[Step 31] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 31] GPU 1 memory: 33.76 GB (reserved: 47.71 GB)
[Step 31] Student logits device: cuda:1, shape: torch.Size([2, 693, 151936]), dtype: torch.float32
[Step 31] Student model device: cuda:1
[Step 31] GPU 0 memory before teacher forward: 16.39 GB
[Step 31] GPU 0 memory after moving inputs: 16.39 GB
[Step 31] GPU 0 memory after teacher forward: 16.81 GB
[Step 31] Teacher logits shape: torch.Size([2, 693, 151936]), dtype: torch.float16
[Step 31] Teacher logits device before move: cuda:0
[Step 31] Target device (student_logits.device): cuda:1
[Step 31] GPU 0 memory after moving logits to GPU 1: 16.81 GB
[Step 31] Teacher logits device after move: cuda:1, shape: torch.Size([2, 693, 151936])
[Step 31] GPU 0 memory after del: 16.39 GB
[Step 31] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 31] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.84 GB
[Step 31] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 31] Sequence length: 693, Batch size: 2
[Step 31] After KL computation - GPU 1: 38.52 GB
[Step 31] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 41] ========== MEMORY DEBUG ==========
[Step 41] Model device: cuda:1
[Step 41] Input device: cuda:1
[Step 41] Teacher model device: cuda:0
[Step 41] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 41] GPU 1 memory: 33.76 GB (reserved: 47.19 GB)
[Step 41] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 41] Student model device: cuda:1
[Step 41] GPU 0 memory before teacher forward: 16.39 GB
[Step 41] GPU 0 memory after moving inputs: 16.39 GB
[Step 41] GPU 0 memory after teacher forward: 17.01 GB
[Step 41] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 41] Teacher logits device before move: cuda:0
[Step 41] Target device (student_logits.device): cuda:1
[Step 41] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 41] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 41] GPU 0 memory after del: 16.39 GB
[Step 41] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 41] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 41] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 41] Sequence length: 1024, Batch size: 2
[Step 41] After KL computation - GPU 1: 40.50 GB
[Step 41] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 51] ========== MEMORY DEBUG ==========
[Step 51] Model device: cuda:1
[Step 51] Input device: cuda:1
[Step 51] Teacher model device: cuda:0
[Step 51] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 51] GPU 1 memory: 33.78 GB (reserved: 46.70 GB)
[Step 51] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 51] Student model device: cuda:1
[Step 51] GPU 0 memory before teacher forward: 16.39 GB
[Step 51] GPU 0 memory after moving inputs: 16.39 GB
[Step 51] GPU 0 memory after teacher forward: 17.01 GB
[Step 51] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 51] Teacher logits device before move: cuda:0
[Step 51] Target device (student_logits.device): cuda:1
[Step 51] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 51] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 51] GPU 0 memory after del: 16.39 GB
[Step 51] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 51] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.03 GB
[Step 51] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 51] Sequence length: 1024, Batch size: 2
[Step 51] After KL computation - GPU 1: 40.52 GB
[Step 51] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 61] ========== MEMORY DEBUG ==========
[Step 61] Model device: cuda:1
[Step 61] Input device: cuda:1
[Step 61] Teacher model device: cuda:0
[Step 61] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 61] GPU 1 memory: 33.78 GB (reserved: 47.73 GB)
[Step 61] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 61] Student model device: cuda:1
[Step 61] GPU 0 memory before teacher forward: 16.39 GB
[Step 61] GPU 0 memory after moving inputs: 16.39 GB
[Step 61] GPU 0 memory after teacher forward: 17.01 GB
[Step 61] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 61] Teacher logits device before move: cuda:0
[Step 61] Target device (student_logits.device): cuda:1
[Step 61] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 61] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 61] GPU 0 memory after del: 16.39 GB
[Step 61] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 61] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.03 GB
[Step 61] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 61] Sequence length: 1024, Batch size: 2
[Step 61] After KL computation - GPU 1: 40.52 GB
[Step 61] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 71] ========== MEMORY DEBUG ==========
[Step 71] Model device: cuda:1
[Step 71] Input device: cuda:1
[Step 71] Teacher model device: cuda:0
[Step 71] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 71] GPU 1 memory: 33.76 GB (reserved: 46.51 GB)
[Step 71] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 71] Student model device: cuda:1
[Step 71] GPU 0 memory before teacher forward: 16.39 GB
[Step 71] GPU 0 memory after moving inputs: 16.39 GB
[Step 71] GPU 0 memory after teacher forward: 17.01 GB
[Step 71] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 71] Teacher logits device before move: cuda:0
[Step 71] Target device (student_logits.device): cuda:1
[Step 71] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 71] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 71] GPU 0 memory after del: 16.39 GB
[Step 71] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 71] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 71] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 71] Sequence length: 1024, Batch size: 2
[Step 71] After KL computation - GPU 1: 40.50 GB
[Step 71] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 81] ========== MEMORY DEBUG ==========
[Step 81] Model device: cuda:1
[Step 81] Input device: cuda:1
[Step 81] Teacher model device: cuda:0
[Step 81] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 81] GPU 1 memory: 25.33 GB (reserved: 43.80 GB)
[Step 81] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 81] Student model device: cuda:1
[Step 81] GPU 0 memory before teacher forward: 16.39 GB
[Step 81] GPU 0 memory after moving inputs: 16.39 GB
[Step 81] GPU 0 memory after teacher forward: 17.01 GB
[Step 81] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 81] Teacher logits device before move: cuda:0
[Step 81] Target device (student_logits.device): cuda:1
[Step 81] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 81] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 81] GPU 0 memory after del: 16.39 GB
[Step 81] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 81] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 81] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 81] Sequence length: 1024, Batch size: 2
[Step 81] After KL computation - GPU 1: 32.07 GB
[Step 81] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 91] ========== MEMORY DEBUG ==========
[Step 91] Model device: cuda:1
[Step 91] Input device: cuda:1
[Step 91] Teacher model device: cuda:0
[Step 91] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 91] GPU 1 memory: 33.76 GB (reserved: 43.54 GB)
[Step 91] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 91] Student model device: cuda:1
[Step 91] GPU 0 memory before teacher forward: 16.39 GB
[Step 91] GPU 0 memory after moving inputs: 16.39 GB
[Step 91] GPU 0 memory after teacher forward: 17.01 GB
[Step 91] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 91] Teacher logits device before move: cuda:0
[Step 91] Target device (student_logits.device): cuda:1
[Step 91] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 91] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 91] GPU 0 memory after del: 16.39 GB
[Step 91] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 91] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 91] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 91] Sequence length: 1024, Batch size: 2
[Step 91] After KL computation - GPU 1: 40.50 GB
[Step 91] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 101] ========== MEMORY DEBUG ==========
[Step 101] Model device: cuda:1
[Step 101] Input device: cuda:1
[Step 101] Teacher model device: cuda:0
[Step 101] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 101] GPU 1 memory: 33.76 GB (reserved: 47.50 GB)
[Step 101] Student logits device: cuda:1, shape: torch.Size([2, 271, 151936]), dtype: torch.float32
[Step 101] Student model device: cuda:1
[Step 101] GPU 0 memory before teacher forward: 16.39 GB
[Step 101] GPU 0 memory after moving inputs: 16.39 GB
[Step 101] GPU 0 memory after teacher forward: 16.56 GB
[Step 101] Teacher logits shape: torch.Size([2, 271, 151936]), dtype: torch.float16
[Step 101] Teacher logits device before move: cuda:0
[Step 101] Target device (student_logits.device): cuda:1
[Step 101] GPU 0 memory after moving logits to GPU 1: 16.56 GB
[Step 101] Teacher logits device after move: cuda:1, shape: torch.Size([2, 271, 151936])
[Step 101] GPU 0 memory after del: 16.39 GB
[Step 101] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 101] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.35 GB
[Step 101] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 101] Sequence length: 271, Batch size: 2
[Step 101] After KL computation - GPU 1: 36.00 GB
[Step 101] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 111] ========== MEMORY DEBUG ==========
[Step 111] Model device: cuda:1
[Step 111] Input device: cuda:1
[Step 111] Teacher model device: cuda:0
[Step 111] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 111] GPU 1 memory: 33.76 GB (reserved: 45.00 GB)
[Step 111] Student logits device: cuda:1, shape: torch.Size([2, 925, 151936]), dtype: torch.float32
[Step 111] Student model device: cuda:1
[Step 111] GPU 0 memory before teacher forward: 16.39 GB
[Step 111] GPU 0 memory after moving inputs: 16.39 GB
[Step 111] GPU 0 memory after teacher forward: 16.95 GB
[Step 111] Teacher logits shape: torch.Size([2, 925, 151936]), dtype: torch.float16
[Step 111] Teacher logits device before move: cuda:0
[Step 111] Target device (student_logits.device): cuda:1
[Step 111] GPU 0 memory after moving logits to GPU 1: 16.95 GB
[Step 111] Teacher logits device after move: cuda:1, shape: torch.Size([2, 925, 151936])
[Step 111] GPU 0 memory after del: 16.39 GB
[Step 111] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 111] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.66 GB
[Step 111] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 111] Sequence length: 925, Batch size: 2
[Step 111] After KL computation - GPU 1: 39.91 GB
[Step 111] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 121] ========== MEMORY DEBUG ==========
[Step 121] Model device: cuda:1
[Step 121] Input device: cuda:1
[Step 121] Teacher model device: cuda:0
[Step 121] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 121] GPU 1 memory: 33.76 GB (reserved: 47.48 GB)
[Step 121] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 121] Student model device: cuda:1
[Step 121] GPU 0 memory before teacher forward: 16.39 GB
[Step 121] GPU 0 memory after moving inputs: 16.39 GB
[Step 121] GPU 0 memory after teacher forward: 17.01 GB
[Step 121] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 121] Teacher logits device before move: cuda:0
[Step 121] Target device (student_logits.device): cuda:1
[Step 121] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 121] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 121] GPU 0 memory after del: 16.39 GB
[Step 121] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 121] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 121] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 121] Sequence length: 1024, Batch size: 2
[Step 121] After KL computation - GPU 1: 40.50 GB
[Step 121] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 131] ========== MEMORY DEBUG ==========
[Step 131] Model device: cuda:1
[Step 131] Input device: cuda:1
[Step 131] Teacher model device: cuda:0
[Step 131] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 131] GPU 1 memory: 33.76 GB (reserved: 47.22 GB)
[Step 131] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 131] Student model device: cuda:1
[Step 131] GPU 0 memory before teacher forward: 16.39 GB
[Step 131] GPU 0 memory after moving inputs: 16.39 GB
[Step 131] GPU 0 memory after teacher forward: 17.01 GB
[Step 131] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 131] Teacher logits device before move: cuda:0
[Step 131] Target device (student_logits.device): cuda:1
[Step 131] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 131] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 131] GPU 0 memory after del: 16.39 GB
[Step 131] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 131] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 131] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 131] Sequence length: 1024, Batch size: 2
[Step 131] After KL computation - GPU 1: 40.50 GB
[Step 131] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 141] ========== MEMORY DEBUG ==========
[Step 141] Model device: cuda:1
[Step 141] Input device: cuda:1
[Step 141] Teacher model device: cuda:0
[Step 141] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 141] GPU 1 memory: 33.76 GB (reserved: 39.33 GB)
[Step 141] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 141] Student model device: cuda:1
[Step 141] GPU 0 memory before teacher forward: 16.39 GB
[Step 141] GPU 0 memory after moving inputs: 16.39 GB
[Step 141] GPU 0 memory after teacher forward: 17.01 GB
[Step 141] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 141] Teacher logits device before move: cuda:0
[Step 141] Target device (student_logits.device): cuda:1
[Step 141] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 141] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 141] GPU 0 memory after del: 16.39 GB
[Step 141] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 141] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 141] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 141] Sequence length: 1024, Batch size: 2
[Step 141] After KL computation - GPU 1: 40.50 GB
[Step 141] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 151] ========== MEMORY DEBUG ==========
[Step 151] Model device: cuda:1
[Step 151] Input device: cuda:1
[Step 151] Teacher model device: cuda:0
[Step 151] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 151] GPU 1 memory: 33.77 GB (reserved: 47.73 GB)
[Step 151] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 151] Student model device: cuda:1
[Step 151] GPU 0 memory before teacher forward: 16.39 GB
[Step 151] GPU 0 memory after moving inputs: 16.39 GB
[Step 151] GPU 0 memory after teacher forward: 17.01 GB
[Step 151] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 151] Teacher logits device before move: cuda:0
[Step 151] Target device (student_logits.device): cuda:1
[Step 151] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 151] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 151] GPU 0 memory after del: 16.39 GB
[Step 151] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 151] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 151] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 151] Sequence length: 1024, Batch size: 2
[Step 151] After KL computation - GPU 1: 40.51 GB
[Step 151] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 1077258.3, 'grad_norm': nan, 'learning_rate': 4.5e-06, 'epoch': 0.0}

[Step 161] ========== MEMORY DEBUG ==========
[Step 161] Model device: cuda:1
[Step 161] Input device: cuda:1
[Step 161] Teacher model device: cuda:0
[Step 161] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 161] GPU 1 memory: 25.33 GB (reserved: 45.45 GB)
[Step 161] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 161] Student model device: cuda:1
[Step 161] GPU 0 memory before teacher forward: 16.39 GB
[Step 161] GPU 0 memory after moving inputs: 16.39 GB
[Step 161] GPU 0 memory after teacher forward: 17.01 GB
[Step 161] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 161] Teacher logits device before move: cuda:0
[Step 161] Target device (student_logits.device): cuda:1
[Step 161] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 161] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 161] GPU 0 memory after del: 16.39 GB
[Step 161] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 161] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 161] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 161] Sequence length: 1024, Batch size: 2
[Step 161] After KL computation - GPU 1: 32.07 GB
[Step 161] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 171] ========== MEMORY DEBUG ==========
[Step 171] Model device: cuda:1
[Step 171] Input device: cuda:1
[Step 171] Teacher model device: cuda:0
[Step 171] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 171] GPU 1 memory: 33.76 GB (reserved: 44.87 GB)
[Step 171] Student logits device: cuda:1, shape: torch.Size([2, 810, 151936]), dtype: torch.float32
[Step 171] Student model device: cuda:1
[Step 171] GPU 0 memory before teacher forward: 16.39 GB
[Step 171] GPU 0 memory after moving inputs: 16.39 GB
[Step 171] GPU 0 memory after teacher forward: 16.88 GB
[Step 171] Teacher logits shape: torch.Size([2, 810, 151936]), dtype: torch.float16
[Step 171] Teacher logits device before move: cuda:0
[Step 171] Target device (student_logits.device): cuda:1
[Step 171] GPU 0 memory after moving logits to GPU 1: 16.88 GB
[Step 171] Teacher logits device after move: cuda:1, shape: torch.Size([2, 810, 151936])
[Step 171] GPU 0 memory after del: 16.39 GB
[Step 171] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 171] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.25 GB
[Step 171] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 171] Sequence length: 810, Batch size: 2
[Step 171] After KL computation - GPU 1: 39.22 GB
[Step 171] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 181] ========== MEMORY DEBUG ==========
[Step 181] Model device: cuda:1
[Step 181] Input device: cuda:1
[Step 181] Teacher model device: cuda:0
[Step 181] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 181] GPU 1 memory: 33.76 GB (reserved: 47.59 GB)
[Step 181] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 181] Student model device: cuda:1
[Step 181] GPU 0 memory before teacher forward: 16.39 GB
[Step 181] GPU 0 memory after moving inputs: 16.39 GB
[Step 181] GPU 0 memory after teacher forward: 17.01 GB
[Step 181] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 181] Teacher logits device before move: cuda:0
[Step 181] Target device (student_logits.device): cuda:1
[Step 181] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 181] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 181] GPU 0 memory after del: 16.39 GB
[Step 181] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 181] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 181] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 181] Sequence length: 1024, Batch size: 2
[Step 181] After KL computation - GPU 1: 40.50 GB
[Step 181] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 191] ========== MEMORY DEBUG ==========
[Step 191] Model device: cuda:1
[Step 191] Input device: cuda:1
[Step 191] Teacher model device: cuda:0
[Step 191] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 191] GPU 1 memory: 33.76 GB (reserved: 42.99 GB)
[Step 191] Student logits device: cuda:1, shape: torch.Size([2, 985, 151936]), dtype: torch.float32
[Step 191] Student model device: cuda:1
[Step 191] GPU 0 memory before teacher forward: 16.39 GB
[Step 191] GPU 0 memory after moving inputs: 16.39 GB
[Step 191] GPU 0 memory after teacher forward: 16.99 GB
[Step 191] Teacher logits shape: torch.Size([2, 985, 151936]), dtype: torch.float16
[Step 191] Teacher logits device before move: cuda:0
[Step 191] Target device (student_logits.device): cuda:1
[Step 191] GPU 0 memory after moving logits to GPU 1: 16.99 GB
[Step 191] Teacher logits device after move: cuda:1, shape: torch.Size([2, 985, 151936])
[Step 191] GPU 0 memory after del: 16.39 GB
[Step 191] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 191] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.88 GB
[Step 191] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 191] Sequence length: 985, Batch size: 2
[Step 191] After KL computation - GPU 1: 40.27 GB
[Step 191] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 201] ========== MEMORY DEBUG ==========
[Step 201] Model device: cuda:1
[Step 201] Input device: cuda:1
[Step 201] Teacher model device: cuda:0
[Step 201] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 201] GPU 1 memory: 33.76 GB (reserved: 47.67 GB)
[Step 201] Student logits device: cuda:1, shape: torch.Size([2, 598, 151936]), dtype: torch.float32
[Step 201] Student model device: cuda:1
[Step 201] GPU 0 memory before teacher forward: 16.39 GB
[Step 201] GPU 0 memory after moving inputs: 16.39 GB
[Step 201] GPU 0 memory after teacher forward: 16.76 GB
[Step 201] Teacher logits shape: torch.Size([2, 598, 151936]), dtype: torch.float16
[Step 201] Teacher logits device before move: cuda:0
[Step 201] Target device (student_logits.device): cuda:1
[Step 201] GPU 0 memory after moving logits to GPU 1: 16.76 GB
[Step 201] Teacher logits device after move: cuda:1, shape: torch.Size([2, 598, 151936])
[Step 201] GPU 0 memory after del: 16.39 GB
[Step 201] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 201] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.51 GB
[Step 201] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 201] Sequence length: 598, Batch size: 2
[Step 201] After KL computation - GPU 1: 37.96 GB
[Step 201] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 211] ========== MEMORY DEBUG ==========
[Step 211] Model device: cuda:1
[Step 211] Input device: cuda:1
[Step 211] Teacher model device: cuda:0
[Step 211] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 211] GPU 1 memory: 33.76 GB (reserved: 47.44 GB)
[Step 211] Student logits device: cuda:1, shape: torch.Size([2, 484, 151936]), dtype: torch.float32
[Step 211] Student model device: cuda:1
[Step 211] GPU 0 memory before teacher forward: 16.39 GB
[Step 211] GPU 0 memory after moving inputs: 16.39 GB
[Step 211] GPU 0 memory after teacher forward: 16.69 GB
[Step 211] Teacher logits shape: torch.Size([2, 484, 151936]), dtype: torch.float16
[Step 211] Teacher logits device before move: cuda:0
[Step 211] Target device (student_logits.device): cuda:1
[Step 211] GPU 0 memory after moving logits to GPU 1: 16.69 GB
[Step 211] Teacher logits device after move: cuda:1, shape: torch.Size([2, 484, 151936])
[Step 211] GPU 0 memory after del: 16.39 GB
[Step 211] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 211] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.10 GB
[Step 211] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 211] Sequence length: 484, Batch size: 2
[Step 211] After KL computation - GPU 1: 37.28 GB
[Step 211] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 221] ========== MEMORY DEBUG ==========
[Step 221] Model device: cuda:1
[Step 221] Input device: cuda:1
[Step 221] Teacher model device: cuda:0
[Step 221] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 221] GPU 1 memory: 33.76 GB (reserved: 48.01 GB)
[Step 221] Student logits device: cuda:1, shape: torch.Size([2, 559, 151936]), dtype: torch.float32
[Step 221] Student model device: cuda:1
[Step 221] GPU 0 memory before teacher forward: 16.39 GB
[Step 221] GPU 0 memory after moving inputs: 16.39 GB
[Step 221] GPU 0 memory after teacher forward: 16.73 GB
[Step 221] Teacher logits shape: torch.Size([2, 559, 151936]), dtype: torch.float16
[Step 221] Teacher logits device before move: cuda:0
[Step 221] Target device (student_logits.device): cuda:1
[Step 221] GPU 0 memory after moving logits to GPU 1: 16.73 GB
[Step 221] Teacher logits device after move: cuda:1, shape: torch.Size([2, 559, 151936])
[Step 221] GPU 0 memory after del: 16.39 GB
[Step 221] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 221] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.37 GB
[Step 221] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 221] Sequence length: 559, Batch size: 2
[Step 221] After KL computation - GPU 1: 37.72 GB
[Step 221] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 231] ========== MEMORY DEBUG ==========
[Step 231] Model device: cuda:1
[Step 231] Input device: cuda:1
[Step 231] Teacher model device: cuda:0
[Step 231] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 231] GPU 1 memory: 33.77 GB (reserved: 44.78 GB)
[Step 231] Student logits device: cuda:1, shape: torch.Size([2, 1020, 151936]), dtype: torch.float32
[Step 231] Student model device: cuda:1
[Step 231] GPU 0 memory before teacher forward: 16.39 GB
[Step 231] GPU 0 memory after moving inputs: 16.39 GB
[Step 231] GPU 0 memory after teacher forward: 17.01 GB
[Step 231] Teacher logits shape: torch.Size([2, 1020, 151936]), dtype: torch.float16
[Step 231] Teacher logits device before move: cuda:0
[Step 231] Target device (student_logits.device): cuda:1
[Step 231] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 231] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1020, 151936])
[Step 231] GPU 0 memory after del: 16.39 GB
[Step 231] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 231] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 231] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 231] Sequence length: 1020, Batch size: 2
[Step 231] After KL computation - GPU 1: 40.49 GB
[Step 231] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 241] ========== MEMORY DEBUG ==========
[Step 241] Model device: cuda:1
[Step 241] Input device: cuda:1
[Step 241] Teacher model device: cuda:0
[Step 241] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 241] GPU 1 memory: 25.33 GB (reserved: 48.00 GB)
[Step 241] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 241] Student model device: cuda:1
[Step 241] GPU 0 memory before teacher forward: 16.39 GB
[Step 241] GPU 0 memory after moving inputs: 16.39 GB
[Step 241] GPU 0 memory after teacher forward: 17.01 GB
[Step 241] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 241] Teacher logits device before move: cuda:0
[Step 241] Target device (student_logits.device): cuda:1
[Step 241] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 241] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 241] GPU 0 memory after del: 16.39 GB
[Step 241] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 241] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 241] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 241] Sequence length: 1024, Batch size: 2
[Step 241] After KL computation - GPU 1: 32.06 GB
[Step 241] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 251] ========== MEMORY DEBUG ==========
[Step 251] Model device: cuda:1
[Step 251] Input device: cuda:1
[Step 251] Teacher model device: cuda:0
[Step 251] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 251] GPU 1 memory: 33.76 GB (reserved: 47.54 GB)
[Step 251] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 251] Student model device: cuda:1
[Step 251] GPU 0 memory before teacher forward: 16.39 GB
[Step 251] GPU 0 memory after moving inputs: 16.39 GB
[Step 251] GPU 0 memory after teacher forward: 17.01 GB
[Step 251] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 251] Teacher logits device before move: cuda:0
[Step 251] Target device (student_logits.device): cuda:1
[Step 251] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 251] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 251] GPU 0 memory after del: 16.39 GB
[Step 251] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 251] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 251] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 251] Sequence length: 1024, Batch size: 2
[Step 251] After KL computation - GPU 1: 40.50 GB
[Step 251] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 261] ========== MEMORY DEBUG ==========
[Step 261] Model device: cuda:1
[Step 261] Input device: cuda:1
[Step 261] Teacher model device: cuda:0
[Step 261] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 261] GPU 1 memory: 33.76 GB (reserved: 47.79 GB)
[Step 261] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 261] Student model device: cuda:1
[Step 261] GPU 0 memory before teacher forward: 16.39 GB
[Step 261] GPU 0 memory after moving inputs: 16.39 GB
[Step 261] GPU 0 memory after teacher forward: 17.01 GB
[Step 261] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 261] Teacher logits device before move: cuda:0
[Step 261] Target device (student_logits.device): cuda:1
[Step 261] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 261] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 261] GPU 0 memory after del: 16.39 GB
[Step 261] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 261] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 261] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 261] Sequence length: 1024, Batch size: 2
[Step 261] After KL computation - GPU 1: 40.50 GB
[Step 261] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 271] ========== MEMORY DEBUG ==========
[Step 271] Model device: cuda:1
[Step 271] Input device: cuda:1
[Step 271] Teacher model device: cuda:0
[Step 271] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 271] GPU 1 memory: 33.76 GB (reserved: 47.68 GB)
[Step 271] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 271] Student model device: cuda:1
[Step 271] GPU 0 memory before teacher forward: 16.39 GB
[Step 271] GPU 0 memory after moving inputs: 16.39 GB
[Step 271] GPU 0 memory after teacher forward: 17.01 GB
[Step 271] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 271] Teacher logits device before move: cuda:0
[Step 271] Target device (student_logits.device): cuda:1
[Step 271] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 271] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 271] GPU 0 memory after del: 16.39 GB
[Step 271] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 271] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 271] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 271] Sequence length: 1024, Batch size: 2
[Step 271] After KL computation - GPU 1: 40.50 GB
[Step 271] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 281] ========== MEMORY DEBUG ==========
[Step 281] Model device: cuda:1
[Step 281] Input device: cuda:1
[Step 281] Teacher model device: cuda:0
[Step 281] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 281] GPU 1 memory: 33.76 GB (reserved: 47.54 GB)
[Step 281] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 281] Student model device: cuda:1
[Step 281] GPU 0 memory before teacher forward: 16.39 GB
[Step 281] GPU 0 memory after moving inputs: 16.39 GB
[Step 281] GPU 0 memory after teacher forward: 17.01 GB
[Step 281] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 281] Teacher logits device before move: cuda:0
[Step 281] Target device (student_logits.device): cuda:1
[Step 281] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 281] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 281] GPU 0 memory after del: 16.39 GB
[Step 281] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 281] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 281] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 281] Sequence length: 1024, Batch size: 2
[Step 281] After KL computation - GPU 1: 40.50 GB
[Step 281] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 291] ========== MEMORY DEBUG ==========
[Step 291] Model device: cuda:1
[Step 291] Input device: cuda:1
[Step 291] Teacher model device: cuda:0
[Step 291] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 291] GPU 1 memory: 33.76 GB (reserved: 41.03 GB)
[Step 291] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 291] Student model device: cuda:1
[Step 291] GPU 0 memory before teacher forward: 16.39 GB
[Step 291] GPU 0 memory after moving inputs: 16.39 GB
[Step 291] GPU 0 memory after teacher forward: 17.01 GB
[Step 291] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 291] Teacher logits device before move: cuda:0
[Step 291] Target device (student_logits.device): cuda:1
[Step 291] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 291] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 291] GPU 0 memory after del: 16.39 GB
[Step 291] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 291] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 291] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 291] Sequence length: 1024, Batch size: 2
[Step 291] After KL computation - GPU 1: 40.50 GB
[Step 291] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 301] ========== MEMORY DEBUG ==========
[Step 301] Model device: cuda:1
[Step 301] Input device: cuda:1
[Step 301] Teacher model device: cuda:0
[Step 301] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 301] GPU 1 memory: 33.76 GB (reserved: 47.58 GB)
[Step 301] Student logits device: cuda:1, shape: torch.Size([2, 929, 151936]), dtype: torch.float32
[Step 301] Student model device: cuda:1
[Step 301] GPU 0 memory before teacher forward: 16.39 GB
[Step 301] GPU 0 memory after moving inputs: 16.39 GB
[Step 301] GPU 0 memory after teacher forward: 16.96 GB
[Step 301] Teacher logits shape: torch.Size([2, 929, 151936]), dtype: torch.float16
[Step 301] Teacher logits device before move: cuda:0
[Step 301] Target device (student_logits.device): cuda:1
[Step 301] GPU 0 memory after moving logits to GPU 1: 16.96 GB
[Step 301] Teacher logits device after move: cuda:1, shape: torch.Size([2, 929, 151936])
[Step 301] GPU 0 memory after del: 16.39 GB
[Step 301] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 301] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.68 GB
[Step 301] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 301] Sequence length: 929, Batch size: 2
[Step 301] After KL computation - GPU 1: 39.93 GB
[Step 301] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 311] ========== MEMORY DEBUG ==========
[Step 311] Model device: cuda:1
[Step 311] Input device: cuda:1
[Step 311] Teacher model device: cuda:0
[Step 311] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 311] GPU 1 memory: 33.77 GB (reserved: 47.80 GB)
[Step 311] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 311] Student model device: cuda:1
[Step 311] GPU 0 memory before teacher forward: 16.39 GB
[Step 311] GPU 0 memory after moving inputs: 16.39 GB
[Step 311] GPU 0 memory after teacher forward: 17.01 GB
[Step 311] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 311] Teacher logits device before move: cuda:0
[Step 311] Target device (student_logits.device): cuda:1
[Step 311] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 311] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 311] GPU 0 memory after del: 16.39 GB
[Step 311] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 311] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 311] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 311] Sequence length: 1024, Batch size: 2
[Step 311] After KL computation - GPU 1: 40.51 GB
[Step 311] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.5e-06, 'epoch': 0.0}

[Step 321] ========== MEMORY DEBUG ==========
[Step 321] Model device: cuda:1
[Step 321] Input device: cuda:1
[Step 321] Teacher model device: cuda:0
[Step 321] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 321] GPU 1 memory: 25.33 GB (reserved: 47.71 GB)
[Step 321] Student logits device: cuda:1, shape: torch.Size([2, 468, 151936]), dtype: torch.float32
[Step 321] Student model device: cuda:1
[Step 321] GPU 0 memory before teacher forward: 16.39 GB
[Step 321] GPU 0 memory after moving inputs: 16.39 GB
[Step 321] GPU 0 memory after teacher forward: 16.68 GB
[Step 321] Teacher logits shape: torch.Size([2, 468, 151936]), dtype: torch.float16
[Step 321] Teacher logits device before move: cuda:0
[Step 321] Target device (student_logits.device): cuda:1
[Step 321] GPU 0 memory after moving logits to GPU 1: 16.68 GB
[Step 321] Teacher logits device after move: cuda:1, shape: torch.Size([2, 468, 151936])
[Step 321] GPU 0 memory after del: 16.39 GB
[Step 321] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 321] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 27.61 GB
[Step 321] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 321] Sequence length: 468, Batch size: 2
[Step 321] After KL computation - GPU 1: 28.75 GB
[Step 321] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 331] ========== MEMORY DEBUG ==========
[Step 331] Model device: cuda:1
[Step 331] Input device: cuda:1
[Step 331] Teacher model device: cuda:0
[Step 331] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 331] GPU 1 memory: 33.77 GB (reserved: 47.80 GB)
[Step 331] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 331] Student model device: cuda:1
[Step 331] GPU 0 memory before teacher forward: 16.39 GB
[Step 331] GPU 0 memory after moving inputs: 16.39 GB
[Step 331] GPU 0 memory after teacher forward: 17.01 GB
[Step 331] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 331] Teacher logits device before move: cuda:0
[Step 331] Target device (student_logits.device): cuda:1
[Step 331] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 331] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 331] GPU 0 memory after del: 16.39 GB
[Step 331] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 331] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 331] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 331] Sequence length: 1024, Batch size: 2
[Step 331] After KL computation - GPU 1: 40.51 GB
[Step 331] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 341] ========== MEMORY DEBUG ==========
[Step 341] Model device: cuda:1
[Step 341] Input device: cuda:1
[Step 341] Teacher model device: cuda:0
[Step 341] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 341] GPU 1 memory: 33.77 GB (reserved: 48.10 GB)
[Step 341] Student logits device: cuda:1, shape: torch.Size([2, 719, 151936]), dtype: torch.float32
[Step 341] Student model device: cuda:1
[Step 341] GPU 0 memory before teacher forward: 16.39 GB
[Step 341] GPU 0 memory after moving inputs: 16.39 GB
[Step 341] GPU 0 memory after teacher forward: 16.83 GB
[Step 341] Teacher logits shape: torch.Size([2, 719, 151936]), dtype: torch.float16
[Step 341] Teacher logits device before move: cuda:0
[Step 341] Target device (student_logits.device): cuda:1
[Step 341] GPU 0 memory after moving logits to GPU 1: 16.83 GB
[Step 341] Teacher logits device after move: cuda:1, shape: torch.Size([2, 719, 151936])
[Step 341] GPU 0 memory after del: 16.39 GB
[Step 341] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 341] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.93 GB
[Step 341] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 341] Sequence length: 719, Batch size: 2
[Step 341] After KL computation - GPU 1: 38.68 GB
[Step 341] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 351] ========== MEMORY DEBUG ==========
[Step 351] Model device: cuda:1
[Step 351] Input device: cuda:1
[Step 351] Teacher model device: cuda:0
[Step 351] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 351] GPU 1 memory: 33.77 GB (reserved: 47.95 GB)
[Step 351] Student logits device: cuda:1, shape: torch.Size([2, 258, 151936]), dtype: torch.float32
[Step 351] Student model device: cuda:1
[Step 351] GPU 0 memory before teacher forward: 16.39 GB
[Step 351] GPU 0 memory after moving inputs: 16.39 GB
[Step 351] GPU 0 memory after teacher forward: 16.55 GB
[Step 351] Teacher logits shape: torch.Size([2, 258, 151936]), dtype: torch.float16
[Step 351] Teacher logits device before move: cuda:0
[Step 351] Target device (student_logits.device): cuda:1
[Step 351] GPU 0 memory after moving logits to GPU 1: 16.55 GB
[Step 351] Teacher logits device after move: cuda:1, shape: torch.Size([2, 258, 151936])
[Step 351] GPU 0 memory after del: 16.39 GB
[Step 351] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 351] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.31 GB
[Step 351] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 351] Sequence length: 258, Batch size: 2
[Step 351] After KL computation - GPU 1: 35.93 GB
[Step 351] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 361] ========== MEMORY DEBUG ==========
[Step 361] Model device: cuda:1
[Step 361] Input device: cuda:1
[Step 361] Teacher model device: cuda:0
[Step 361] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 361] GPU 1 memory: 33.76 GB (reserved: 47.54 GB)
[Step 361] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 361] Student model device: cuda:1
[Step 361] GPU 0 memory before teacher forward: 16.39 GB
[Step 361] GPU 0 memory after moving inputs: 16.39 GB
[Step 361] GPU 0 memory after teacher forward: 17.01 GB
[Step 361] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 361] Teacher logits device before move: cuda:0
[Step 361] Target device (student_logits.device): cuda:1
[Step 361] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 361] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 361] GPU 0 memory after del: 16.39 GB
[Step 361] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 361] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 361] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 361] Sequence length: 1024, Batch size: 2
[Step 361] After KL computation - GPU 1: 40.51 GB
[Step 361] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 371] ========== MEMORY DEBUG ==========
[Step 371] Model device: cuda:1
[Step 371] Input device: cuda:1
[Step 371] Teacher model device: cuda:0
[Step 371] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 371] GPU 1 memory: 33.76 GB (reserved: 47.73 GB)
[Step 371] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 371] Student model device: cuda:1
[Step 371] GPU 0 memory before teacher forward: 16.39 GB
[Step 371] GPU 0 memory after moving inputs: 16.39 GB
[Step 371] GPU 0 memory after teacher forward: 17.01 GB
[Step 371] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 371] Teacher logits device before move: cuda:0
[Step 371] Target device (student_logits.device): cuda:1
[Step 371] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 371] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 371] GPU 0 memory after del: 16.39 GB
[Step 371] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 371] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 371] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 371] Sequence length: 1024, Batch size: 2
[Step 371] After KL computation - GPU 1: 40.51 GB
[Step 371] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 381] ========== MEMORY DEBUG ==========
[Step 381] Model device: cuda:1
[Step 381] Input device: cuda:1
[Step 381] Teacher model device: cuda:0
[Step 381] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 381] GPU 1 memory: 33.76 GB (reserved: 47.67 GB)
[Step 381] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 381] Student model device: cuda:1
[Step 381] GPU 0 memory before teacher forward: 16.39 GB
[Step 381] GPU 0 memory after moving inputs: 16.39 GB
[Step 381] GPU 0 memory after teacher forward: 17.01 GB
[Step 381] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 381] Teacher logits device before move: cuda:0
[Step 381] Target device (student_logits.device): cuda:1
[Step 381] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 381] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 381] GPU 0 memory after del: 16.39 GB
[Step 381] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 381] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 381] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 381] Sequence length: 1024, Batch size: 2
[Step 381] After KL computation - GPU 1: 40.51 GB
[Step 381] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 391] ========== MEMORY DEBUG ==========
[Step 391] Model device: cuda:1
[Step 391] Input device: cuda:1
[Step 391] Teacher model device: cuda:0
[Step 391] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 391] GPU 1 memory: 33.76 GB (reserved: 47.54 GB)
[Step 391] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 391] Student model device: cuda:1
[Step 391] GPU 0 memory before teacher forward: 16.39 GB
[Step 391] GPU 0 memory after moving inputs: 16.39 GB
[Step 391] GPU 0 memory after teacher forward: 17.01 GB
[Step 391] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 391] Teacher logits device before move: cuda:0
[Step 391] Target device (student_logits.device): cuda:1
[Step 391] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 391] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 391] GPU 0 memory after del: 16.39 GB
[Step 391] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 391] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 391] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 391] Sequence length: 1024, Batch size: 2
[Step 391] After KL computation - GPU 1: 40.50 GB
[Step 391] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 401] ========== MEMORY DEBUG ==========
[Step 401] Model device: cuda:1
[Step 401] Input device: cuda:1
[Step 401] Teacher model device: cuda:0
[Step 401] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 401] GPU 1 memory: 25.33 GB (reserved: 42.66 GB)
[Step 401] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 401] Student model device: cuda:1
[Step 401] GPU 0 memory before teacher forward: 16.39 GB
[Step 401] GPU 0 memory after moving inputs: 16.39 GB
[Step 401] GPU 0 memory after teacher forward: 17.01 GB
[Step 401] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 401] Teacher logits device before move: cuda:0
[Step 401] Target device (student_logits.device): cuda:1
[Step 401] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 401] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 401] GPU 0 memory after del: 16.39 GB
[Step 401] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 401] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 401] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 401] Sequence length: 1024, Batch size: 2
[Step 401] After KL computation - GPU 1: 32.07 GB
[Step 401] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 411] ========== MEMORY DEBUG ==========
[Step 411] Model device: cuda:1
[Step 411] Input device: cuda:1
[Step 411] Teacher model device: cuda:0
[Step 411] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 411] GPU 1 memory: 33.76 GB (reserved: 47.64 GB)
[Step 411] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 411] Student model device: cuda:1
[Step 411] GPU 0 memory before teacher forward: 16.39 GB
[Step 411] GPU 0 memory after moving inputs: 16.39 GB
[Step 411] GPU 0 memory after teacher forward: 17.01 GB
[Step 411] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 411] Teacher logits device before move: cuda:0
[Step 411] Target device (student_logits.device): cuda:1
[Step 411] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 411] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 411] GPU 0 memory after del: 16.39 GB
[Step 411] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 411] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 411] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 411] Sequence length: 1024, Batch size: 2
[Step 411] After KL computation - GPU 1: 40.50 GB
[Step 411] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 421] ========== MEMORY DEBUG ==========
[Step 421] Model device: cuda:1
[Step 421] Input device: cuda:1
[Step 421] Teacher model device: cuda:0
[Step 421] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 421] GPU 1 memory: 33.76 GB (reserved: 47.47 GB)
[Step 421] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 421] Student model device: cuda:1
[Step 421] GPU 0 memory before teacher forward: 16.39 GB
[Step 421] GPU 0 memory after moving inputs: 16.39 GB
[Step 421] GPU 0 memory after teacher forward: 17.01 GB
[Step 421] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 421] Teacher logits device before move: cuda:0
[Step 421] Target device (student_logits.device): cuda:1
[Step 421] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 421] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 421] GPU 0 memory after del: 16.39 GB
[Step 421] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 421] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 421] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 421] Sequence length: 1024, Batch size: 2
[Step 421] After KL computation - GPU 1: 40.50 GB
[Step 421] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 431] ========== MEMORY DEBUG ==========
[Step 431] Model device: cuda:1
[Step 431] Input device: cuda:1
[Step 431] Teacher model device: cuda:0
[Step 431] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 431] GPU 1 memory: 33.76 GB (reserved: 47.93 GB)
[Step 431] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 431] Student model device: cuda:1
[Step 431] GPU 0 memory before teacher forward: 16.39 GB
[Step 431] GPU 0 memory after moving inputs: 16.39 GB
[Step 431] GPU 0 memory after teacher forward: 17.01 GB
[Step 431] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 431] Teacher logits device before move: cuda:0
[Step 431] Target device (student_logits.device): cuda:1
[Step 431] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 431] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 431] GPU 0 memory after del: 16.39 GB
[Step 431] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 431] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 431] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 431] Sequence length: 1024, Batch size: 2
[Step 431] After KL computation - GPU 1: 40.51 GB
[Step 431] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 441] ========== MEMORY DEBUG ==========
[Step 441] Model device: cuda:1
[Step 441] Input device: cuda:1
[Step 441] Teacher model device: cuda:0
[Step 441] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 441] GPU 1 memory: 33.76 GB (reserved: 41.60 GB)
[Step 441] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 441] Student model device: cuda:1
[Step 441] GPU 0 memory before teacher forward: 16.39 GB
[Step 441] GPU 0 memory after moving inputs: 16.39 GB
[Step 441] GPU 0 memory after teacher forward: 17.01 GB
[Step 441] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 441] Teacher logits device before move: cuda:0
[Step 441] Target device (student_logits.device): cuda:1
[Step 441] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 441] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 441] GPU 0 memory after del: 16.39 GB
[Step 441] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 441] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 441] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 441] Sequence length: 1024, Batch size: 2
[Step 441] After KL computation - GPU 1: 40.50 GB
[Step 441] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 451] ========== MEMORY DEBUG ==========
[Step 451] Model device: cuda:1
[Step 451] Input device: cuda:1
[Step 451] Teacher model device: cuda:0
[Step 451] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 451] GPU 1 memory: 33.77 GB (reserved: 48.28 GB)
[Step 451] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 451] Student model device: cuda:1
[Step 451] GPU 0 memory before teacher forward: 16.39 GB
[Step 451] GPU 0 memory after moving inputs: 16.39 GB
[Step 451] GPU 0 memory after teacher forward: 17.01 GB
[Step 451] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 451] Teacher logits device before move: cuda:0
[Step 451] Target device (student_logits.device): cuda:1
[Step 451] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 451] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 451] GPU 0 memory after del: 16.39 GB
[Step 451] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 451] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 451] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 451] Sequence length: 1024, Batch size: 2
[Step 451] After KL computation - GPU 1: 40.51 GB
[Step 451] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 461] ========== MEMORY DEBUG ==========
[Step 461] Model device: cuda:1
[Step 461] Input device: cuda:1
[Step 461] Teacher model device: cuda:0
[Step 461] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 461] GPU 1 memory: 33.77 GB (reserved: 48.24 GB)
[Step 461] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 461] Student model device: cuda:1
[Step 461] GPU 0 memory before teacher forward: 16.39 GB
[Step 461] GPU 0 memory after moving inputs: 16.39 GB
[Step 461] GPU 0 memory after teacher forward: 17.01 GB
[Step 461] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 461] Teacher logits device before move: cuda:0
[Step 461] Target device (student_logits.device): cuda:1
[Step 461] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 461] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 461] GPU 0 memory after del: 16.39 GB
[Step 461] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 461] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 461] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 461] Sequence length: 1024, Batch size: 2
[Step 461] After KL computation - GPU 1: 40.50 GB
[Step 461] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 471] ========== MEMORY DEBUG ==========
[Step 471] Model device: cuda:1
[Step 471] Input device: cuda:1
[Step 471] Teacher model device: cuda:0
[Step 471] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 471] GPU 1 memory: 33.78 GB (reserved: 47.70 GB)
[Step 471] Student logits device: cuda:1, shape: torch.Size([2, 779, 151936]), dtype: torch.float32
[Step 471] Student model device: cuda:1
[Step 471] GPU 0 memory before teacher forward: 16.39 GB
[Step 471] GPU 0 memory after moving inputs: 16.39 GB
[Step 471] GPU 0 memory after teacher forward: 16.87 GB
[Step 471] Teacher logits shape: torch.Size([2, 779, 151936]), dtype: torch.float16
[Step 471] Teacher logits device before move: cuda:0
[Step 471] Target device (student_logits.device): cuda:1
[Step 471] GPU 0 memory after moving logits to GPU 1: 16.87 GB
[Step 471] Teacher logits device after move: cuda:1, shape: torch.Size([2, 779, 151936])
[Step 471] GPU 0 memory after del: 16.39 GB
[Step 471] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 471] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.17 GB
[Step 471] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 471] Sequence length: 779, Batch size: 2
[Step 471] After KL computation - GPU 1: 39.06 GB
[Step 471] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.45e-05, 'epoch': 0.0}

[Step 481] ========== MEMORY DEBUG ==========
[Step 481] Model device: cuda:1
[Step 481] Input device: cuda:1
[Step 481] Teacher model device: cuda:0
[Step 481] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 481] GPU 1 memory: 25.33 GB (reserved: 47.41 GB)
[Step 481] Student logits device: cuda:1, shape: torch.Size([2, 321, 151936]), dtype: torch.float32
[Step 481] Student model device: cuda:1
[Step 481] GPU 0 memory before teacher forward: 16.39 GB
[Step 481] GPU 0 memory after moving inputs: 16.39 GB
[Step 481] GPU 0 memory after teacher forward: 16.59 GB
[Step 481] Teacher logits shape: torch.Size([2, 321, 151936]), dtype: torch.float16
[Step 481] Teacher logits device before move: cuda:0
[Step 481] Target device (student_logits.device): cuda:1
[Step 481] GPU 0 memory after moving logits to GPU 1: 16.59 GB
[Step 481] Teacher logits device after move: cuda:1, shape: torch.Size([2, 321, 151936])
[Step 481] GPU 0 memory after del: 16.39 GB
[Step 481] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 481] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 27.09 GB
[Step 481] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 481] Sequence length: 321, Batch size: 2
[Step 481] After KL computation - GPU 1: 27.87 GB
[Step 481] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 491] ========== MEMORY DEBUG ==========
[Step 491] Model device: cuda:1
[Step 491] Input device: cuda:1
[Step 491] Teacher model device: cuda:0
[Step 491] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 491] GPU 1 memory: 33.76 GB (reserved: 47.82 GB)
[Step 491] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 491] Student model device: cuda:1
[Step 491] GPU 0 memory before teacher forward: 16.39 GB
[Step 491] GPU 0 memory after moving inputs: 16.39 GB
[Step 491] GPU 0 memory after teacher forward: 17.01 GB
[Step 491] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 491] Teacher logits device before move: cuda:0
[Step 491] Target device (student_logits.device): cuda:1
[Step 491] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 491] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 491] GPU 0 memory after del: 16.39 GB
[Step 491] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 491] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 491] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 491] Sequence length: 1024, Batch size: 2
[Step 491] After KL computation - GPU 1: 40.50 GB
[Step 491] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 501] ========== MEMORY DEBUG ==========
[Step 501] Model device: cuda:1
[Step 501] Input device: cuda:1
[Step 501] Teacher model device: cuda:0
[Step 501] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 501] GPU 1 memory: 33.76 GB (reserved: 47.50 GB)
[Step 501] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 501] Student model device: cuda:1
[Step 501] GPU 0 memory before teacher forward: 16.39 GB
[Step 501] GPU 0 memory after moving inputs: 16.39 GB
[Step 501] GPU 0 memory after teacher forward: 17.01 GB
[Step 501] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 501] Teacher logits device before move: cuda:0
[Step 501] Target device (student_logits.device): cuda:1
[Step 501] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 501] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 501] GPU 0 memory after del: 16.39 GB
[Step 501] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 501] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 501] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 501] Sequence length: 1024, Batch size: 2
[Step 501] After KL computation - GPU 1: 40.50 GB
[Step 501] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 511] ========== MEMORY DEBUG ==========
[Step 511] Model device: cuda:1
[Step 511] Input device: cuda:1
[Step 511] Teacher model device: cuda:0
[Step 511] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 511] GPU 1 memory: 33.76 GB (reserved: 46.36 GB)
[Step 511] Student logits device: cuda:1, shape: torch.Size([2, 529, 151936]), dtype: torch.float32
[Step 511] Student model device: cuda:1
[Step 511] GPU 0 memory before teacher forward: 16.39 GB
[Step 511] GPU 0 memory after moving inputs: 16.39 GB
[Step 511] GPU 0 memory after teacher forward: 16.71 GB
[Step 511] Teacher logits shape: torch.Size([2, 529, 151936]), dtype: torch.float16
[Step 511] Teacher logits device before move: cuda:0
[Step 511] Target device (student_logits.device): cuda:1
[Step 511] GPU 0 memory after moving logits to GPU 1: 16.71 GB
[Step 511] Teacher logits device after move: cuda:1, shape: torch.Size([2, 529, 151936])
[Step 511] GPU 0 memory after del: 16.39 GB
[Step 511] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 511] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.26 GB
[Step 511] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 511] Sequence length: 529, Batch size: 2
[Step 511] After KL computation - GPU 1: 37.55 GB
[Step 511] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 521] ========== MEMORY DEBUG ==========
[Step 521] Model device: cuda:1
[Step 521] Input device: cuda:1
[Step 521] Teacher model device: cuda:0
[Step 521] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 521] GPU 1 memory: 33.76 GB (reserved: 42.71 GB)
[Step 521] Student logits device: cuda:1, shape: torch.Size([2, 740, 151936]), dtype: torch.float32
[Step 521] Student model device: cuda:1
[Step 521] GPU 0 memory before teacher forward: 16.39 GB
[Step 521] GPU 0 memory after moving inputs: 16.39 GB
[Step 521] GPU 0 memory after teacher forward: 16.84 GB
[Step 521] Teacher logits shape: torch.Size([2, 740, 151936]), dtype: torch.float16
[Step 521] Teacher logits device before move: cuda:0
[Step 521] Target device (student_logits.device): cuda:1
[Step 521] GPU 0 memory after moving logits to GPU 1: 16.84 GB
[Step 521] Teacher logits device after move: cuda:1, shape: torch.Size([2, 740, 151936])
[Step 521] GPU 0 memory after del: 16.39 GB
[Step 521] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 521] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.01 GB
[Step 521] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 521] Sequence length: 740, Batch size: 2
[Step 521] After KL computation - GPU 1: 38.80 GB
[Step 521] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 531] ========== MEMORY DEBUG ==========
[Step 531] Model device: cuda:1
[Step 531] Input device: cuda:1
[Step 531] Teacher model device: cuda:0
[Step 531] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 531] GPU 1 memory: 33.77 GB (reserved: 46.22 GB)
[Step 531] Student logits device: cuda:1, shape: torch.Size([2, 236, 151936]), dtype: torch.float32
[Step 531] Student model device: cuda:1
[Step 531] GPU 0 memory before teacher forward: 16.39 GB
[Step 531] GPU 0 memory after moving inputs: 16.39 GB
[Step 531] GPU 0 memory after teacher forward: 16.54 GB
[Step 531] Teacher logits shape: torch.Size([2, 236, 151936]), dtype: torch.float16
[Step 531] Teacher logits device before move: cuda:0
[Step 531] Target device (student_logits.device): cuda:1
[Step 531] GPU 0 memory after moving logits to GPU 1: 16.54 GB
[Step 531] Teacher logits device after move: cuda:1, shape: torch.Size([2, 236, 151936])
[Step 531] GPU 0 memory after del: 16.39 GB
[Step 531] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 531] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.24 GB
[Step 531] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 531] Sequence length: 236, Batch size: 2
[Step 531] After KL computation - GPU 1: 35.82 GB
[Step 531] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 541] ========== MEMORY DEBUG ==========
[Step 541] Model device: cuda:1
[Step 541] Input device: cuda:1
[Step 541] Teacher model device: cuda:0
[Step 541] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 541] GPU 1 memory: 33.77 GB (reserved: 47.80 GB)
[Step 541] Student logits device: cuda:1, shape: torch.Size([2, 882, 151936]), dtype: torch.float32
[Step 541] Student model device: cuda:1
[Step 541] GPU 0 memory before teacher forward: 16.39 GB
[Step 541] GPU 0 memory after moving inputs: 16.39 GB
[Step 541] GPU 0 memory after teacher forward: 16.93 GB
[Step 541] Teacher logits shape: torch.Size([2, 882, 151936]), dtype: torch.float16
[Step 541] Teacher logits device before move: cuda:0
[Step 541] Target device (student_logits.device): cuda:1
[Step 541] GPU 0 memory after moving logits to GPU 1: 16.93 GB
[Step 541] Teacher logits device after move: cuda:1, shape: torch.Size([2, 882, 151936])
[Step 541] GPU 0 memory after del: 16.39 GB
[Step 541] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 541] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.52 GB
[Step 541] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 541] Sequence length: 882, Batch size: 2
[Step 541] After KL computation - GPU 1: 39.67 GB
[Step 541] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 551] ========== MEMORY DEBUG ==========
[Step 551] Model device: cuda:1
[Step 551] Input device: cuda:1
[Step 551] Teacher model device: cuda:0
[Step 551] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 551] GPU 1 memory: 33.77 GB (reserved: 47.70 GB)
[Step 551] Student logits device: cuda:1, shape: torch.Size([2, 475, 151936]), dtype: torch.float32
[Step 551] Student model device: cuda:1
[Step 551] GPU 0 memory before teacher forward: 16.39 GB
[Step 551] GPU 0 memory after moving inputs: 16.39 GB
[Step 551] GPU 0 memory after teacher forward: 16.68 GB
[Step 551] Teacher logits shape: torch.Size([2, 475, 151936]), dtype: torch.float16
[Step 551] Teacher logits device before move: cuda:0
[Step 551] Target device (student_logits.device): cuda:1
[Step 551] GPU 0 memory after moving logits to GPU 1: 16.68 GB
[Step 551] Teacher logits device after move: cuda:1, shape: torch.Size([2, 475, 151936])
[Step 551] GPU 0 memory after del: 16.39 GB
[Step 551] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 551] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.07 GB
[Step 551] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 551] Sequence length: 475, Batch size: 2
[Step 551] After KL computation - GPU 1: 37.23 GB
[Step 551] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 561] ========== MEMORY DEBUG ==========
[Step 561] Model device: cuda:1
[Step 561] Input device: cuda:1
[Step 561] Teacher model device: cuda:0
[Step 561] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 561] GPU 1 memory: 25.33 GB (reserved: 43.90 GB)
[Step 561] Student logits device: cuda:1, shape: torch.Size([2, 497, 151936]), dtype: torch.float32
[Step 561] Student model device: cuda:1
[Step 561] GPU 0 memory before teacher forward: 16.39 GB
[Step 561] GPU 0 memory after moving inputs: 16.39 GB
[Step 561] GPU 0 memory after teacher forward: 16.69 GB
[Step 561] Teacher logits shape: torch.Size([2, 497, 151936]), dtype: torch.float16
[Step 561] Teacher logits device before move: cuda:0
[Step 561] Target device (student_logits.device): cuda:1
[Step 561] GPU 0 memory after moving logits to GPU 1: 16.69 GB
[Step 561] Teacher logits device after move: cuda:1, shape: torch.Size([2, 497, 151936])
[Step 561] GPU 0 memory after del: 16.39 GB
[Step 561] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 561] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 27.71 GB
[Step 561] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 561] Sequence length: 497, Batch size: 2
[Step 561] After KL computation - GPU 1: 28.92 GB
[Step 561] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 571] ========== MEMORY DEBUG ==========
[Step 571] Model device: cuda:1
[Step 571] Input device: cuda:1
[Step 571] Teacher model device: cuda:0
[Step 571] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 571] GPU 1 memory: 33.77 GB (reserved: 48.09 GB)
[Step 571] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 571] Student model device: cuda:1
[Step 571] GPU 0 memory before teacher forward: 16.39 GB
[Step 571] GPU 0 memory after moving inputs: 16.39 GB
[Step 571] GPU 0 memory after teacher forward: 17.01 GB
[Step 571] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 571] Teacher logits device before move: cuda:0
[Step 571] Target device (student_logits.device): cuda:1
[Step 571] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 571] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 571] GPU 0 memory after del: 16.39 GB
[Step 571] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 571] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 571] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 571] Sequence length: 1024, Batch size: 2
[Step 571] After KL computation - GPU 1: 40.51 GB
[Step 571] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 581] ========== MEMORY DEBUG ==========
[Step 581] Model device: cuda:1
[Step 581] Input device: cuda:1
[Step 581] Teacher model device: cuda:0
[Step 581] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 581] GPU 1 memory: 33.76 GB (reserved: 42.93 GB)
[Step 581] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 581] Student model device: cuda:1
[Step 581] GPU 0 memory before teacher forward: 16.39 GB
[Step 581] GPU 0 memory after moving inputs: 16.39 GB
[Step 581] GPU 0 memory after teacher forward: 17.01 GB
[Step 581] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 581] Teacher logits device before move: cuda:0
[Step 581] Target device (student_logits.device): cuda:1
[Step 581] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 581] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 581] GPU 0 memory after del: 16.39 GB
[Step 581] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 581] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 581] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 581] Sequence length: 1024, Batch size: 2
[Step 581] After KL computation - GPU 1: 40.50 GB
[Step 581] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 591] ========== MEMORY DEBUG ==========
[Step 591] Model device: cuda:1
[Step 591] Input device: cuda:1
[Step 591] Teacher model device: cuda:0
[Step 591] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 591] GPU 1 memory: 33.76 GB (reserved: 47.02 GB)
[Step 591] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 591] Student model device: cuda:1
[Step 591] GPU 0 memory before teacher forward: 16.39 GB
[Step 591] GPU 0 memory after moving inputs: 16.39 GB
[Step 591] GPU 0 memory after teacher forward: 17.01 GB
[Step 591] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 591] Teacher logits device before move: cuda:0
[Step 591] Target device (student_logits.device): cuda:1
[Step 591] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 591] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 591] GPU 0 memory after del: 16.39 GB
[Step 591] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 591] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 591] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 591] Sequence length: 1024, Batch size: 2
[Step 591] After KL computation - GPU 1: 40.50 GB
[Step 591] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 601] ========== MEMORY DEBUG ==========
[Step 601] Model device: cuda:1
[Step 601] Input device: cuda:1
[Step 601] Teacher model device: cuda:0
[Step 601] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 601] GPU 1 memory: 33.76 GB (reserved: 40.03 GB)
[Step 601] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 601] Student model device: cuda:1
[Step 601] GPU 0 memory before teacher forward: 16.39 GB
[Step 601] GPU 0 memory after moving inputs: 16.39 GB
[Step 601] GPU 0 memory after teacher forward: 17.01 GB
[Step 601] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 601] Teacher logits device before move: cuda:0
[Step 601] Target device (student_logits.device): cuda:1
[Step 601] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 601] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 601] GPU 0 memory after del: 16.39 GB
[Step 601] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 601] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 601] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 601] Sequence length: 1024, Batch size: 2
[Step 601] After KL computation - GPU 1: 40.50 GB
[Step 601] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 611] ========== MEMORY DEBUG ==========
[Step 611] Model device: cuda:1
[Step 611] Input device: cuda:1
[Step 611] Teacher model device: cuda:0
[Step 611] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 611] GPU 1 memory: 33.76 GB (reserved: 47.59 GB)
[Step 611] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 611] Student model device: cuda:1
[Step 611] GPU 0 memory before teacher forward: 16.39 GB
[Step 611] GPU 0 memory after moving inputs: 16.39 GB
[Step 611] GPU 0 memory after teacher forward: 17.01 GB
[Step 611] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 611] Teacher logits device before move: cuda:0
[Step 611] Target device (student_logits.device): cuda:1
[Step 611] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 611] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 611] GPU 0 memory after del: 16.39 GB
[Step 611] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 611] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 611] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 611] Sequence length: 1024, Batch size: 2
[Step 611] After KL computation - GPU 1: 40.50 GB
[Step 611] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 621] ========== MEMORY DEBUG ==========
[Step 621] Model device: cuda:1
[Step 621] Input device: cuda:1
[Step 621] Teacher model device: cuda:0
[Step 621] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 621] GPU 1 memory: 33.76 GB (reserved: 43.55 GB)
[Step 621] Student logits device: cuda:1, shape: torch.Size([2, 973, 151936]), dtype: torch.float32
[Step 621] Student model device: cuda:1
[Step 621] GPU 0 memory before teacher forward: 16.39 GB
[Step 621] GPU 0 memory after moving inputs: 16.39 GB
[Step 621] GPU 0 memory after teacher forward: 16.98 GB
[Step 621] Teacher logits shape: torch.Size([2, 973, 151936]), dtype: torch.float16
[Step 621] Teacher logits device before move: cuda:0
[Step 621] Target device (student_logits.device): cuda:1
[Step 621] GPU 0 memory after moving logits to GPU 1: 16.98 GB
[Step 621] Teacher logits device after move: cuda:1, shape: torch.Size([2, 973, 151936])
[Step 621] GPU 0 memory after del: 16.39 GB
[Step 621] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 621] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.84 GB
[Step 621] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 621] Sequence length: 973, Batch size: 2
[Step 621] After KL computation - GPU 1: 40.20 GB
[Step 621] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 631] ========== MEMORY DEBUG ==========
[Step 631] Model device: cuda:1
[Step 631] Input device: cuda:1
[Step 631] Teacher model device: cuda:0
[Step 631] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 631] GPU 1 memory: 33.76 GB (reserved: 47.87 GB)
[Step 631] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 631] Student model device: cuda:1
[Step 631] GPU 0 memory before teacher forward: 16.39 GB
[Step 631] GPU 0 memory after moving inputs: 16.39 GB
[Step 631] GPU 0 memory after teacher forward: 17.01 GB
[Step 631] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 631] Teacher logits device before move: cuda:0
[Step 631] Target device (student_logits.device): cuda:1
[Step 631] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 631] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 631] GPU 0 memory after del: 16.39 GB
[Step 631] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 631] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 631] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 631] Sequence length: 1024, Batch size: 2
[Step 631] After KL computation - GPU 1: 40.50 GB
[Step 631] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.0}

[Step 641] ========== MEMORY DEBUG ==========
[Step 641] Model device: cuda:1
[Step 641] Input device: cuda:1
[Step 641] Teacher model device: cuda:0
[Step 641] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 641] GPU 1 memory: 25.33 GB (reserved: 47.78 GB)
[Step 641] Student logits device: cuda:1, shape: torch.Size([2, 748, 151936]), dtype: torch.float32
[Step 641] Student model device: cuda:1
[Step 641] GPU 0 memory before teacher forward: 16.39 GB
[Step 641] GPU 0 memory after moving inputs: 16.39 GB
[Step 641] GPU 0 memory after teacher forward: 16.85 GB
[Step 641] Teacher logits shape: torch.Size([2, 748, 151936]), dtype: torch.float16
[Step 641] Teacher logits device before move: cuda:0
[Step 641] Target device (student_logits.device): cuda:1
[Step 641] GPU 0 memory after moving logits to GPU 1: 16.85 GB
[Step 641] Teacher logits device after move: cuda:1, shape: torch.Size([2, 748, 151936])
[Step 641] GPU 0 memory after del: 16.39 GB
[Step 641] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 641] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.60 GB
[Step 641] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 641] Sequence length: 748, Batch size: 2
[Step 641] After KL computation - GPU 1: 30.42 GB
[Step 641] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 651] ========== MEMORY DEBUG ==========
[Step 651] Model device: cuda:1
[Step 651] Input device: cuda:1
[Step 651] Teacher model device: cuda:0
[Step 651] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 651] GPU 1 memory: 33.77 GB (reserved: 47.78 GB)
[Step 651] Student logits device: cuda:1, shape: torch.Size([2, 722, 151936]), dtype: torch.float32
[Step 651] Student model device: cuda:1
[Step 651] GPU 0 memory before teacher forward: 16.39 GB
[Step 651] GPU 0 memory after moving inputs: 16.39 GB
[Step 651] GPU 0 memory after teacher forward: 16.83 GB
[Step 651] Teacher logits shape: torch.Size([2, 722, 151936]), dtype: torch.float16
[Step 651] Teacher logits device before move: cuda:0
[Step 651] Target device (student_logits.device): cuda:1
[Step 651] GPU 0 memory after moving logits to GPU 1: 16.83 GB
[Step 651] Teacher logits device after move: cuda:1, shape: torch.Size([2, 722, 151936])
[Step 651] GPU 0 memory after del: 16.39 GB
[Step 651] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 651] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.95 GB
[Step 651] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 651] Sequence length: 722, Batch size: 2
[Step 651] After KL computation - GPU 1: 38.70 GB
[Step 651] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 661] ========== MEMORY DEBUG ==========
[Step 661] Model device: cuda:1
[Step 661] Input device: cuda:1
[Step 661] Teacher model device: cuda:0
[Step 661] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 661] GPU 1 memory: 33.77 GB (reserved: 47.90 GB)
[Step 661] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 661] Student model device: cuda:1
[Step 661] GPU 0 memory before teacher forward: 16.39 GB
[Step 661] GPU 0 memory after moving inputs: 16.39 GB
[Step 661] GPU 0 memory after teacher forward: 17.01 GB
[Step 661] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 661] Teacher logits device before move: cuda:0
[Step 661] Target device (student_logits.device): cuda:1
[Step 661] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 661] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 661] GPU 0 memory after del: 16.39 GB
[Step 661] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 661] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 661] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 661] Sequence length: 1024, Batch size: 2
[Step 661] After KL computation - GPU 1: 40.51 GB
[Step 661] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 671] ========== MEMORY DEBUG ==========
[Step 671] Model device: cuda:1
[Step 671] Input device: cuda:1
[Step 671] Teacher model device: cuda:0
[Step 671] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 671] GPU 1 memory: 33.77 GB (reserved: 42.62 GB)
[Step 671] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 671] Student model device: cuda:1
[Step 671] GPU 0 memory before teacher forward: 16.39 GB
[Step 671] GPU 0 memory after moving inputs: 16.39 GB
[Step 671] GPU 0 memory after teacher forward: 17.01 GB
[Step 671] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 671] Teacher logits device before move: cuda:0
[Step 671] Target device (student_logits.device): cuda:1
[Step 671] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 671] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 671] GPU 0 memory after del: 16.39 GB
[Step 671] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 671] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 671] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 671] Sequence length: 1024, Batch size: 2
[Step 671] After KL computation - GPU 1: 40.51 GB
[Step 671] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 681] ========== MEMORY DEBUG ==========
[Step 681] Model device: cuda:1
[Step 681] Input device: cuda:1
[Step 681] Teacher model device: cuda:0
[Step 681] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 681] GPU 1 memory: 33.76 GB (reserved: 47.32 GB)
[Step 681] Student logits device: cuda:1, shape: torch.Size([2, 876, 151936]), dtype: torch.float32
[Step 681] Student model device: cuda:1
[Step 681] GPU 0 memory before teacher forward: 16.39 GB
[Step 681] GPU 0 memory after moving inputs: 16.39 GB
[Step 681] GPU 0 memory after teacher forward: 16.92 GB
[Step 681] Teacher logits shape: torch.Size([2, 876, 151936]), dtype: torch.float16
[Step 681] Teacher logits device before move: cuda:0
[Step 681] Target device (student_logits.device): cuda:1
[Step 681] GPU 0 memory after moving logits to GPU 1: 16.92 GB
[Step 681] Teacher logits device after move: cuda:1, shape: torch.Size([2, 876, 151936])
[Step 681] GPU 0 memory after del: 16.39 GB
[Step 681] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 681] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.49 GB
[Step 681] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 681] Sequence length: 876, Batch size: 2
[Step 681] After KL computation - GPU 1: 39.62 GB
[Step 681] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 691] ========== MEMORY DEBUG ==========
[Step 691] Model device: cuda:1
[Step 691] Input device: cuda:1
[Step 691] Teacher model device: cuda:0
[Step 691] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 691] GPU 1 memory: 33.76 GB (reserved: 47.49 GB)
[Step 691] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 691] Student model device: cuda:1
[Step 691] GPU 0 memory before teacher forward: 16.39 GB
[Step 691] GPU 0 memory after moving inputs: 16.39 GB
[Step 691] GPU 0 memory after teacher forward: 17.01 GB
[Step 691] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 691] Teacher logits device before move: cuda:0
[Step 691] Target device (student_logits.device): cuda:1
[Step 691] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 691] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 691] GPU 0 memory after del: 16.39 GB
[Step 691] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 691] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 691] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 691] Sequence length: 1024, Batch size: 2
[Step 691] After KL computation - GPU 1: 40.50 GB
[Step 691] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 701] ========== MEMORY DEBUG ==========
[Step 701] Model device: cuda:1
[Step 701] Input device: cuda:1
[Step 701] Teacher model device: cuda:0
[Step 701] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 701] GPU 1 memory: 33.76 GB (reserved: 43.82 GB)
[Step 701] Student logits device: cuda:1, shape: torch.Size([2, 580, 151936]), dtype: torch.float32
[Step 701] Student model device: cuda:1
[Step 701] GPU 0 memory before teacher forward: 16.39 GB
[Step 701] GPU 0 memory after moving inputs: 16.39 GB
[Step 701] GPU 0 memory after teacher forward: 16.74 GB
[Step 701] Teacher logits shape: torch.Size([2, 580, 151936]), dtype: torch.float16
[Step 701] Teacher logits device before move: cuda:0
[Step 701] Target device (student_logits.device): cuda:1
[Step 701] GPU 0 memory after moving logits to GPU 1: 16.74 GB
[Step 701] Teacher logits device after move: cuda:1, shape: torch.Size([2, 580, 151936])
[Step 701] GPU 0 memory after del: 16.39 GB
[Step 701] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 701] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.44 GB
[Step 701] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 701] Sequence length: 580, Batch size: 2
[Step 701] After KL computation - GPU 1: 37.85 GB
[Step 701] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 711] ========== MEMORY DEBUG ==========
[Step 711] Model device: cuda:1
[Step 711] Input device: cuda:1
[Step 711] Teacher model device: cuda:0
[Step 711] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 711] GPU 1 memory: 33.76 GB (reserved: 47.29 GB)
[Step 711] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 711] Student model device: cuda:1
[Step 711] GPU 0 memory before teacher forward: 16.39 GB
[Step 711] GPU 0 memory after moving inputs: 16.39 GB
[Step 711] GPU 0 memory after teacher forward: 17.01 GB
[Step 711] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 711] Teacher logits device before move: cuda:0
[Step 711] Target device (student_logits.device): cuda:1
[Step 711] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 711] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 711] GPU 0 memory after del: 16.39 GB
[Step 711] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 711] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 711] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 711] Sequence length: 1024, Batch size: 2
[Step 711] After KL computation - GPU 1: 40.50 GB
[Step 711] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 721] ========== MEMORY DEBUG ==========
[Step 721] Model device: cuda:1
[Step 721] Input device: cuda:1
[Step 721] Teacher model device: cuda:0
[Step 721] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 721] GPU 1 memory: 25.33 GB (reserved: 47.87 GB)
[Step 721] Student logits device: cuda:1, shape: torch.Size([2, 400, 151936]), dtype: torch.float32
[Step 721] Student model device: cuda:1
[Step 721] GPU 0 memory before teacher forward: 16.39 GB
[Step 721] GPU 0 memory after moving inputs: 16.39 GB
[Step 721] GPU 0 memory after teacher forward: 16.64 GB
[Step 721] Teacher logits shape: torch.Size([2, 400, 151936]), dtype: torch.float16
[Step 721] Teacher logits device before move: cuda:0
[Step 721] Target device (student_logits.device): cuda:1
[Step 721] GPU 0 memory after moving logits to GPU 1: 16.64 GB
[Step 721] Teacher logits device after move: cuda:1, shape: torch.Size([2, 400, 151936])
[Step 721] GPU 0 memory after del: 16.39 GB
[Step 721] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 721] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 27.37 GB
[Step 721] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 721] Sequence length: 400, Batch size: 2
[Step 721] After KL computation - GPU 1: 28.34 GB
[Step 721] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 731] ========== MEMORY DEBUG ==========
[Step 731] Model device: cuda:1
[Step 731] Input device: cuda:1
[Step 731] Teacher model device: cuda:0
[Step 731] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 731] GPU 1 memory: 33.77 GB (reserved: 47.51 GB)
[Step 731] Student logits device: cuda:1, shape: torch.Size([2, 604, 151936]), dtype: torch.float32
[Step 731] Student model device: cuda:1
[Step 731] GPU 0 memory before teacher forward: 16.39 GB
[Step 731] GPU 0 memory after moving inputs: 16.39 GB
[Step 731] GPU 0 memory after teacher forward: 16.76 GB
[Step 731] Teacher logits shape: torch.Size([2, 604, 151936]), dtype: torch.float16
[Step 731] Teacher logits device before move: cuda:0
[Step 731] Target device (student_logits.device): cuda:1
[Step 731] GPU 0 memory after moving logits to GPU 1: 16.76 GB
[Step 731] Teacher logits device after move: cuda:1, shape: torch.Size([2, 604, 151936])
[Step 731] GPU 0 memory after del: 16.39 GB
[Step 731] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 731] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.53 GB
[Step 731] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 731] Sequence length: 604, Batch size: 2
[Step 731] After KL computation - GPU 1: 38.00 GB
[Step 731] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 741] ========== MEMORY DEBUG ==========
[Step 741] Model device: cuda:1
[Step 741] Input device: cuda:1
[Step 741] Teacher model device: cuda:0
[Step 741] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 741] GPU 1 memory: 33.77 GB (reserved: 47.59 GB)
[Step 741] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 741] Student model device: cuda:1
[Step 741] GPU 0 memory before teacher forward: 16.39 GB
[Step 741] GPU 0 memory after moving inputs: 16.39 GB
[Step 741] GPU 0 memory after teacher forward: 17.01 GB
[Step 741] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 741] Teacher logits device before move: cuda:0
[Step 741] Target device (student_logits.device): cuda:1
[Step 741] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 741] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 741] GPU 0 memory after del: 16.39 GB
[Step 741] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 741] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 741] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 741] Sequence length: 1024, Batch size: 2
[Step 741] After KL computation - GPU 1: 40.51 GB
[Step 741] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 751] ========== MEMORY DEBUG ==========
[Step 751] Model device: cuda:1
[Step 751] Input device: cuda:1
[Step 751] Teacher model device: cuda:0
[Step 751] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 751] GPU 1 memory: 33.77 GB (reserved: 47.57 GB)
[Step 751] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 751] Student model device: cuda:1
[Step 751] GPU 0 memory before teacher forward: 16.39 GB
[Step 751] GPU 0 memory after moving inputs: 16.39 GB
[Step 751] GPU 0 memory after teacher forward: 17.01 GB
[Step 751] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 751] Teacher logits device before move: cuda:0
[Step 751] Target device (student_logits.device): cuda:1
[Step 751] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 751] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 751] GPU 0 memory after del: 16.39 GB
[Step 751] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 751] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 751] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 751] Sequence length: 1024, Batch size: 2
[Step 751] After KL computation - GPU 1: 40.51 GB
[Step 751] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 761] ========== MEMORY DEBUG ==========
[Step 761] Model device: cuda:1
[Step 761] Input device: cuda:1
[Step 761] Teacher model device: cuda:0
[Step 761] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 761] GPU 1 memory: 33.76 GB (reserved: 47.66 GB)
[Step 761] Student logits device: cuda:1, shape: torch.Size([2, 476, 151936]), dtype: torch.float32
[Step 761] Student model device: cuda:1
[Step 761] GPU 0 memory before teacher forward: 16.39 GB
[Step 761] GPU 0 memory after moving inputs: 16.39 GB
[Step 761] GPU 0 memory after teacher forward: 16.68 GB
[Step 761] Teacher logits shape: torch.Size([2, 476, 151936]), dtype: torch.float16
[Step 761] Teacher logits device before move: cuda:0
[Step 761] Target device (student_logits.device): cuda:1
[Step 761] GPU 0 memory after moving logits to GPU 1: 16.68 GB
[Step 761] Teacher logits device after move: cuda:1, shape: torch.Size([2, 476, 151936])
[Step 761] GPU 0 memory after del: 16.39 GB
[Step 761] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 761] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.07 GB
[Step 761] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 761] Sequence length: 476, Batch size: 2
[Step 761] After KL computation - GPU 1: 37.23 GB
[Step 761] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 771] ========== MEMORY DEBUG ==========
[Step 771] Model device: cuda:1
[Step 771] Input device: cuda:1
[Step 771] Teacher model device: cuda:0
[Step 771] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 771] GPU 1 memory: 33.76 GB (reserved: 46.34 GB)
[Step 771] Student logits device: cuda:1, shape: torch.Size([2, 408, 151936]), dtype: torch.float32
[Step 771] Student model device: cuda:1
[Step 771] GPU 0 memory before teacher forward: 16.39 GB
[Step 771] GPU 0 memory after moving inputs: 16.39 GB
[Step 771] GPU 0 memory after teacher forward: 16.64 GB
[Step 771] Teacher logits shape: torch.Size([2, 408, 151936]), dtype: torch.float16
[Step 771] Teacher logits device before move: cuda:0
[Step 771] Target device (student_logits.device): cuda:1
[Step 771] GPU 0 memory after moving logits to GPU 1: 16.64 GB
[Step 771] Teacher logits device after move: cuda:1, shape: torch.Size([2, 408, 151936])
[Step 771] GPU 0 memory after del: 16.39 GB
[Step 771] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 771] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.83 GB
[Step 771] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 771] Sequence length: 408, Batch size: 2
[Step 771] After KL computation - GPU 1: 36.82 GB
[Step 771] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 781] ========== MEMORY DEBUG ==========
[Step 781] Model device: cuda:1
[Step 781] Input device: cuda:1
[Step 781] Teacher model device: cuda:0
[Step 781] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 781] GPU 1 memory: 33.76 GB (reserved: 45.61 GB)
[Step 781] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 781] Student model device: cuda:1
[Step 781] GPU 0 memory before teacher forward: 16.39 GB
[Step 781] GPU 0 memory after moving inputs: 16.39 GB
[Step 781] GPU 0 memory after teacher forward: 17.01 GB
[Step 781] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 781] Teacher logits device before move: cuda:0
[Step 781] Target device (student_logits.device): cuda:1
[Step 781] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 781] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 781] GPU 0 memory after del: 16.39 GB
[Step 781] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 781] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 781] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 781] Sequence length: 1024, Batch size: 2
[Step 781] After KL computation - GPU 1: 40.50 GB
[Step 781] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 791] ========== MEMORY DEBUG ==========
[Step 791] Model device: cuda:1
[Step 791] Input device: cuda:1
[Step 791] Teacher model device: cuda:0
[Step 791] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 791] GPU 1 memory: 33.77 GB (reserved: 43.90 GB)
[Step 791] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 791] Student model device: cuda:1
[Step 791] GPU 0 memory before teacher forward: 16.39 GB
[Step 791] GPU 0 memory after moving inputs: 16.39 GB
[Step 791] GPU 0 memory after teacher forward: 17.01 GB
[Step 791] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 791] Teacher logits device before move: cuda:0
[Step 791] Target device (student_logits.device): cuda:1
[Step 791] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 791] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 791] GPU 0 memory after del: 16.39 GB
[Step 791] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 791] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 791] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 791] Sequence length: 1024, Batch size: 2
[Step 791] After KL computation - GPU 1: 40.51 GB
[Step 791] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.45e-05, 'epoch': 0.01}

[Step 801] ========== MEMORY DEBUG ==========
[Step 801] Model device: cuda:1
[Step 801] Input device: cuda:1
[Step 801] Teacher model device: cuda:0
[Step 801] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 801] GPU 1 memory: 25.33 GB (reserved: 44.28 GB)
[Step 801] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 801] Student model device: cuda:1
[Step 801] GPU 0 memory before teacher forward: 16.39 GB
[Step 801] GPU 0 memory after moving inputs: 16.39 GB
[Step 801] GPU 0 memory after teacher forward: 17.01 GB
[Step 801] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 801] Teacher logits device before move: cuda:0
[Step 801] Target device (student_logits.device): cuda:1
[Step 801] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 801] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 801] GPU 0 memory after del: 16.39 GB
[Step 801] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 801] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 801] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 801] Sequence length: 1024, Batch size: 2
[Step 801] After KL computation - GPU 1: 32.07 GB
[Step 801] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 811] ========== MEMORY DEBUG ==========
[Step 811] Model device: cuda:1
[Step 811] Input device: cuda:1
[Step 811] Teacher model device: cuda:0
[Step 811] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 811] GPU 1 memory: 33.76 GB (reserved: 47.56 GB)
[Step 811] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 811] Student model device: cuda:1
[Step 811] GPU 0 memory before teacher forward: 16.39 GB
[Step 811] GPU 0 memory after moving inputs: 16.39 GB
[Step 811] GPU 0 memory after teacher forward: 17.01 GB
[Step 811] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 811] Teacher logits device before move: cuda:0
[Step 811] Target device (student_logits.device): cuda:1
[Step 811] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 811] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 811] GPU 0 memory after del: 16.39 GB
[Step 811] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 811] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 811] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 811] Sequence length: 1024, Batch size: 2
[Step 811] After KL computation - GPU 1: 40.50 GB
[Step 811] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 821] ========== MEMORY DEBUG ==========
[Step 821] Model device: cuda:1
[Step 821] Input device: cuda:1
[Step 821] Teacher model device: cuda:0
[Step 821] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 821] GPU 1 memory: 33.76 GB (reserved: 47.64 GB)
[Step 821] Student logits device: cuda:1, shape: torch.Size([2, 568, 151936]), dtype: torch.float32
[Step 821] Student model device: cuda:1
[Step 821] GPU 0 memory before teacher forward: 16.39 GB
[Step 821] GPU 0 memory after moving inputs: 16.39 GB
[Step 821] GPU 0 memory after teacher forward: 16.74 GB
[Step 821] Teacher logits shape: torch.Size([2, 568, 151936]), dtype: torch.float16
[Step 821] Teacher logits device before move: cuda:0
[Step 821] Target device (student_logits.device): cuda:1
[Step 821] GPU 0 memory after moving logits to GPU 1: 16.74 GB
[Step 821] Teacher logits device after move: cuda:1, shape: torch.Size([2, 568, 151936])
[Step 821] GPU 0 memory after del: 16.39 GB
[Step 821] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 821] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.40 GB
[Step 821] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 821] Sequence length: 568, Batch size: 2
[Step 821] After KL computation - GPU 1: 37.78 GB
[Step 821] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 831] ========== MEMORY DEBUG ==========
[Step 831] Model device: cuda:1
[Step 831] Input device: cuda:1
[Step 831] Teacher model device: cuda:0
[Step 831] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 831] GPU 1 memory: 33.76 GB (reserved: 47.42 GB)
[Step 831] Student logits device: cuda:1, shape: torch.Size([2, 679, 151936]), dtype: torch.float32
[Step 831] Student model device: cuda:1
[Step 831] GPU 0 memory before teacher forward: 16.39 GB
[Step 831] GPU 0 memory after moving inputs: 16.39 GB
[Step 831] GPU 0 memory after teacher forward: 16.81 GB
[Step 831] Teacher logits shape: torch.Size([2, 679, 151936]), dtype: torch.float16
[Step 831] Teacher logits device before move: cuda:0
[Step 831] Target device (student_logits.device): cuda:1
[Step 831] GPU 0 memory after moving logits to GPU 1: 16.81 GB
[Step 831] Teacher logits device after move: cuda:1, shape: torch.Size([2, 679, 151936])
[Step 831] GPU 0 memory after del: 16.39 GB
[Step 831] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 831] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.79 GB
[Step 831] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 831] Sequence length: 679, Batch size: 2
[Step 831] After KL computation - GPU 1: 38.44 GB
[Step 831] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 841] ========== MEMORY DEBUG ==========
[Step 841] Model device: cuda:1
[Step 841] Input device: cuda:1
[Step 841] Teacher model device: cuda:0
[Step 841] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 841] GPU 1 memory: 33.77 GB (reserved: 47.79 GB)
[Step 841] Student logits device: cuda:1, shape: torch.Size([2, 136, 151936]), dtype: torch.float32
[Step 841] Student model device: cuda:1
[Step 841] GPU 0 memory before teacher forward: 16.39 GB
[Step 841] GPU 0 memory after moving inputs: 16.39 GB
[Step 841] GPU 0 memory after teacher forward: 16.47 GB
[Step 841] Teacher logits shape: torch.Size([2, 136, 151936]), dtype: torch.float16
[Step 841] Teacher logits device before move: cuda:0
[Step 841] Target device (student_logits.device): cuda:1
[Step 841] GPU 0 memory after moving logits to GPU 1: 16.47 GB
[Step 841] Teacher logits device after move: cuda:1, shape: torch.Size([2, 136, 151936])
[Step 841] GPU 0 memory after del: 16.39 GB
[Step 841] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 841] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 34.87 GB
[Step 841] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 841] Sequence length: 136, Batch size: 2
[Step 841] After KL computation - GPU 1: 35.20 GB
[Step 841] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 851] ========== MEMORY DEBUG ==========
[Step 851] Model device: cuda:1
[Step 851] Input device: cuda:1
[Step 851] Teacher model device: cuda:0
[Step 851] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 851] GPU 1 memory: 33.76 GB (reserved: 47.56 GB)
[Step 851] Student logits device: cuda:1, shape: torch.Size([2, 508, 151936]), dtype: torch.float32
[Step 851] Student model device: cuda:1
[Step 851] GPU 0 memory before teacher forward: 16.39 GB
[Step 851] GPU 0 memory after moving inputs: 16.39 GB
[Step 851] GPU 0 memory after teacher forward: 16.70 GB
[Step 851] Teacher logits shape: torch.Size([2, 508, 151936]), dtype: torch.float16
[Step 851] Teacher logits device before move: cuda:0
[Step 851] Target device (student_logits.device): cuda:1
[Step 851] GPU 0 memory after moving logits to GPU 1: 16.70 GB
[Step 851] Teacher logits device after move: cuda:1, shape: torch.Size([2, 508, 151936])
[Step 851] GPU 0 memory after del: 16.39 GB
[Step 851] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 851] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.18 GB
[Step 851] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 851] Sequence length: 508, Batch size: 2
[Step 851] After KL computation - GPU 1: 37.42 GB
[Step 851] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 861] ========== MEMORY DEBUG ==========
[Step 861] Model device: cuda:1
[Step 861] Input device: cuda:1
[Step 861] Teacher model device: cuda:0
[Step 861] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 861] GPU 1 memory: 33.76 GB (reserved: 47.54 GB)
[Step 861] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 861] Student model device: cuda:1
[Step 861] GPU 0 memory before teacher forward: 16.39 GB
[Step 861] GPU 0 memory after moving inputs: 16.39 GB
[Step 861] GPU 0 memory after teacher forward: 17.01 GB
[Step 861] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 861] Teacher logits device before move: cuda:0
[Step 861] Target device (student_logits.device): cuda:1
[Step 861] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 861] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 861] GPU 0 memory after del: 16.39 GB
[Step 861] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 861] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 861] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 861] Sequence length: 1024, Batch size: 2
[Step 861] After KL computation - GPU 1: 40.50 GB
[Step 861] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 871] ========== MEMORY DEBUG ==========
[Step 871] Model device: cuda:1
[Step 871] Input device: cuda:1
[Step 871] Teacher model device: cuda:0
[Step 871] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 871] GPU 1 memory: 33.76 GB (reserved: 47.80 GB)
[Step 871] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 871] Student model device: cuda:1
[Step 871] GPU 0 memory before teacher forward: 16.39 GB
[Step 871] GPU 0 memory after moving inputs: 16.39 GB
[Step 871] GPU 0 memory after teacher forward: 17.01 GB
[Step 871] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 871] Teacher logits device before move: cuda:0
[Step 871] Target device (student_logits.device): cuda:1
[Step 871] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 871] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 871] GPU 0 memory after del: 16.39 GB
[Step 871] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 871] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 871] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 871] Sequence length: 1024, Batch size: 2
[Step 871] After KL computation - GPU 1: 40.50 GB
[Step 871] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 881] ========== MEMORY DEBUG ==========
[Step 881] Model device: cuda:1
[Step 881] Input device: cuda:1
[Step 881] Teacher model device: cuda:0
[Step 881] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 881] GPU 1 memory: 25.33 GB (reserved: 47.27 GB)
[Step 881] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 881] Student model device: cuda:1
[Step 881] GPU 0 memory before teacher forward: 16.39 GB
[Step 881] GPU 0 memory after moving inputs: 16.39 GB
[Step 881] GPU 0 memory after teacher forward: 17.01 GB
[Step 881] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 881] Teacher logits device before move: cuda:0
[Step 881] Target device (student_logits.device): cuda:1
[Step 881] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 881] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 881] GPU 0 memory after del: 16.39 GB
[Step 881] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 881] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 881] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 881] Sequence length: 1024, Batch size: 2
[Step 881] After KL computation - GPU 1: 32.07 GB
[Step 881] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 891] ========== MEMORY DEBUG ==========
[Step 891] Model device: cuda:1
[Step 891] Input device: cuda:1
[Step 891] Teacher model device: cuda:0
[Step 891] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 891] GPU 1 memory: 33.76 GB (reserved: 47.49 GB)
[Step 891] Student logits device: cuda:1, shape: torch.Size([2, 755, 151936]), dtype: torch.float32
[Step 891] Student model device: cuda:1
[Step 891] GPU 0 memory before teacher forward: 16.39 GB
[Step 891] GPU 0 memory after moving inputs: 16.39 GB
[Step 891] GPU 0 memory after teacher forward: 16.85 GB
[Step 891] Teacher logits shape: torch.Size([2, 755, 151936]), dtype: torch.float16
[Step 891] Teacher logits device before move: cuda:0
[Step 891] Target device (student_logits.device): cuda:1
[Step 891] GPU 0 memory after moving logits to GPU 1: 16.85 GB
[Step 891] Teacher logits device after move: cuda:1, shape: torch.Size([2, 755, 151936])
[Step 891] GPU 0 memory after del: 16.39 GB
[Step 891] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 891] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.06 GB
[Step 891] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 891] Sequence length: 755, Batch size: 2
[Step 891] After KL computation - GPU 1: 38.90 GB
[Step 891] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 901] ========== MEMORY DEBUG ==========
[Step 901] Model device: cuda:1
[Step 901] Input device: cuda:1
[Step 901] Teacher model device: cuda:0
[Step 901] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 901] GPU 1 memory: 33.76 GB (reserved: 47.59 GB)
[Step 901] Student logits device: cuda:1, shape: torch.Size([2, 544, 151936]), dtype: torch.float32
[Step 901] Student model device: cuda:1
[Step 901] GPU 0 memory before teacher forward: 16.39 GB
[Step 901] GPU 0 memory after moving inputs: 16.39 GB
[Step 901] GPU 0 memory after teacher forward: 16.72 GB
[Step 901] Teacher logits shape: torch.Size([2, 544, 151936]), dtype: torch.float16
[Step 901] Teacher logits device before move: cuda:0
[Step 901] Target device (student_logits.device): cuda:1
[Step 901] GPU 0 memory after moving logits to GPU 1: 16.72 GB
[Step 901] Teacher logits device after move: cuda:1, shape: torch.Size([2, 544, 151936])
[Step 901] GPU 0 memory after del: 16.39 GB
[Step 901] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 901] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.31 GB
[Step 901] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 901] Sequence length: 544, Batch size: 2
[Step 901] After KL computation - GPU 1: 37.64 GB
[Step 901] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 911] ========== MEMORY DEBUG ==========
[Step 911] Model device: cuda:1
[Step 911] Input device: cuda:1
[Step 911] Teacher model device: cuda:0
[Step 911] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 911] GPU 1 memory: 33.76 GB (reserved: 47.56 GB)
[Step 911] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 911] Student model device: cuda:1
[Step 911] GPU 0 memory before teacher forward: 16.39 GB
[Step 911] GPU 0 memory after moving inputs: 16.39 GB
[Step 911] GPU 0 memory after teacher forward: 17.01 GB
[Step 911] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 911] Teacher logits device before move: cuda:0
[Step 911] Target device (student_logits.device): cuda:1
[Step 911] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 911] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 911] GPU 0 memory after del: 16.39 GB
[Step 911] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 911] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 911] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 911] Sequence length: 1024, Batch size: 2
[Step 911] After KL computation - GPU 1: 40.50 GB
[Step 911] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 921] ========== MEMORY DEBUG ==========
[Step 921] Model device: cuda:1
[Step 921] Input device: cuda:1
[Step 921] Teacher model device: cuda:0
[Step 921] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 921] GPU 1 memory: 33.77 GB (reserved: 44.33 GB)
[Step 921] Student logits device: cuda:1, shape: torch.Size([2, 242, 151936]), dtype: torch.float32
[Step 921] Student model device: cuda:1
[Step 921] GPU 0 memory before teacher forward: 16.39 GB
[Step 921] GPU 0 memory after moving inputs: 16.39 GB
[Step 921] GPU 0 memory after teacher forward: 16.54 GB
[Step 921] Teacher logits shape: torch.Size([2, 242, 151936]), dtype: torch.float16
[Step 921] Teacher logits device before move: cuda:0
[Step 921] Target device (student_logits.device): cuda:1
[Step 921] GPU 0 memory after moving logits to GPU 1: 16.54 GB
[Step 921] Teacher logits device after move: cuda:1, shape: torch.Size([2, 242, 151936])
[Step 921] GPU 0 memory after del: 16.39 GB
[Step 921] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 921] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.25 GB
[Step 921] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 921] Sequence length: 242, Batch size: 2
[Step 921] After KL computation - GPU 1: 35.84 GB
[Step 921] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 931] ========== MEMORY DEBUG ==========
[Step 931] Model device: cuda:1
[Step 931] Input device: cuda:1
[Step 931] Teacher model device: cuda:0
[Step 931] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 931] GPU 1 memory: 33.77 GB (reserved: 46.02 GB)
[Step 931] Student logits device: cuda:1, shape: torch.Size([2, 635, 151936]), dtype: torch.float32
[Step 931] Student model device: cuda:1
[Step 931] GPU 0 memory before teacher forward: 16.39 GB
[Step 931] GPU 0 memory after moving inputs: 16.39 GB
[Step 931] GPU 0 memory after teacher forward: 16.78 GB
[Step 931] Teacher logits shape: torch.Size([2, 635, 151936]), dtype: torch.float16
[Step 931] Teacher logits device before move: cuda:0
[Step 931] Target device (student_logits.device): cuda:1
[Step 931] GPU 0 memory after moving logits to GPU 1: 16.78 GB
[Step 931] Teacher logits device after move: cuda:1, shape: torch.Size([2, 635, 151936])
[Step 931] GPU 0 memory after del: 16.39 GB
[Step 931] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 931] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.64 GB
[Step 931] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 931] Sequence length: 635, Batch size: 2
[Step 931] After KL computation - GPU 1: 38.18 GB
[Step 931] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 941] ========== MEMORY DEBUG ==========
[Step 941] Model device: cuda:1
[Step 941] Input device: cuda:1
[Step 941] Teacher model device: cuda:0
[Step 941] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 941] GPU 1 memory: 33.77 GB (reserved: 47.71 GB)
[Step 941] Student logits device: cuda:1, shape: torch.Size([2, 906, 151936]), dtype: torch.float32
[Step 941] Student model device: cuda:1
[Step 941] GPU 0 memory before teacher forward: 16.39 GB
[Step 941] GPU 0 memory after moving inputs: 16.39 GB
[Step 941] GPU 0 memory after teacher forward: 16.94 GB
[Step 941] Teacher logits shape: torch.Size([2, 906, 151936]), dtype: torch.float16
[Step 941] Teacher logits device before move: cuda:0
[Step 941] Target device (student_logits.device): cuda:1
[Step 941] GPU 0 memory after moving logits to GPU 1: 16.94 GB
[Step 941] Teacher logits device after move: cuda:1, shape: torch.Size([2, 906, 151936])
[Step 941] GPU 0 memory after del: 16.39 GB
[Step 941] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 941] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.60 GB
[Step 941] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 941] Sequence length: 906, Batch size: 2
[Step 941] After KL computation - GPU 1: 39.80 GB
[Step 941] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 951] ========== MEMORY DEBUG ==========
[Step 951] Model device: cuda:1
[Step 951] Input device: cuda:1
[Step 951] Teacher model device: cuda:0
[Step 951] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 951] GPU 1 memory: 33.77 GB (reserved: 47.63 GB)
[Step 951] Student logits device: cuda:1, shape: torch.Size([2, 900, 151936]), dtype: torch.float32
[Step 951] Student model device: cuda:1
[Step 951] GPU 0 memory before teacher forward: 16.39 GB
[Step 951] GPU 0 memory after moving inputs: 16.39 GB
[Step 951] GPU 0 memory after teacher forward: 16.94 GB
[Step 951] Teacher logits shape: torch.Size([2, 900, 151936]), dtype: torch.float16
[Step 951] Teacher logits device before move: cuda:0
[Step 951] Target device (student_logits.device): cuda:1
[Step 951] GPU 0 memory after moving logits to GPU 1: 16.94 GB
[Step 951] Teacher logits device after move: cuda:1, shape: torch.Size([2, 900, 151936])
[Step 951] GPU 0 memory after del: 16.39 GB
[Step 951] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 951] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.58 GB
[Step 951] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 951] Sequence length: 900, Batch size: 2
[Step 951] After KL computation - GPU 1: 39.76 GB
[Step 951] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.95e-05, 'epoch': 0.01}

[Step 961] ========== MEMORY DEBUG ==========
[Step 961] Model device: cuda:1
[Step 961] Input device: cuda:1
[Step 961] Teacher model device: cuda:0
[Step 961] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 961] GPU 1 memory: 25.33 GB (reserved: 47.43 GB)
[Step 961] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 961] Student model device: cuda:1
[Step 961] GPU 0 memory before teacher forward: 16.39 GB
[Step 961] GPU 0 memory after moving inputs: 16.39 GB
[Step 961] GPU 0 memory after teacher forward: 17.01 GB
[Step 961] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 961] Teacher logits device before move: cuda:0
[Step 961] Target device (student_logits.device): cuda:1
[Step 961] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 961] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 961] GPU 0 memory after del: 16.39 GB
[Step 961] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 961] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 961] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 961] Sequence length: 1024, Batch size: 2
[Step 961] After KL computation - GPU 1: 32.07 GB
[Step 961] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 971] ========== MEMORY DEBUG ==========
[Step 971] Model device: cuda:1
[Step 971] Input device: cuda:1
[Step 971] Teacher model device: cuda:0
[Step 971] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 971] GPU 1 memory: 33.76 GB (reserved: 42.60 GB)
[Step 971] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 971] Student model device: cuda:1
[Step 971] GPU 0 memory before teacher forward: 16.39 GB
[Step 971] GPU 0 memory after moving inputs: 16.39 GB
[Step 971] GPU 0 memory after teacher forward: 17.01 GB
[Step 971] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 971] Teacher logits device before move: cuda:0
[Step 971] Target device (student_logits.device): cuda:1
[Step 971] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 971] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 971] GPU 0 memory after del: 16.39 GB
[Step 971] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 971] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 971] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 971] Sequence length: 1024, Batch size: 2
[Step 971] After KL computation - GPU 1: 40.50 GB
[Step 971] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 981] ========== MEMORY DEBUG ==========
[Step 981] Model device: cuda:1
[Step 981] Input device: cuda:1
[Step 981] Teacher model device: cuda:0
[Step 981] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 981] GPU 1 memory: 33.76 GB (reserved: 46.02 GB)
[Step 981] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 981] Student model device: cuda:1
[Step 981] GPU 0 memory before teacher forward: 16.39 GB
[Step 981] GPU 0 memory after moving inputs: 16.39 GB
[Step 981] GPU 0 memory after teacher forward: 17.01 GB
[Step 981] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 981] Teacher logits device before move: cuda:0
[Step 981] Target device (student_logits.device): cuda:1
[Step 981] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 981] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 981] GPU 0 memory after del: 16.39 GB
[Step 981] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 981] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 981] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 981] Sequence length: 1024, Batch size: 2
[Step 981] After KL computation - GPU 1: 40.50 GB
[Step 981] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 991] ========== MEMORY DEBUG ==========
[Step 991] Model device: cuda:1
[Step 991] Input device: cuda:1
[Step 991] Teacher model device: cuda:0
[Step 991] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 991] GPU 1 memory: 33.76 GB (reserved: 48.01 GB)
[Step 991] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 991] Student model device: cuda:1
[Step 991] GPU 0 memory before teacher forward: 16.39 GB
[Step 991] GPU 0 memory after moving inputs: 16.39 GB
[Step 991] GPU 0 memory after teacher forward: 17.01 GB
[Step 991] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 991] Teacher logits device before move: cuda:0
[Step 991] Target device (student_logits.device): cuda:1
[Step 991] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 991] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 991] GPU 0 memory after del: 16.39 GB
[Step 991] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 991] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 991] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 991] Sequence length: 1024, Batch size: 2
[Step 991] After KL computation - GPU 1: 40.50 GB
[Step 991] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1001] ========== MEMORY DEBUG ==========
[Step 1001] Model device: cuda:1
[Step 1001] Input device: cuda:1
[Step 1001] Teacher model device: cuda:0
[Step 1001] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1001] GPU 1 memory: 33.76 GB (reserved: 40.44 GB)
[Step 1001] Student logits device: cuda:1, shape: torch.Size([2, 671, 151936]), dtype: torch.float32
[Step 1001] Student model device: cuda:1
[Step 1001] GPU 0 memory before teacher forward: 16.39 GB
[Step 1001] GPU 0 memory after moving inputs: 16.39 GB
[Step 1001] GPU 0 memory after teacher forward: 16.80 GB
[Step 1001] Teacher logits shape: torch.Size([2, 671, 151936]), dtype: torch.float16
[Step 1001] Teacher logits device before move: cuda:0
[Step 1001] Target device (student_logits.device): cuda:1
[Step 1001] GPU 0 memory after moving logits to GPU 1: 16.80 GB
[Step 1001] Teacher logits device after move: cuda:1, shape: torch.Size([2, 671, 151936])
[Step 1001] GPU 0 memory after del: 16.39 GB
[Step 1001] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1001] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.76 GB
[Step 1001] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1001] Sequence length: 671, Batch size: 2
[Step 1001] After KL computation - GPU 1: 38.39 GB
[Step 1001] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1011] ========== MEMORY DEBUG ==========
[Step 1011] Model device: cuda:1
[Step 1011] Input device: cuda:1
[Step 1011] Teacher model device: cuda:0
[Step 1011] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1011] GPU 1 memory: 33.76 GB (reserved: 47.56 GB)
[Step 1011] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1011] Student model device: cuda:1
[Step 1011] GPU 0 memory before teacher forward: 16.39 GB
[Step 1011] GPU 0 memory after moving inputs: 16.39 GB
[Step 1011] GPU 0 memory after teacher forward: 17.01 GB
[Step 1011] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1011] Teacher logits device before move: cuda:0
[Step 1011] Target device (student_logits.device): cuda:1
[Step 1011] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1011] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1011] GPU 0 memory after del: 16.39 GB
[Step 1011] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1011] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1011] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1011] Sequence length: 1024, Batch size: 2
[Step 1011] After KL computation - GPU 1: 40.50 GB
[Step 1011] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1021] ========== MEMORY DEBUG ==========
[Step 1021] Model device: cuda:1
[Step 1021] Input device: cuda:1
[Step 1021] Teacher model device: cuda:0
[Step 1021] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1021] GPU 1 memory: 33.76 GB (reserved: 47.76 GB)
[Step 1021] Student logits device: cuda:1, shape: torch.Size([2, 673, 151936]), dtype: torch.float32
[Step 1021] Student model device: cuda:1
[Step 1021] GPU 0 memory before teacher forward: 16.39 GB
[Step 1021] GPU 0 memory after moving inputs: 16.39 GB
[Step 1021] GPU 0 memory after teacher forward: 16.80 GB
[Step 1021] Teacher logits shape: torch.Size([2, 673, 151936]), dtype: torch.float16
[Step 1021] Teacher logits device before move: cuda:0
[Step 1021] Target device (student_logits.device): cuda:1
[Step 1021] GPU 0 memory after moving logits to GPU 1: 16.80 GB
[Step 1021] Teacher logits device after move: cuda:1, shape: torch.Size([2, 673, 151936])
[Step 1021] GPU 0 memory after del: 16.39 GB
[Step 1021] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1021] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.77 GB
[Step 1021] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1021] Sequence length: 673, Batch size: 2
[Step 1021] After KL computation - GPU 1: 38.40 GB
[Step 1021] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1031] ========== MEMORY DEBUG ==========
[Step 1031] Model device: cuda:1
[Step 1031] Input device: cuda:1
[Step 1031] Teacher model device: cuda:0
[Step 1031] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1031] GPU 1 memory: 33.76 GB (reserved: 47.55 GB)
[Step 1031] Student logits device: cuda:1, shape: torch.Size([2, 711, 151936]), dtype: torch.float32
[Step 1031] Student model device: cuda:1
[Step 1031] GPU 0 memory before teacher forward: 16.39 GB
[Step 1031] GPU 0 memory after moving inputs: 16.39 GB
[Step 1031] GPU 0 memory after teacher forward: 16.82 GB
[Step 1031] Teacher logits shape: torch.Size([2, 711, 151936]), dtype: torch.float16
[Step 1031] Teacher logits device before move: cuda:0
[Step 1031] Target device (student_logits.device): cuda:1
[Step 1031] GPU 0 memory after moving logits to GPU 1: 16.82 GB
[Step 1031] Teacher logits device after move: cuda:1, shape: torch.Size([2, 711, 151936])
[Step 1031] GPU 0 memory after del: 16.39 GB
[Step 1031] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1031] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.90 GB
[Step 1031] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1031] Sequence length: 711, Batch size: 2
[Step 1031] After KL computation - GPU 1: 38.63 GB
[Step 1031] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1041] ========== MEMORY DEBUG ==========
[Step 1041] Model device: cuda:1
[Step 1041] Input device: cuda:1
[Step 1041] Teacher model device: cuda:0
[Step 1041] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1041] GPU 1 memory: 25.33 GB (reserved: 47.36 GB)
[Step 1041] Student logits device: cuda:1, shape: torch.Size([2, 449, 151936]), dtype: torch.float32
[Step 1041] Student model device: cuda:1
[Step 1041] GPU 0 memory before teacher forward: 16.39 GB
[Step 1041] GPU 0 memory after moving inputs: 16.39 GB
[Step 1041] GPU 0 memory after teacher forward: 16.67 GB
[Step 1041] Teacher logits shape: torch.Size([2, 449, 151936]), dtype: torch.float16
[Step 1041] Teacher logits device before move: cuda:0
[Step 1041] Target device (student_logits.device): cuda:1
[Step 1041] GPU 0 memory after moving logits to GPU 1: 16.67 GB
[Step 1041] Teacher logits device after move: cuda:1, shape: torch.Size([2, 449, 151936])
[Step 1041] GPU 0 memory after del: 16.39 GB
[Step 1041] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1041] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 27.54 GB
[Step 1041] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1041] Sequence length: 449, Batch size: 2
[Step 1041] After KL computation - GPU 1: 28.63 GB
[Step 1041] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1051] ========== MEMORY DEBUG ==========
[Step 1051] Model device: cuda:1
[Step 1051] Input device: cuda:1
[Step 1051] Teacher model device: cuda:0
[Step 1051] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1051] GPU 1 memory: 33.77 GB (reserved: 46.85 GB)
[Step 1051] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1051] Student model device: cuda:1
[Step 1051] GPU 0 memory before teacher forward: 16.39 GB
[Step 1051] GPU 0 memory after moving inputs: 16.39 GB
[Step 1051] GPU 0 memory after teacher forward: 17.01 GB
[Step 1051] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1051] Teacher logits device before move: cuda:0
[Step 1051] Target device (student_logits.device): cuda:1
[Step 1051] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1051] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1051] GPU 0 memory after del: 16.39 GB
[Step 1051] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1051] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1051] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1051] Sequence length: 1024, Batch size: 2
[Step 1051] After KL computation - GPU 1: 40.51 GB
[Step 1051] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1061] ========== MEMORY DEBUG ==========
[Step 1061] Model device: cuda:1
[Step 1061] Input device: cuda:1
[Step 1061] Teacher model device: cuda:0
[Step 1061] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1061] GPU 1 memory: 33.76 GB (reserved: 47.87 GB)
[Step 1061] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1061] Student model device: cuda:1
[Step 1061] GPU 0 memory before teacher forward: 16.39 GB
[Step 1061] GPU 0 memory after moving inputs: 16.39 GB
[Step 1061] GPU 0 memory after teacher forward: 17.01 GB
[Step 1061] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1061] Teacher logits device before move: cuda:0
[Step 1061] Target device (student_logits.device): cuda:1
[Step 1061] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1061] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1061] GPU 0 memory after del: 16.39 GB
[Step 1061] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1061] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1061] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1061] Sequence length: 1024, Batch size: 2
[Step 1061] After KL computation - GPU 1: 40.50 GB
[Step 1061] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1071] ========== MEMORY DEBUG ==========
[Step 1071] Model device: cuda:1
[Step 1071] Input device: cuda:1
[Step 1071] Teacher model device: cuda:0
[Step 1071] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1071] GPU 1 memory: 33.76 GB (reserved: 43.83 GB)
[Step 1071] Student logits device: cuda:1, shape: torch.Size([2, 424, 151936]), dtype: torch.float32
[Step 1071] Student model device: cuda:1
[Step 1071] GPU 0 memory before teacher forward: 16.39 GB
[Step 1071] GPU 0 memory after moving inputs: 16.39 GB
[Step 1071] GPU 0 memory after teacher forward: 16.65 GB
[Step 1071] Teacher logits shape: torch.Size([2, 424, 151936]), dtype: torch.float16
[Step 1071] Teacher logits device before move: cuda:0
[Step 1071] Target device (student_logits.device): cuda:1
[Step 1071] GPU 0 memory after moving logits to GPU 1: 16.65 GB
[Step 1071] Teacher logits device after move: cuda:1, shape: torch.Size([2, 424, 151936])
[Step 1071] GPU 0 memory after del: 16.39 GB
[Step 1071] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1071] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.89 GB
[Step 1071] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1071] Sequence length: 424, Batch size: 2
[Step 1071] After KL computation - GPU 1: 36.92 GB
[Step 1071] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1081] ========== MEMORY DEBUG ==========
[Step 1081] Model device: cuda:1
[Step 1081] Input device: cuda:1
[Step 1081] Teacher model device: cuda:0
[Step 1081] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1081] GPU 1 memory: 33.76 GB (reserved: 47.68 GB)
[Step 1081] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1081] Student model device: cuda:1
[Step 1081] GPU 0 memory before teacher forward: 16.39 GB
[Step 1081] GPU 0 memory after moving inputs: 16.39 GB
[Step 1081] GPU 0 memory after teacher forward: 17.01 GB
[Step 1081] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1081] Teacher logits device before move: cuda:0
[Step 1081] Target device (student_logits.device): cuda:1
[Step 1081] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1081] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1081] GPU 0 memory after del: 16.39 GB
[Step 1081] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1081] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1081] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1081] Sequence length: 1024, Batch size: 2
[Step 1081] After KL computation - GPU 1: 40.50 GB
[Step 1081] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1091] ========== MEMORY DEBUG ==========
[Step 1091] Model device: cuda:1
[Step 1091] Input device: cuda:1
[Step 1091] Teacher model device: cuda:0
[Step 1091] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1091] GPU 1 memory: 33.76 GB (reserved: 43.70 GB)
[Step 1091] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1091] Student model device: cuda:1
[Step 1091] GPU 0 memory before teacher forward: 16.39 GB
[Step 1091] GPU 0 memory after moving inputs: 16.39 GB
[Step 1091] GPU 0 memory after teacher forward: 17.01 GB
[Step 1091] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1091] Teacher logits device before move: cuda:0
[Step 1091] Target device (student_logits.device): cuda:1
[Step 1091] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1091] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1091] GPU 0 memory after del: 16.39 GB
[Step 1091] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1091] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1091] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1091] Sequence length: 1024, Batch size: 2
[Step 1091] After KL computation - GPU 1: 40.50 GB
[Step 1091] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1101] ========== MEMORY DEBUG ==========
[Step 1101] Model device: cuda:1
[Step 1101] Input device: cuda:1
[Step 1101] Teacher model device: cuda:0
[Step 1101] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1101] GPU 1 memory: 33.76 GB (reserved: 42.29 GB)
[Step 1101] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1101] Student model device: cuda:1
[Step 1101] GPU 0 memory before teacher forward: 16.39 GB
[Step 1101] GPU 0 memory after moving inputs: 16.39 GB
[Step 1101] GPU 0 memory after teacher forward: 17.01 GB
[Step 1101] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1101] Teacher logits device before move: cuda:0
[Step 1101] Target device (student_logits.device): cuda:1
[Step 1101] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1101] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1101] GPU 0 memory after del: 16.39 GB
[Step 1101] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1101] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1101] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1101] Sequence length: 1024, Batch size: 2
[Step 1101] After KL computation - GPU 1: 40.50 GB
[Step 1101] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1111] ========== MEMORY DEBUG ==========
[Step 1111] Model device: cuda:1
[Step 1111] Input device: cuda:1
[Step 1111] Teacher model device: cuda:0
[Step 1111] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1111] GPU 1 memory: 33.76 GB (reserved: 47.98 GB)
[Step 1111] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1111] Student model device: cuda:1
[Step 1111] GPU 0 memory before teacher forward: 16.39 GB
[Step 1111] GPU 0 memory after moving inputs: 16.39 GB
[Step 1111] GPU 0 memory after teacher forward: 17.01 GB
[Step 1111] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1111] Teacher logits device before move: cuda:0
[Step 1111] Target device (student_logits.device): cuda:1
[Step 1111] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1111] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1111] GPU 0 memory after del: 16.39 GB
[Step 1111] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1111] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1111] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1111] Sequence length: 1024, Batch size: 2
[Step 1111] After KL computation - GPU 1: 40.50 GB
[Step 1111] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 3895497169305.6, 'grad_norm': nan, 'learning_rate': 3.45e-05, 'epoch': 0.01}

[Step 1121] ========== MEMORY DEBUG ==========
[Step 1121] Model device: cuda:1
[Step 1121] Input device: cuda:1
[Step 1121] Teacher model device: cuda:0
[Step 1121] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1121] GPU 1 memory: 25.33 GB (reserved: 46.81 GB)
[Step 1121] Student logits device: cuda:1, shape: torch.Size([2, 1006, 151936]), dtype: torch.float32
[Step 1121] Student model device: cuda:1
[Step 1121] GPU 0 memory before teacher forward: 16.39 GB
[Step 1121] GPU 0 memory after moving inputs: 16.39 GB
[Step 1121] GPU 0 memory after teacher forward: 17.00 GB
[Step 1121] Teacher logits shape: torch.Size([2, 1006, 151936]), dtype: torch.float16
[Step 1121] Teacher logits device before move: cuda:0
[Step 1121] Target device (student_logits.device): cuda:1
[Step 1121] GPU 0 memory after moving logits to GPU 1: 17.00 GB
[Step 1121] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1006, 151936])
[Step 1121] GPU 0 memory after del: 16.39 GB
[Step 1121] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1121] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.51 GB
[Step 1121] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1121] Sequence length: 1006, Batch size: 2
[Step 1121] After KL computation - GPU 1: 31.96 GB
[Step 1121] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1131] ========== MEMORY DEBUG ==========
[Step 1131] Model device: cuda:1
[Step 1131] Input device: cuda:1
[Step 1131] Teacher model device: cuda:0
[Step 1131] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1131] GPU 1 memory: 33.77 GB (reserved: 47.92 GB)
[Step 1131] Student logits device: cuda:1, shape: torch.Size([2, 326, 151936]), dtype: torch.float32
[Step 1131] Student model device: cuda:1
[Step 1131] GPU 0 memory before teacher forward: 16.39 GB
[Step 1131] GPU 0 memory after moving inputs: 16.39 GB
[Step 1131] GPU 0 memory after teacher forward: 16.59 GB
[Step 1131] Teacher logits shape: torch.Size([2, 326, 151936]), dtype: torch.float16
[Step 1131] Teacher logits device before move: cuda:0
[Step 1131] Target device (student_logits.device): cuda:1
[Step 1131] GPU 0 memory after moving logits to GPU 1: 16.59 GB
[Step 1131] Teacher logits device after move: cuda:1, shape: torch.Size([2, 326, 151936])
[Step 1131] GPU 0 memory after del: 16.39 GB
[Step 1131] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1131] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.55 GB
[Step 1131] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1131] Sequence length: 326, Batch size: 2
[Step 1131] After KL computation - GPU 1: 36.34 GB
[Step 1131] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1141] ========== MEMORY DEBUG ==========
[Step 1141] Model device: cuda:1
[Step 1141] Input device: cuda:1
[Step 1141] Teacher model device: cuda:0
[Step 1141] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1141] GPU 1 memory: 33.76 GB (reserved: 46.07 GB)
[Step 1141] Student logits device: cuda:1, shape: torch.Size([2, 568, 151936]), dtype: torch.float32
[Step 1141] Student model device: cuda:1
[Step 1141] GPU 0 memory before teacher forward: 16.39 GB
[Step 1141] GPU 0 memory after moving inputs: 16.39 GB
[Step 1141] GPU 0 memory after teacher forward: 16.74 GB
[Step 1141] Teacher logits shape: torch.Size([2, 568, 151936]), dtype: torch.float16
[Step 1141] Teacher logits device before move: cuda:0
[Step 1141] Target device (student_logits.device): cuda:1
[Step 1141] GPU 0 memory after moving logits to GPU 1: 16.74 GB
[Step 1141] Teacher logits device after move: cuda:1, shape: torch.Size([2, 568, 151936])
[Step 1141] GPU 0 memory after del: 16.39 GB
[Step 1141] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1141] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.40 GB
[Step 1141] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1141] Sequence length: 568, Batch size: 2
[Step 1141] After KL computation - GPU 1: 37.78 GB
[Step 1141] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1151] ========== MEMORY DEBUG ==========
[Step 1151] Model device: cuda:1
[Step 1151] Input device: cuda:1
[Step 1151] Teacher model device: cuda:0
[Step 1151] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1151] GPU 1 memory: 33.76 GB (reserved: 42.66 GB)
[Step 1151] Student logits device: cuda:1, shape: torch.Size([2, 364, 151936]), dtype: torch.float32
[Step 1151] Student model device: cuda:1
[Step 1151] GPU 0 memory before teacher forward: 16.39 GB
[Step 1151] GPU 0 memory after moving inputs: 16.39 GB
[Step 1151] GPU 0 memory after teacher forward: 16.61 GB
[Step 1151] Teacher logits shape: torch.Size([2, 364, 151936]), dtype: torch.float16
[Step 1151] Teacher logits device before move: cuda:0
[Step 1151] Target device (student_logits.device): cuda:1
[Step 1151] GPU 0 memory after moving logits to GPU 1: 16.61 GB
[Step 1151] Teacher logits device after move: cuda:1, shape: torch.Size([2, 364, 151936])
[Step 1151] GPU 0 memory after del: 16.39 GB
[Step 1151] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1151] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.67 GB
[Step 1151] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1151] Sequence length: 364, Batch size: 2
[Step 1151] After KL computation - GPU 1: 36.56 GB
[Step 1151] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1161] ========== MEMORY DEBUG ==========
[Step 1161] Model device: cuda:1
[Step 1161] Input device: cuda:1
[Step 1161] Teacher model device: cuda:0
[Step 1161] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1161] GPU 1 memory: 33.76 GB (reserved: 47.24 GB)
[Step 1161] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1161] Student model device: cuda:1
[Step 1161] GPU 0 memory before teacher forward: 16.39 GB
[Step 1161] GPU 0 memory after moving inputs: 16.39 GB
[Step 1161] GPU 0 memory after teacher forward: 17.01 GB
[Step 1161] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1161] Teacher logits device before move: cuda:0
[Step 1161] Target device (student_logits.device): cuda:1
[Step 1161] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1161] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1161] GPU 0 memory after del: 16.39 GB
[Step 1161] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1161] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1161] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1161] Sequence length: 1024, Batch size: 2
[Step 1161] After KL computation - GPU 1: 40.50 GB
[Step 1161] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1171] ========== MEMORY DEBUG ==========
[Step 1171] Model device: cuda:1
[Step 1171] Input device: cuda:1
[Step 1171] Teacher model device: cuda:0
[Step 1171] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1171] GPU 1 memory: 33.76 GB (reserved: 47.39 GB)
[Step 1171] Student logits device: cuda:1, shape: torch.Size([2, 445, 151936]), dtype: torch.float32
[Step 1171] Student model device: cuda:1
[Step 1171] GPU 0 memory before teacher forward: 16.39 GB
[Step 1171] GPU 0 memory after moving inputs: 16.39 GB
[Step 1171] GPU 0 memory after teacher forward: 16.66 GB
[Step 1171] Teacher logits shape: torch.Size([2, 445, 151936]), dtype: torch.float16
[Step 1171] Teacher logits device before move: cuda:0
[Step 1171] Target device (student_logits.device): cuda:1
[Step 1171] GPU 0 memory after moving logits to GPU 1: 16.66 GB
[Step 1171] Teacher logits device after move: cuda:1, shape: torch.Size([2, 445, 151936])
[Step 1171] GPU 0 memory after del: 16.39 GB
[Step 1171] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1171] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.96 GB
[Step 1171] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1171] Sequence length: 445, Batch size: 2
[Step 1171] After KL computation - GPU 1: 37.05 GB
[Step 1171] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1181] ========== MEMORY DEBUG ==========
[Step 1181] Model device: cuda:1
[Step 1181] Input device: cuda:1
[Step 1181] Teacher model device: cuda:0
[Step 1181] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1181] GPU 1 memory: 33.76 GB (reserved: 44.87 GB)
[Step 1181] Student logits device: cuda:1, shape: torch.Size([2, 764, 151936]), dtype: torch.float32
[Step 1181] Student model device: cuda:1
[Step 1181] GPU 0 memory before teacher forward: 16.39 GB
[Step 1181] GPU 0 memory after moving inputs: 16.39 GB
[Step 1181] GPU 0 memory after teacher forward: 16.86 GB
[Step 1181] Teacher logits shape: torch.Size([2, 764, 151936]), dtype: torch.float16
[Step 1181] Teacher logits device before move: cuda:0
[Step 1181] Target device (student_logits.device): cuda:1
[Step 1181] GPU 0 memory after moving logits to GPU 1: 16.86 GB
[Step 1181] Teacher logits device after move: cuda:1, shape: torch.Size([2, 764, 151936])
[Step 1181] GPU 0 memory after del: 16.39 GB
[Step 1181] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1181] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.09 GB
[Step 1181] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1181] Sequence length: 764, Batch size: 2
[Step 1181] After KL computation - GPU 1: 38.95 GB
[Step 1181] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1191] ========== MEMORY DEBUG ==========
[Step 1191] Model device: cuda:1
[Step 1191] Input device: cuda:1
[Step 1191] Teacher model device: cuda:0
[Step 1191] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1191] GPU 1 memory: 33.76 GB (reserved: 43.83 GB)
[Step 1191] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1191] Student model device: cuda:1
[Step 1191] GPU 0 memory before teacher forward: 16.39 GB
[Step 1191] GPU 0 memory after moving inputs: 16.39 GB
[Step 1191] GPU 0 memory after teacher forward: 17.01 GB
[Step 1191] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1191] Teacher logits device before move: cuda:0
[Step 1191] Target device (student_logits.device): cuda:1
[Step 1191] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1191] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1191] GPU 0 memory after del: 16.39 GB
[Step 1191] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1191] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1191] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1191] Sequence length: 1024, Batch size: 2
[Step 1191] After KL computation - GPU 1: 40.50 GB
[Step 1191] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1201] ========== MEMORY DEBUG ==========
[Step 1201] Model device: cuda:1
[Step 1201] Input device: cuda:1
[Step 1201] Teacher model device: cuda:0
[Step 1201] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1201] GPU 1 memory: 25.33 GB (reserved: 47.63 GB)
[Step 1201] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1201] Student model device: cuda:1
[Step 1201] GPU 0 memory before teacher forward: 16.39 GB
[Step 1201] GPU 0 memory after moving inputs: 16.39 GB
[Step 1201] GPU 0 memory after teacher forward: 17.01 GB
[Step 1201] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1201] Teacher logits device before move: cuda:0
[Step 1201] Target device (student_logits.device): cuda:1
[Step 1201] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1201] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1201] GPU 0 memory after del: 16.39 GB
[Step 1201] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1201] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 1201] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1201] Sequence length: 1024, Batch size: 2
[Step 1201] After KL computation - GPU 1: 32.07 GB
[Step 1201] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1211] ========== MEMORY DEBUG ==========
[Step 1211] Model device: cuda:1
[Step 1211] Input device: cuda:1
[Step 1211] Teacher model device: cuda:0
[Step 1211] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1211] GPU 1 memory: 33.76 GB (reserved: 47.71 GB)
[Step 1211] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1211] Student model device: cuda:1
[Step 1211] GPU 0 memory before teacher forward: 16.39 GB
[Step 1211] GPU 0 memory after moving inputs: 16.39 GB
[Step 1211] GPU 0 memory after teacher forward: 17.01 GB
[Step 1211] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1211] Teacher logits device before move: cuda:0
[Step 1211] Target device (student_logits.device): cuda:1
[Step 1211] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1211] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1211] GPU 0 memory after del: 16.39 GB
[Step 1211] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1211] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1211] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1211] Sequence length: 1024, Batch size: 2
[Step 1211] After KL computation - GPU 1: 40.50 GB
[Step 1211] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1221] ========== MEMORY DEBUG ==========
[Step 1221] Model device: cuda:1
[Step 1221] Input device: cuda:1
[Step 1221] Teacher model device: cuda:0
[Step 1221] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1221] GPU 1 memory: 33.76 GB (reserved: 44.81 GB)
[Step 1221] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1221] Student model device: cuda:1
[Step 1221] GPU 0 memory before teacher forward: 16.39 GB
[Step 1221] GPU 0 memory after moving inputs: 16.39 GB
[Step 1221] GPU 0 memory after teacher forward: 17.01 GB
[Step 1221] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1221] Teacher logits device before move: cuda:0
[Step 1221] Target device (student_logits.device): cuda:1
[Step 1221] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1221] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1221] GPU 0 memory after del: 16.39 GB
[Step 1221] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1221] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1221] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1221] Sequence length: 1024, Batch size: 2
[Step 1221] After KL computation - GPU 1: 40.50 GB
[Step 1221] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1231] ========== MEMORY DEBUG ==========
[Step 1231] Model device: cuda:1
[Step 1231] Input device: cuda:1
[Step 1231] Teacher model device: cuda:0
[Step 1231] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1231] GPU 1 memory: 33.76 GB (reserved: 47.58 GB)
[Step 1231] Student logits device: cuda:1, shape: torch.Size([2, 417, 151936]), dtype: torch.float32
[Step 1231] Student model device: cuda:1
[Step 1231] GPU 0 memory before teacher forward: 16.39 GB
[Step 1231] GPU 0 memory after moving inputs: 16.39 GB
[Step 1231] GPU 0 memory after teacher forward: 16.65 GB
[Step 1231] Teacher logits shape: torch.Size([2, 417, 151936]), dtype: torch.float16
[Step 1231] Teacher logits device before move: cuda:0
[Step 1231] Target device (student_logits.device): cuda:1
[Step 1231] GPU 0 memory after moving logits to GPU 1: 16.65 GB
[Step 1231] Teacher logits device after move: cuda:1, shape: torch.Size([2, 417, 151936])
[Step 1231] GPU 0 memory after del: 16.39 GB
[Step 1231] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1231] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.86 GB
[Step 1231] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1231] Sequence length: 417, Batch size: 2
[Step 1231] After KL computation - GPU 1: 36.88 GB
[Step 1231] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1241] ========== MEMORY DEBUG ==========
[Step 1241] Model device: cuda:1
[Step 1241] Input device: cuda:1
[Step 1241] Teacher model device: cuda:0
[Step 1241] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1241] GPU 1 memory: 33.76 GB (reserved: 40.63 GB)
[Step 1241] Student logits device: cuda:1, shape: torch.Size([2, 316, 151936]), dtype: torch.float32
[Step 1241] Student model device: cuda:1
[Step 1241] GPU 0 memory before teacher forward: 16.39 GB
[Step 1241] GPU 0 memory after moving inputs: 16.39 GB
[Step 1241] GPU 0 memory after teacher forward: 16.59 GB
[Step 1241] Teacher logits shape: torch.Size([2, 316, 151936]), dtype: torch.float16
[Step 1241] Teacher logits device before move: cuda:0
[Step 1241] Target device (student_logits.device): cuda:1
[Step 1241] GPU 0 memory after moving logits to GPU 1: 16.59 GB
[Step 1241] Teacher logits device after move: cuda:1, shape: torch.Size([2, 316, 151936])
[Step 1241] GPU 0 memory after del: 16.39 GB
[Step 1241] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1241] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.51 GB
[Step 1241] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1241] Sequence length: 316, Batch size: 2
[Step 1241] After KL computation - GPU 1: 36.28 GB
[Step 1241] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1251] ========== MEMORY DEBUG ==========
[Step 1251] Model device: cuda:1
[Step 1251] Input device: cuda:1
[Step 1251] Teacher model device: cuda:0
[Step 1251] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1251] GPU 1 memory: 33.76 GB (reserved: 41.78 GB)
[Step 1251] Student logits device: cuda:1, shape: torch.Size([2, 210, 151936]), dtype: torch.float32
[Step 1251] Student model device: cuda:1
[Step 1251] GPU 0 memory before teacher forward: 16.39 GB
[Step 1251] GPU 0 memory after moving inputs: 16.39 GB
[Step 1251] GPU 0 memory after teacher forward: 16.52 GB
[Step 1251] Teacher logits shape: torch.Size([2, 210, 151936]), dtype: torch.float16
[Step 1251] Teacher logits device before move: cuda:0
[Step 1251] Target device (student_logits.device): cuda:1
[Step 1251] GPU 0 memory after moving logits to GPU 1: 16.52 GB
[Step 1251] Teacher logits device after move: cuda:1, shape: torch.Size([2, 210, 151936])
[Step 1251] GPU 0 memory after del: 16.39 GB
[Step 1251] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1251] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.14 GB
[Step 1251] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1251] Sequence length: 210, Batch size: 2
[Step 1251] After KL computation - GPU 1: 35.66 GB
[Step 1251] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1261] ========== MEMORY DEBUG ==========
[Step 1261] Model device: cuda:1
[Step 1261] Input device: cuda:1
[Step 1261] Teacher model device: cuda:0
[Step 1261] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1261] GPU 1 memory: 33.76 GB (reserved: 47.44 GB)
[Step 1261] Student logits device: cuda:1, shape: torch.Size([2, 878, 151936]), dtype: torch.float32
[Step 1261] Student model device: cuda:1
[Step 1261] GPU 0 memory before teacher forward: 16.39 GB
[Step 1261] GPU 0 memory after moving inputs: 16.39 GB
[Step 1261] GPU 0 memory after teacher forward: 16.93 GB
[Step 1261] Teacher logits shape: torch.Size([2, 878, 151936]), dtype: torch.float16
[Step 1261] Teacher logits device before move: cuda:0
[Step 1261] Target device (student_logits.device): cuda:1
[Step 1261] GPU 0 memory after moving logits to GPU 1: 16.93 GB
[Step 1261] Teacher logits device after move: cuda:1, shape: torch.Size([2, 878, 151936])
[Step 1261] GPU 0 memory after del: 16.39 GB
[Step 1261] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1261] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.49 GB
[Step 1261] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1261] Sequence length: 878, Batch size: 2
[Step 1261] After KL computation - GPU 1: 39.63 GB
[Step 1261] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1271] ========== MEMORY DEBUG ==========
[Step 1271] Model device: cuda:1
[Step 1271] Input device: cuda:1
[Step 1271] Teacher model device: cuda:0
[Step 1271] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1271] GPU 1 memory: 33.77 GB (reserved: 47.81 GB)
[Step 1271] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1271] Student model device: cuda:1
[Step 1271] GPU 0 memory before teacher forward: 16.39 GB
[Step 1271] GPU 0 memory after moving inputs: 16.39 GB
[Step 1271] GPU 0 memory after teacher forward: 17.01 GB
[Step 1271] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1271] Teacher logits device before move: cuda:0
[Step 1271] Target device (student_logits.device): cuda:1
[Step 1271] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1271] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1271] GPU 0 memory after del: 16.39 GB
[Step 1271] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1271] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.03 GB
[Step 1271] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1271] Sequence length: 1024, Batch size: 2
[Step 1271] After KL computation - GPU 1: 40.51 GB
[Step 1271] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.01}

[Step 1281] ========== MEMORY DEBUG ==========
[Step 1281] Model device: cuda:1
[Step 1281] Input device: cuda:1
[Step 1281] Teacher model device: cuda:0
[Step 1281] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1281] GPU 1 memory: 25.33 GB (reserved: 47.46 GB)
[Step 1281] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1281] Student model device: cuda:1
[Step 1281] GPU 0 memory before teacher forward: 16.39 GB
[Step 1281] GPU 0 memory after moving inputs: 16.39 GB
[Step 1281] GPU 0 memory after teacher forward: 17.01 GB
[Step 1281] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1281] Teacher logits device before move: cuda:0
[Step 1281] Target device (student_logits.device): cuda:1
[Step 1281] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1281] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1281] GPU 0 memory after del: 16.39 GB
[Step 1281] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1281] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 1281] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1281] Sequence length: 1024, Batch size: 2
[Step 1281] After KL computation - GPU 1: 32.07 GB
[Step 1281] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1291] ========== MEMORY DEBUG ==========
[Step 1291] Model device: cuda:1
[Step 1291] Input device: cuda:1
[Step 1291] Teacher model device: cuda:0
[Step 1291] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1291] GPU 1 memory: 33.76 GB (reserved: 44.28 GB)
[Step 1291] Student logits device: cuda:1, shape: torch.Size([2, 166, 151936]), dtype: torch.float32
[Step 1291] Student model device: cuda:1
[Step 1291] GPU 0 memory before teacher forward: 16.39 GB
[Step 1291] GPU 0 memory after moving inputs: 16.39 GB
[Step 1291] GPU 0 memory after teacher forward: 16.49 GB
[Step 1291] Teacher logits shape: torch.Size([2, 166, 151936]), dtype: torch.float16
[Step 1291] Teacher logits device before move: cuda:0
[Step 1291] Target device (student_logits.device): cuda:1
[Step 1291] GPU 0 memory after moving logits to GPU 1: 16.49 GB
[Step 1291] Teacher logits device after move: cuda:1, shape: torch.Size([2, 166, 151936])
[Step 1291] GPU 0 memory after del: 16.39 GB
[Step 1291] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1291] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 34.97 GB
[Step 1291] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1291] Sequence length: 166, Batch size: 2
[Step 1291] After KL computation - GPU 1: 35.38 GB
[Step 1291] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1301] ========== MEMORY DEBUG ==========
[Step 1301] Model device: cuda:1
[Step 1301] Input device: cuda:1
[Step 1301] Teacher model device: cuda:0
[Step 1301] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1301] GPU 1 memory: 33.76 GB (reserved: 43.20 GB)
[Step 1301] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1301] Student model device: cuda:1
[Step 1301] GPU 0 memory before teacher forward: 16.39 GB
[Step 1301] GPU 0 memory after moving inputs: 16.39 GB
[Step 1301] GPU 0 memory after teacher forward: 17.01 GB
[Step 1301] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1301] Teacher logits device before move: cuda:0
[Step 1301] Target device (student_logits.device): cuda:1
[Step 1301] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1301] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1301] GPU 0 memory after del: 16.39 GB
[Step 1301] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1301] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1301] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1301] Sequence length: 1024, Batch size: 2
[Step 1301] After KL computation - GPU 1: 40.50 GB
[Step 1301] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1311] ========== MEMORY DEBUG ==========
[Step 1311] Model device: cuda:1
[Step 1311] Input device: cuda:1
[Step 1311] Teacher model device: cuda:0
[Step 1311] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1311] GPU 1 memory: 33.76 GB (reserved: 47.60 GB)
[Step 1311] Student logits device: cuda:1, shape: torch.Size([2, 342, 151936]), dtype: torch.float32
[Step 1311] Student model device: cuda:1
[Step 1311] GPU 0 memory before teacher forward: 16.39 GB
[Step 1311] GPU 0 memory after moving inputs: 16.39 GB
[Step 1311] GPU 0 memory after teacher forward: 16.60 GB
[Step 1311] Teacher logits shape: torch.Size([2, 342, 151936]), dtype: torch.float16
[Step 1311] Teacher logits device before move: cuda:0
[Step 1311] Target device (student_logits.device): cuda:1
[Step 1311] GPU 0 memory after moving logits to GPU 1: 16.60 GB
[Step 1311] Teacher logits device after move: cuda:1, shape: torch.Size([2, 342, 151936])
[Step 1311] GPU 0 memory after del: 16.39 GB
[Step 1311] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1311] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.60 GB
[Step 1311] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1311] Sequence length: 342, Batch size: 2
[Step 1311] After KL computation - GPU 1: 36.43 GB
[Step 1311] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1321] ========== MEMORY DEBUG ==========
[Step 1321] Model device: cuda:1
[Step 1321] Input device: cuda:1
[Step 1321] Teacher model device: cuda:0
[Step 1321] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1321] GPU 1 memory: 33.76 GB (reserved: 45.07 GB)
[Step 1321] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1321] Student model device: cuda:1
[Step 1321] GPU 0 memory before teacher forward: 16.39 GB
[Step 1321] GPU 0 memory after moving inputs: 16.39 GB
[Step 1321] GPU 0 memory after teacher forward: 17.01 GB
[Step 1321] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1321] Teacher logits device before move: cuda:0
[Step 1321] Target device (student_logits.device): cuda:1
[Step 1321] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1321] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1321] GPU 0 memory after del: 16.39 GB
[Step 1321] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1321] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1321] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1321] Sequence length: 1024, Batch size: 2
[Step 1321] After KL computation - GPU 1: 40.50 GB
[Step 1321] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1331] ========== MEMORY DEBUG ==========
[Step 1331] Model device: cuda:1
[Step 1331] Input device: cuda:1
[Step 1331] Teacher model device: cuda:0
[Step 1331] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1331] GPU 1 memory: 33.76 GB (reserved: 42.95 GB)
[Step 1331] Student logits device: cuda:1, shape: torch.Size([2, 405, 151936]), dtype: torch.float32
[Step 1331] Student model device: cuda:1
[Step 1331] GPU 0 memory before teacher forward: 16.39 GB
[Step 1331] GPU 0 memory after moving inputs: 16.39 GB
[Step 1331] GPU 0 memory after teacher forward: 16.64 GB
[Step 1331] Teacher logits shape: torch.Size([2, 405, 151936]), dtype: torch.float16
[Step 1331] Teacher logits device before move: cuda:0
[Step 1331] Target device (student_logits.device): cuda:1
[Step 1331] GPU 0 memory after moving logits to GPU 1: 16.64 GB
[Step 1331] Teacher logits device after move: cuda:1, shape: torch.Size([2, 405, 151936])
[Step 1331] GPU 0 memory after del: 16.39 GB
[Step 1331] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1331] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.82 GB
[Step 1331] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1331] Sequence length: 405, Batch size: 2
[Step 1331] After KL computation - GPU 1: 36.81 GB
[Step 1331] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1341] ========== MEMORY DEBUG ==========
[Step 1341] Model device: cuda:1
[Step 1341] Input device: cuda:1
[Step 1341] Teacher model device: cuda:0
[Step 1341] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1341] GPU 1 memory: 33.76 GB (reserved: 44.23 GB)
[Step 1341] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1341] Student model device: cuda:1
[Step 1341] GPU 0 memory before teacher forward: 16.39 GB
[Step 1341] GPU 0 memory after moving inputs: 16.39 GB
[Step 1341] GPU 0 memory after teacher forward: 17.01 GB
[Step 1341] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1341] Teacher logits device before move: cuda:0
[Step 1341] Target device (student_logits.device): cuda:1
[Step 1341] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1341] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1341] GPU 0 memory after del: 16.39 GB
[Step 1341] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1341] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1341] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1341] Sequence length: 1024, Batch size: 2
[Step 1341] After KL computation - GPU 1: 40.50 GB
[Step 1341] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1351] ========== MEMORY DEBUG ==========
[Step 1351] Model device: cuda:1
[Step 1351] Input device: cuda:1
[Step 1351] Teacher model device: cuda:0
[Step 1351] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1351] GPU 1 memory: 33.77 GB (reserved: 47.98 GB)
[Step 1351] Student logits device: cuda:1, shape: torch.Size([2, 487, 151936]), dtype: torch.float32
[Step 1351] Student model device: cuda:1
[Step 1351] GPU 0 memory before teacher forward: 16.39 GB
[Step 1351] GPU 0 memory after moving inputs: 16.39 GB
[Step 1351] GPU 0 memory after teacher forward: 16.69 GB
[Step 1351] Teacher logits shape: torch.Size([2, 487, 151936]), dtype: torch.float16
[Step 1351] Teacher logits device before move: cuda:0
[Step 1351] Target device (student_logits.device): cuda:1
[Step 1351] GPU 0 memory after moving logits to GPU 1: 16.69 GB
[Step 1351] Teacher logits device after move: cuda:1, shape: torch.Size([2, 487, 151936])
[Step 1351] GPU 0 memory after del: 16.39 GB
[Step 1351] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1351] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.12 GB
[Step 1351] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1351] Sequence length: 487, Batch size: 2
[Step 1351] After KL computation - GPU 1: 37.30 GB
[Step 1351] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1361] ========== MEMORY DEBUG ==========
[Step 1361] Model device: cuda:1
[Step 1361] Input device: cuda:1
[Step 1361] Teacher model device: cuda:0
[Step 1361] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1361] GPU 1 memory: 25.33 GB (reserved: 42.88 GB)
[Step 1361] Student logits device: cuda:1, shape: torch.Size([2, 665, 151936]), dtype: torch.float32
[Step 1361] Student model device: cuda:1
[Step 1361] GPU 0 memory before teacher forward: 16.39 GB
[Step 1361] GPU 0 memory after moving inputs: 16.39 GB
[Step 1361] GPU 0 memory after teacher forward: 16.80 GB
[Step 1361] Teacher logits shape: torch.Size([2, 665, 151936]), dtype: torch.float16
[Step 1361] Teacher logits device before move: cuda:0
[Step 1361] Target device (student_logits.device): cuda:1
[Step 1361] GPU 0 memory after moving logits to GPU 1: 16.80 GB
[Step 1361] Teacher logits device after move: cuda:1, shape: torch.Size([2, 665, 151936])
[Step 1361] GPU 0 memory after del: 16.39 GB
[Step 1361] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1361] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.30 GB
[Step 1361] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1361] Sequence length: 665, Batch size: 2
[Step 1361] After KL computation - GPU 1: 29.92 GB
[Step 1361] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1371] ========== MEMORY DEBUG ==========
[Step 1371] Model device: cuda:1
[Step 1371] Input device: cuda:1
[Step 1371] Teacher model device: cuda:0
[Step 1371] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1371] GPU 1 memory: 33.76 GB (reserved: 47.86 GB)
[Step 1371] Student logits device: cuda:1, shape: torch.Size([2, 558, 151936]), dtype: torch.float32
[Step 1371] Student model device: cuda:1
[Step 1371] GPU 0 memory before teacher forward: 16.39 GB
[Step 1371] GPU 0 memory after moving inputs: 16.39 GB
[Step 1371] GPU 0 memory after teacher forward: 16.73 GB
[Step 1371] Teacher logits shape: torch.Size([2, 558, 151936]), dtype: torch.float16
[Step 1371] Teacher logits device before move: cuda:0
[Step 1371] Target device (student_logits.device): cuda:1
[Step 1371] GPU 0 memory after moving logits to GPU 1: 16.73 GB
[Step 1371] Teacher logits device after move: cuda:1, shape: torch.Size([2, 558, 151936])
[Step 1371] GPU 0 memory after del: 16.39 GB
[Step 1371] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1371] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.36 GB
[Step 1371] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1371] Sequence length: 558, Batch size: 2
[Step 1371] After KL computation - GPU 1: 37.72 GB
[Step 1371] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1381] ========== MEMORY DEBUG ==========
[Step 1381] Model device: cuda:1
[Step 1381] Input device: cuda:1
[Step 1381] Teacher model device: cuda:0
[Step 1381] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1381] GPU 1 memory: 33.76 GB (reserved: 47.26 GB)
[Step 1381] Student logits device: cuda:1, shape: torch.Size([2, 645, 151936]), dtype: torch.float32
[Step 1381] Student model device: cuda:1
[Step 1381] GPU 0 memory before teacher forward: 16.39 GB
[Step 1381] GPU 0 memory after moving inputs: 16.39 GB
[Step 1381] GPU 0 memory after teacher forward: 16.78 GB
[Step 1381] Teacher logits shape: torch.Size([2, 645, 151936]), dtype: torch.float16
[Step 1381] Teacher logits device before move: cuda:0
[Step 1381] Target device (student_logits.device): cuda:1
[Step 1381] GPU 0 memory after moving logits to GPU 1: 16.78 GB
[Step 1381] Teacher logits device after move: cuda:1, shape: torch.Size([2, 645, 151936])
[Step 1381] GPU 0 memory after del: 16.39 GB
[Step 1381] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1381] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.67 GB
[Step 1381] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1381] Sequence length: 645, Batch size: 2
[Step 1381] After KL computation - GPU 1: 38.24 GB
[Step 1381] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1391] ========== MEMORY DEBUG ==========
[Step 1391] Model device: cuda:1
[Step 1391] Input device: cuda:1
[Step 1391] Teacher model device: cuda:0
[Step 1391] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1391] GPU 1 memory: 33.76 GB (reserved: 39.68 GB)
[Step 1391] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1391] Student model device: cuda:1
[Step 1391] GPU 0 memory before teacher forward: 16.39 GB
[Step 1391] GPU 0 memory after moving inputs: 16.39 GB
[Step 1391] GPU 0 memory after teacher forward: 17.01 GB
[Step 1391] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1391] Teacher logits device before move: cuda:0
[Step 1391] Target device (student_logits.device): cuda:1
[Step 1391] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1391] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1391] GPU 0 memory after del: 16.39 GB
[Step 1391] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1391] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1391] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1391] Sequence length: 1024, Batch size: 2
[Step 1391] After KL computation - GPU 1: 40.50 GB
[Step 1391] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1401] ========== MEMORY DEBUG ==========
[Step 1401] Model device: cuda:1
[Step 1401] Input device: cuda:1
[Step 1401] Teacher model device: cuda:0
[Step 1401] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1401] GPU 1 memory: 33.77 GB (reserved: 48.02 GB)
[Step 1401] Student logits device: cuda:1, shape: torch.Size([2, 994, 151936]), dtype: torch.float32
[Step 1401] Student model device: cuda:1
[Step 1401] GPU 0 memory before teacher forward: 16.39 GB
[Step 1401] GPU 0 memory after moving inputs: 16.39 GB
[Step 1401] GPU 0 memory after teacher forward: 17.00 GB
[Step 1401] Teacher logits shape: torch.Size([2, 994, 151936]), dtype: torch.float16
[Step 1401] Teacher logits device before move: cuda:0
[Step 1401] Target device (student_logits.device): cuda:1
[Step 1401] GPU 0 memory after moving logits to GPU 1: 17.00 GB
[Step 1401] Teacher logits device after move: cuda:1, shape: torch.Size([2, 994, 151936])
[Step 1401] GPU 0 memory after del: 16.39 GB
[Step 1401] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1401] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.91 GB
[Step 1401] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1401] Sequence length: 994, Batch size: 2
[Step 1401] After KL computation - GPU 1: 40.33 GB
[Step 1401] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1411] ========== MEMORY DEBUG ==========
[Step 1411] Model device: cuda:1
[Step 1411] Input device: cuda:1
[Step 1411] Teacher model device: cuda:0
[Step 1411] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1411] GPU 1 memory: 33.76 GB (reserved: 39.97 GB)
[Step 1411] Student logits device: cuda:1, shape: torch.Size([2, 470, 151936]), dtype: torch.float32
[Step 1411] Student model device: cuda:1
[Step 1411] GPU 0 memory before teacher forward: 16.39 GB
[Step 1411] GPU 0 memory after moving inputs: 16.39 GB
[Step 1411] GPU 0 memory after teacher forward: 16.68 GB
[Step 1411] Teacher logits shape: torch.Size([2, 470, 151936]), dtype: torch.float16
[Step 1411] Teacher logits device before move: cuda:0
[Step 1411] Target device (student_logits.device): cuda:1
[Step 1411] GPU 0 memory after moving logits to GPU 1: 16.68 GB
[Step 1411] Teacher logits device after move: cuda:1, shape: torch.Size([2, 470, 151936])
[Step 1411] GPU 0 memory after del: 16.39 GB
[Step 1411] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1411] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.05 GB
[Step 1411] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1411] Sequence length: 470, Batch size: 2
[Step 1411] After KL computation - GPU 1: 37.19 GB
[Step 1411] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1421] ========== MEMORY DEBUG ==========
[Step 1421] Model device: cuda:1
[Step 1421] Input device: cuda:1
[Step 1421] Teacher model device: cuda:0
[Step 1421] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1421] GPU 1 memory: 33.76 GB (reserved: 47.71 GB)
[Step 1421] Student logits device: cuda:1, shape: torch.Size([2, 784, 151936]), dtype: torch.float32
[Step 1421] Student model device: cuda:1
[Step 1421] GPU 0 memory before teacher forward: 16.39 GB
[Step 1421] GPU 0 memory after moving inputs: 16.39 GB
[Step 1421] GPU 0 memory after teacher forward: 16.87 GB
[Step 1421] Teacher logits shape: torch.Size([2, 784, 151936]), dtype: torch.float16
[Step 1421] Teacher logits device before move: cuda:0
[Step 1421] Target device (student_logits.device): cuda:1
[Step 1421] GPU 0 memory after moving logits to GPU 1: 16.87 GB
[Step 1421] Teacher logits device after move: cuda:1, shape: torch.Size([2, 784, 151936])
[Step 1421] GPU 0 memory after del: 16.39 GB
[Step 1421] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1421] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.17 GB
[Step 1421] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1421] Sequence length: 784, Batch size: 2
[Step 1421] After KL computation - GPU 1: 39.07 GB
[Step 1421] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1431] ========== MEMORY DEBUG ==========
[Step 1431] Model device: cuda:1
[Step 1431] Input device: cuda:1
[Step 1431] Teacher model device: cuda:0
[Step 1431] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1431] GPU 1 memory: 33.76 GB (reserved: 47.83 GB)
[Step 1431] Student logits device: cuda:1, shape: torch.Size([2, 895, 151936]), dtype: torch.float32
[Step 1431] Student model device: cuda:1
[Step 1431] GPU 0 memory before teacher forward: 16.39 GB
[Step 1431] GPU 0 memory after moving inputs: 16.39 GB
[Step 1431] GPU 0 memory after teacher forward: 16.94 GB
[Step 1431] Teacher logits shape: torch.Size([2, 895, 151936]), dtype: torch.float16
[Step 1431] Teacher logits device before move: cuda:0
[Step 1431] Target device (student_logits.device): cuda:1
[Step 1431] GPU 0 memory after moving logits to GPU 1: 16.94 GB
[Step 1431] Teacher logits device after move: cuda:1, shape: torch.Size([2, 895, 151936])
[Step 1431] GPU 0 memory after del: 16.39 GB
[Step 1431] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1431] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.56 GB
[Step 1431] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1431] Sequence length: 895, Batch size: 2
[Step 1431] After KL computation - GPU 1: 39.73 GB
[Step 1431] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 189454.025, 'grad_norm': nan, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}

[Step 1441] ========== MEMORY DEBUG ==========
[Step 1441] Model device: cuda:1
[Step 1441] Input device: cuda:1
[Step 1441] Teacher model device: cuda:0
[Step 1441] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1441] GPU 1 memory: 25.33 GB (reserved: 44.95 GB)
[Step 1441] Student logits device: cuda:1, shape: torch.Size([2, 816, 151936]), dtype: torch.float32
[Step 1441] Student model device: cuda:1
[Step 1441] GPU 0 memory before teacher forward: 16.39 GB
[Step 1441] GPU 0 memory after moving inputs: 16.39 GB
[Step 1441] GPU 0 memory after teacher forward: 16.89 GB
[Step 1441] Teacher logits shape: torch.Size([2, 816, 151936]), dtype: torch.float16
[Step 1441] Teacher logits device before move: cuda:0
[Step 1441] Target device (student_logits.device): cuda:1
[Step 1441] GPU 0 memory after moving logits to GPU 1: 16.89 GB
[Step 1441] Teacher logits device after move: cuda:1, shape: torch.Size([2, 816, 151936])
[Step 1441] GPU 0 memory after del: 16.39 GB
[Step 1441] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1441] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.84 GB
[Step 1441] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1441] Sequence length: 816, Batch size: 2
[Step 1441] After KL computation - GPU 1: 30.82 GB
[Step 1441] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1451] ========== MEMORY DEBUG ==========
[Step 1451] Model device: cuda:1
[Step 1451] Input device: cuda:1
[Step 1451] Teacher model device: cuda:0
[Step 1451] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1451] GPU 1 memory: 33.76 GB (reserved: 45.66 GB)
[Step 1451] Student logits device: cuda:1, shape: torch.Size([2, 483, 151936]), dtype: torch.float32
[Step 1451] Student model device: cuda:1
[Step 1451] GPU 0 memory before teacher forward: 16.39 GB
[Step 1451] GPU 0 memory after moving inputs: 16.39 GB
[Step 1451] GPU 0 memory after teacher forward: 16.69 GB
[Step 1451] Teacher logits shape: torch.Size([2, 483, 151936]), dtype: torch.float16
[Step 1451] Teacher logits device before move: cuda:0
[Step 1451] Target device (student_logits.device): cuda:1
[Step 1451] GPU 0 memory after moving logits to GPU 1: 16.69 GB
[Step 1451] Teacher logits device after move: cuda:1, shape: torch.Size([2, 483, 151936])
[Step 1451] GPU 0 memory after del: 16.39 GB
[Step 1451] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1451] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.10 GB
[Step 1451] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1451] Sequence length: 483, Batch size: 2
[Step 1451] After KL computation - GPU 1: 37.27 GB
[Step 1451] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1461] ========== MEMORY DEBUG ==========
[Step 1461] Model device: cuda:1
[Step 1461] Input device: cuda:1
[Step 1461] Teacher model device: cuda:0
[Step 1461] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1461] GPU 1 memory: 33.76 GB (reserved: 47.57 GB)
[Step 1461] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1461] Student model device: cuda:1
[Step 1461] GPU 0 memory before teacher forward: 16.39 GB
[Step 1461] GPU 0 memory after moving inputs: 16.39 GB
[Step 1461] GPU 0 memory after teacher forward: 17.01 GB
[Step 1461] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1461] Teacher logits device before move: cuda:0
[Step 1461] Target device (student_logits.device): cuda:1
[Step 1461] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1461] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1461] GPU 0 memory after del: 16.39 GB
[Step 1461] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1461] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1461] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1461] Sequence length: 1024, Batch size: 2
[Step 1461] After KL computation - GPU 1: 40.50 GB
[Step 1461] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1471] ========== MEMORY DEBUG ==========
[Step 1471] Model device: cuda:1
[Step 1471] Input device: cuda:1
[Step 1471] Teacher model device: cuda:0
[Step 1471] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1471] GPU 1 memory: 33.76 GB (reserved: 47.56 GB)
[Step 1471] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1471] Student model device: cuda:1
[Step 1471] GPU 0 memory before teacher forward: 16.39 GB
[Step 1471] GPU 0 memory after moving inputs: 16.39 GB
[Step 1471] GPU 0 memory after teacher forward: 17.01 GB
[Step 1471] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1471] Teacher logits device before move: cuda:0
[Step 1471] Target device (student_logits.device): cuda:1
[Step 1471] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1471] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1471] GPU 0 memory after del: 16.39 GB
[Step 1471] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1471] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1471] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1471] Sequence length: 1024, Batch size: 2
[Step 1471] After KL computation - GPU 1: 40.50 GB
[Step 1471] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1481] ========== MEMORY DEBUG ==========
[Step 1481] Model device: cuda:1
[Step 1481] Input device: cuda:1
[Step 1481] Teacher model device: cuda:0
[Step 1481] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1481] GPU 1 memory: 33.76 GB (reserved: 47.62 GB)
[Step 1481] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1481] Student model device: cuda:1
[Step 1481] GPU 0 memory before teacher forward: 16.39 GB
[Step 1481] GPU 0 memory after moving inputs: 16.39 GB
[Step 1481] GPU 0 memory after teacher forward: 17.01 GB
[Step 1481] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1481] Teacher logits device before move: cuda:0
[Step 1481] Target device (student_logits.device): cuda:1
[Step 1481] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1481] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1481] GPU 0 memory after del: 16.39 GB
[Step 1481] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1481] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1481] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1481] Sequence length: 1024, Batch size: 2
[Step 1481] After KL computation - GPU 1: 40.50 GB
[Step 1481] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1491] ========== MEMORY DEBUG ==========
[Step 1491] Model device: cuda:1
[Step 1491] Input device: cuda:1
[Step 1491] Teacher model device: cuda:0
[Step 1491] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1491] GPU 1 memory: 33.76 GB (reserved: 47.12 GB)
[Step 1491] Student logits device: cuda:1, shape: torch.Size([2, 841, 151936]), dtype: torch.float32
[Step 1491] Student model device: cuda:1
[Step 1491] GPU 0 memory before teacher forward: 16.39 GB
[Step 1491] GPU 0 memory after moving inputs: 16.39 GB
[Step 1491] GPU 0 memory after teacher forward: 16.90 GB
[Step 1491] Teacher logits shape: torch.Size([2, 841, 151936]), dtype: torch.float16
[Step 1491] Teacher logits device before move: cuda:0
[Step 1491] Target device (student_logits.device): cuda:1
[Step 1491] GPU 0 memory after moving logits to GPU 1: 16.90 GB
[Step 1491] Teacher logits device after move: cuda:1, shape: torch.Size([2, 841, 151936])
[Step 1491] GPU 0 memory after del: 16.39 GB
[Step 1491] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1491] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.37 GB
[Step 1491] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1491] Sequence length: 841, Batch size: 2
[Step 1491] After KL computation - GPU 1: 39.41 GB
[Step 1491] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1501] ========== MEMORY DEBUG ==========
[Step 1501] Model device: cuda:1
[Step 1501] Input device: cuda:1
[Step 1501] Teacher model device: cuda:0
[Step 1501] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1501] GPU 1 memory: 33.76 GB (reserved: 47.52 GB)
[Step 1501] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1501] Student model device: cuda:1
[Step 1501] GPU 0 memory before teacher forward: 16.39 GB
[Step 1501] GPU 0 memory after moving inputs: 16.39 GB
[Step 1501] GPU 0 memory after teacher forward: 17.01 GB
[Step 1501] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1501] Teacher logits device before move: cuda:0
[Step 1501] Target device (student_logits.device): cuda:1
[Step 1501] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1501] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1501] GPU 0 memory after del: 16.39 GB
[Step 1501] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1501] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1501] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1501] Sequence length: 1024, Batch size: 2
[Step 1501] After KL computation - GPU 1: 40.50 GB
[Step 1501] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1511] ========== MEMORY DEBUG ==========
[Step 1511] Model device: cuda:1
[Step 1511] Input device: cuda:1
[Step 1511] Teacher model device: cuda:0
[Step 1511] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1511] GPU 1 memory: 33.76 GB (reserved: 47.42 GB)
[Step 1511] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1511] Student model device: cuda:1
[Step 1511] GPU 0 memory before teacher forward: 16.39 GB
[Step 1511] GPU 0 memory after moving inputs: 16.39 GB
[Step 1511] GPU 0 memory after teacher forward: 17.01 GB
[Step 1511] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1511] Teacher logits device before move: cuda:0
[Step 1511] Target device (student_logits.device): cuda:1
[Step 1511] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1511] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1511] GPU 0 memory after del: 16.39 GB
[Step 1511] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1511] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1511] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1511] Sequence length: 1024, Batch size: 2
[Step 1511] After KL computation - GPU 1: 40.50 GB
[Step 1511] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1521] ========== MEMORY DEBUG ==========
[Step 1521] Model device: cuda:1
[Step 1521] Input device: cuda:1
[Step 1521] Teacher model device: cuda:0
[Step 1521] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1521] GPU 1 memory: 25.33 GB (reserved: 47.46 GB)
[Step 1521] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1521] Student model device: cuda:1
[Step 1521] GPU 0 memory before teacher forward: 16.39 GB
[Step 1521] GPU 0 memory after moving inputs: 16.39 GB
[Step 1521] GPU 0 memory after teacher forward: 17.01 GB
[Step 1521] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1521] Teacher logits device before move: cuda:0
[Step 1521] Target device (student_logits.device): cuda:1
[Step 1521] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1521] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1521] GPU 0 memory after del: 16.39 GB
[Step 1521] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1521] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 1521] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1521] Sequence length: 1024, Batch size: 2
[Step 1521] After KL computation - GPU 1: 32.07 GB
[Step 1521] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1531] ========== MEMORY DEBUG ==========
[Step 1531] Model device: cuda:1
[Step 1531] Input device: cuda:1
[Step 1531] Teacher model device: cuda:0
[Step 1531] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1531] GPU 1 memory: 33.76 GB (reserved: 47.54 GB)
[Step 1531] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1531] Student model device: cuda:1
[Step 1531] GPU 0 memory before teacher forward: 16.39 GB
[Step 1531] GPU 0 memory after moving inputs: 16.39 GB
[Step 1531] GPU 0 memory after teacher forward: 17.01 GB
[Step 1531] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1531] Teacher logits device before move: cuda:0
[Step 1531] Target device (student_logits.device): cuda:1
[Step 1531] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1531] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1531] GPU 0 memory after del: 16.39 GB
[Step 1531] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1531] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1531] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1531] Sequence length: 1024, Batch size: 2
[Step 1531] After KL computation - GPU 1: 40.50 GB
[Step 1531] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1541] ========== MEMORY DEBUG ==========
[Step 1541] Model device: cuda:1
[Step 1541] Input device: cuda:1
[Step 1541] Teacher model device: cuda:0
[Step 1541] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1541] GPU 1 memory: 33.76 GB (reserved: 47.39 GB)
[Step 1541] Student logits device: cuda:1, shape: torch.Size([2, 1004, 151936]), dtype: torch.float32
[Step 1541] Student model device: cuda:1
[Step 1541] GPU 0 memory before teacher forward: 16.39 GB
[Step 1541] GPU 0 memory after moving inputs: 16.39 GB
[Step 1541] GPU 0 memory after teacher forward: 17.00 GB
[Step 1541] Teacher logits shape: torch.Size([2, 1004, 151936]), dtype: torch.float16
[Step 1541] Teacher logits device before move: cuda:0
[Step 1541] Target device (student_logits.device): cuda:1
[Step 1541] GPU 0 memory after moving logits to GPU 1: 17.00 GB
[Step 1541] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1004, 151936])
[Step 1541] GPU 0 memory after del: 16.39 GB
[Step 1541] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1541] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.94 GB
[Step 1541] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1541] Sequence length: 1004, Batch size: 2
[Step 1541] After KL computation - GPU 1: 40.38 GB
[Step 1541] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1551] ========== MEMORY DEBUG ==========
[Step 1551] Model device: cuda:1
[Step 1551] Input device: cuda:1
[Step 1551] Teacher model device: cuda:0
[Step 1551] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1551] GPU 1 memory: 33.76 GB (reserved: 42.91 GB)
[Step 1551] Student logits device: cuda:1, shape: torch.Size([2, 203, 151936]), dtype: torch.float32
[Step 1551] Student model device: cuda:1
[Step 1551] GPU 0 memory before teacher forward: 16.39 GB
[Step 1551] GPU 0 memory after moving inputs: 16.39 GB
[Step 1551] GPU 0 memory after teacher forward: 16.52 GB
[Step 1551] Teacher logits shape: torch.Size([2, 203, 151936]), dtype: torch.float16
[Step 1551] Teacher logits device before move: cuda:0
[Step 1551] Target device (student_logits.device): cuda:1
[Step 1551] GPU 0 memory after moving logits to GPU 1: 16.52 GB
[Step 1551] Teacher logits device after move: cuda:1, shape: torch.Size([2, 203, 151936])
[Step 1551] GPU 0 memory after del: 16.39 GB
[Step 1551] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1551] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.12 GB
[Step 1551] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1551] Sequence length: 203, Batch size: 2
[Step 1551] After KL computation - GPU 1: 35.62 GB
[Step 1551] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1561] ========== MEMORY DEBUG ==========
[Step 1561] Model device: cuda:1
[Step 1561] Input device: cuda:1
[Step 1561] Teacher model device: cuda:0
[Step 1561] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1561] GPU 1 memory: 33.77 GB (reserved: 44.12 GB)
[Step 1561] Student logits device: cuda:1, shape: torch.Size([2, 981, 151936]), dtype: torch.float32
[Step 1561] Student model device: cuda:1
[Step 1561] GPU 0 memory before teacher forward: 16.39 GB
[Step 1561] GPU 0 memory after moving inputs: 16.39 GB
[Step 1561] GPU 0 memory after teacher forward: 16.99 GB
[Step 1561] Teacher logits shape: torch.Size([2, 981, 151936]), dtype: torch.float16
[Step 1561] Teacher logits device before move: cuda:0
[Step 1561] Target device (student_logits.device): cuda:1
[Step 1561] GPU 0 memory after moving logits to GPU 1: 16.99 GB
[Step 1561] Teacher logits device after move: cuda:1, shape: torch.Size([2, 981, 151936])
[Step 1561] GPU 0 memory after del: 16.39 GB
[Step 1561] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1561] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.87 GB
[Step 1561] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1561] Sequence length: 981, Batch size: 2
[Step 1561] After KL computation - GPU 1: 40.25 GB
[Step 1561] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1571] ========== MEMORY DEBUG ==========
[Step 1571] Model device: cuda:1
[Step 1571] Input device: cuda:1
[Step 1571] Teacher model device: cuda:0
[Step 1571] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1571] GPU 1 memory: 33.76 GB (reserved: 47.59 GB)
[Step 1571] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1571] Student model device: cuda:1
[Step 1571] GPU 0 memory before teacher forward: 16.39 GB
[Step 1571] GPU 0 memory after moving inputs: 16.39 GB
[Step 1571] GPU 0 memory after teacher forward: 17.01 GB
[Step 1571] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1571] Teacher logits device before move: cuda:0
[Step 1571] Target device (student_logits.device): cuda:1
[Step 1571] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1571] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1571] GPU 0 memory after del: 16.39 GB
[Step 1571] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1571] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1571] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1571] Sequence length: 1024, Batch size: 2
[Step 1571] After KL computation - GPU 1: 40.50 GB
[Step 1571] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1581] ========== MEMORY DEBUG ==========
[Step 1581] Model device: cuda:1
[Step 1581] Input device: cuda:1
[Step 1581] Teacher model device: cuda:0
[Step 1581] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1581] GPU 1 memory: 33.76 GB (reserved: 47.44 GB)
[Step 1581] Student logits device: cuda:1, shape: torch.Size([2, 764, 151936]), dtype: torch.float32
[Step 1581] Student model device: cuda:1
[Step 1581] GPU 0 memory before teacher forward: 16.39 GB
[Step 1581] GPU 0 memory after moving inputs: 16.39 GB
[Step 1581] GPU 0 memory after teacher forward: 16.86 GB
[Step 1581] Teacher logits shape: torch.Size([2, 764, 151936]), dtype: torch.float16
[Step 1581] Teacher logits device before move: cuda:0
[Step 1581] Target device (student_logits.device): cuda:1
[Step 1581] GPU 0 memory after moving logits to GPU 1: 16.86 GB
[Step 1581] Teacher logits device after move: cuda:1, shape: torch.Size([2, 764, 151936])
[Step 1581] GPU 0 memory after del: 16.39 GB
[Step 1581] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1581] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.09 GB
[Step 1581] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1581] Sequence length: 764, Batch size: 2
[Step 1581] After KL computation - GPU 1: 38.95 GB
[Step 1581] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1591] ========== MEMORY DEBUG ==========
[Step 1591] Model device: cuda:1
[Step 1591] Input device: cuda:1
[Step 1591] Teacher model device: cuda:0
[Step 1591] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1591] GPU 1 memory: 33.77 GB (reserved: 48.26 GB)
[Step 1591] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1591] Student model device: cuda:1
[Step 1591] GPU 0 memory before teacher forward: 16.39 GB
[Step 1591] GPU 0 memory after moving inputs: 16.39 GB
[Step 1591] GPU 0 memory after teacher forward: 17.01 GB
[Step 1591] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1591] Teacher logits device before move: cuda:0
[Step 1591] Target device (student_logits.device): cuda:1
[Step 1591] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1591] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1591] GPU 0 memory after del: 16.39 GB
[Step 1591] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1591] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1591] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1591] Sequence length: 1024, Batch size: 2
[Step 1591] After KL computation - GPU 1: 40.51 GB
[Step 1591] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.01}

[Step 1601] ========== MEMORY DEBUG ==========
[Step 1601] Model device: cuda:1
[Step 1601] Input device: cuda:1
[Step 1601] Teacher model device: cuda:0
[Step 1601] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1601] GPU 1 memory: 25.33 GB (reserved: 45.96 GB)
[Step 1601] Student logits device: cuda:1, shape: torch.Size([2, 771, 151936]), dtype: torch.float32
[Step 1601] Student model device: cuda:1
[Step 1601] GPU 0 memory before teacher forward: 16.39 GB
[Step 1601] GPU 0 memory after moving inputs: 16.39 GB
[Step 1601] GPU 0 memory after teacher forward: 16.86 GB
[Step 1601] Teacher logits shape: torch.Size([2, 771, 151936]), dtype: torch.float16
[Step 1601] Teacher logits device before move: cuda:0
[Step 1601] Target device (student_logits.device): cuda:1
[Step 1601] GPU 0 memory after moving logits to GPU 1: 16.86 GB
[Step 1601] Teacher logits device after move: cuda:1, shape: torch.Size([2, 771, 151936])
[Step 1601] GPU 0 memory after del: 16.39 GB
[Step 1601] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1601] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.68 GB
[Step 1601] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1601] Sequence length: 771, Batch size: 2
[Step 1601] After KL computation - GPU 1: 30.56 GB
[Step 1601] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1611] ========== MEMORY DEBUG ==========
[Step 1611] Model device: cuda:1
[Step 1611] Input device: cuda:1
[Step 1611] Teacher model device: cuda:0
[Step 1611] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1611] GPU 1 memory: 33.76 GB (reserved: 47.85 GB)
[Step 1611] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1611] Student model device: cuda:1
[Step 1611] GPU 0 memory before teacher forward: 16.39 GB
[Step 1611] GPU 0 memory after moving inputs: 16.39 GB
[Step 1611] GPU 0 memory after teacher forward: 17.01 GB
[Step 1611] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1611] Teacher logits device before move: cuda:0
[Step 1611] Target device (student_logits.device): cuda:1
[Step 1611] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1611] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1611] GPU 0 memory after del: 16.39 GB
[Step 1611] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1611] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1611] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1611] Sequence length: 1024, Batch size: 2
[Step 1611] After KL computation - GPU 1: 40.50 GB
[Step 1611] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1621] ========== MEMORY DEBUG ==========
[Step 1621] Model device: cuda:1
[Step 1621] Input device: cuda:1
[Step 1621] Teacher model device: cuda:0
[Step 1621] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1621] GPU 1 memory: 33.76 GB (reserved: 41.02 GB)
[Step 1621] Student logits device: cuda:1, shape: torch.Size([2, 237, 151936]), dtype: torch.float32
[Step 1621] Student model device: cuda:1
[Step 1621] GPU 0 memory before teacher forward: 16.39 GB
[Step 1621] GPU 0 memory after moving inputs: 16.39 GB
[Step 1621] GPU 0 memory after teacher forward: 16.54 GB
[Step 1621] Teacher logits shape: torch.Size([2, 237, 151936]), dtype: torch.float16
[Step 1621] Teacher logits device before move: cuda:0
[Step 1621] Target device (student_logits.device): cuda:1
[Step 1621] GPU 0 memory after moving logits to GPU 1: 16.54 GB
[Step 1621] Teacher logits device after move: cuda:1, shape: torch.Size([2, 237, 151936])
[Step 1621] GPU 0 memory after del: 16.39 GB
[Step 1621] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1621] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.23 GB
[Step 1621] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1621] Sequence length: 237, Batch size: 2
[Step 1621] After KL computation - GPU 1: 35.81 GB
[Step 1621] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1631] ========== MEMORY DEBUG ==========
[Step 1631] Model device: cuda:1
[Step 1631] Input device: cuda:1
[Step 1631] Teacher model device: cuda:0
[Step 1631] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1631] GPU 1 memory: 33.76 GB (reserved: 47.74 GB)
[Step 1631] Student logits device: cuda:1, shape: torch.Size([2, 399, 151936]), dtype: torch.float32
[Step 1631] Student model device: cuda:1
[Step 1631] GPU 0 memory before teacher forward: 16.39 GB
[Step 1631] GPU 0 memory after moving inputs: 16.39 GB
[Step 1631] GPU 0 memory after teacher forward: 16.64 GB
[Step 1631] Teacher logits shape: torch.Size([2, 399, 151936]), dtype: torch.float16
[Step 1631] Teacher logits device before move: cuda:0
[Step 1631] Target device (student_logits.device): cuda:1
[Step 1631] GPU 0 memory after moving logits to GPU 1: 16.64 GB
[Step 1631] Teacher logits device after move: cuda:1, shape: torch.Size([2, 399, 151936])
[Step 1631] GPU 0 memory after del: 16.39 GB
[Step 1631] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1631] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.80 GB
[Step 1631] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1631] Sequence length: 399, Batch size: 2
[Step 1631] After KL computation - GPU 1: 36.77 GB
[Step 1631] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1641] ========== MEMORY DEBUG ==========
[Step 1641] Model device: cuda:1
[Step 1641] Input device: cuda:1
[Step 1641] Teacher model device: cuda:0
[Step 1641] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1641] GPU 1 memory: 33.76 GB (reserved: 47.51 GB)
[Step 1641] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1641] Student model device: cuda:1
[Step 1641] GPU 0 memory before teacher forward: 16.39 GB
[Step 1641] GPU 0 memory after moving inputs: 16.39 GB
[Step 1641] GPU 0 memory after teacher forward: 17.01 GB
[Step 1641] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1641] Teacher logits device before move: cuda:0
[Step 1641] Target device (student_logits.device): cuda:1
[Step 1641] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1641] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1641] GPU 0 memory after del: 16.39 GB
[Step 1641] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1641] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1641] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1641] Sequence length: 1024, Batch size: 2
[Step 1641] After KL computation - GPU 1: 40.50 GB
[Step 1641] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1651] ========== MEMORY DEBUG ==========
[Step 1651] Model device: cuda:1
[Step 1651] Input device: cuda:1
[Step 1651] Teacher model device: cuda:0
[Step 1651] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1651] GPU 1 memory: 33.76 GB (reserved: 47.07 GB)
[Step 1651] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1651] Student model device: cuda:1
[Step 1651] GPU 0 memory before teacher forward: 16.39 GB
[Step 1651] GPU 0 memory after moving inputs: 16.39 GB
[Step 1651] GPU 0 memory after teacher forward: 17.01 GB
[Step 1651] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1651] Teacher logits device before move: cuda:0
[Step 1651] Target device (student_logits.device): cuda:1
[Step 1651] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1651] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1651] GPU 0 memory after del: 16.39 GB
[Step 1651] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1651] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1651] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1651] Sequence length: 1024, Batch size: 2
[Step 1651] After KL computation - GPU 1: 40.51 GB
[Step 1651] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1661] ========== MEMORY DEBUG ==========
[Step 1661] Model device: cuda:1
[Step 1661] Input device: cuda:1
[Step 1661] Teacher model device: cuda:0
[Step 1661] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1661] GPU 1 memory: 33.76 GB (reserved: 47.63 GB)
[Step 1661] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1661] Student model device: cuda:1
[Step 1661] GPU 0 memory before teacher forward: 16.39 GB
[Step 1661] GPU 0 memory after moving inputs: 16.39 GB
[Step 1661] GPU 0 memory after teacher forward: 17.01 GB
[Step 1661] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1661] Teacher logits device before move: cuda:0
[Step 1661] Target device (student_logits.device): cuda:1
[Step 1661] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1661] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1661] GPU 0 memory after del: 16.39 GB
[Step 1661] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1661] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1661] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1661] Sequence length: 1024, Batch size: 2
[Step 1661] After KL computation - GPU 1: 40.51 GB
[Step 1661] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1671] ========== MEMORY DEBUG ==========
[Step 1671] Model device: cuda:1
[Step 1671] Input device: cuda:1
[Step 1671] Teacher model device: cuda:0
[Step 1671] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1671] GPU 1 memory: 33.76 GB (reserved: 42.01 GB)
[Step 1671] Student logits device: cuda:1, shape: torch.Size([2, 246, 151936]), dtype: torch.float32
[Step 1671] Student model device: cuda:1
[Step 1671] GPU 0 memory before teacher forward: 16.39 GB
[Step 1671] GPU 0 memory after moving inputs: 16.39 GB
[Step 1671] GPU 0 memory after teacher forward: 16.54 GB
[Step 1671] Teacher logits shape: torch.Size([2, 246, 151936]), dtype: torch.float16
[Step 1671] Teacher logits device before move: cuda:0
[Step 1671] Target device (student_logits.device): cuda:1
[Step 1671] GPU 0 memory after moving logits to GPU 1: 16.54 GB
[Step 1671] Teacher logits device after move: cuda:1, shape: torch.Size([2, 246, 151936])
[Step 1671] GPU 0 memory after del: 16.39 GB
[Step 1671] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1671] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.26 GB
[Step 1671] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1671] Sequence length: 246, Batch size: 2
[Step 1671] After KL computation - GPU 1: 35.86 GB
[Step 1671] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1681] ========== MEMORY DEBUG ==========
[Step 1681] Model device: cuda:1
[Step 1681] Input device: cuda:1
[Step 1681] Teacher model device: cuda:0
[Step 1681] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1681] GPU 1 memory: 25.33 GB (reserved: 47.78 GB)
[Step 1681] Student logits device: cuda:1, shape: torch.Size([2, 623, 151936]), dtype: torch.float32
[Step 1681] Student model device: cuda:1
[Step 1681] GPU 0 memory before teacher forward: 16.39 GB
[Step 1681] GPU 0 memory after moving inputs: 16.39 GB
[Step 1681] GPU 0 memory after teacher forward: 16.77 GB
[Step 1681] Teacher logits shape: torch.Size([2, 623, 151936]), dtype: torch.float16
[Step 1681] Teacher logits device before move: cuda:0
[Step 1681] Target device (student_logits.device): cuda:1
[Step 1681] GPU 0 memory after moving logits to GPU 1: 16.77 GB
[Step 1681] Teacher logits device after move: cuda:1, shape: torch.Size([2, 623, 151936])
[Step 1681] GPU 0 memory after del: 16.39 GB
[Step 1681] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1681] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.16 GB
[Step 1681] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1681] Sequence length: 623, Batch size: 2
[Step 1681] After KL computation - GPU 1: 29.67 GB
[Step 1681] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1691] ========== MEMORY DEBUG ==========
[Step 1691] Model device: cuda:1
[Step 1691] Input device: cuda:1
[Step 1691] Teacher model device: cuda:0
[Step 1691] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1691] GPU 1 memory: 33.76 GB (reserved: 44.30 GB)
[Step 1691] Student logits device: cuda:1, shape: torch.Size([2, 779, 151936]), dtype: torch.float32
[Step 1691] Student model device: cuda:1
[Step 1691] GPU 0 memory before teacher forward: 16.39 GB
[Step 1691] GPU 0 memory after moving inputs: 16.39 GB
[Step 1691] GPU 0 memory after teacher forward: 16.87 GB
[Step 1691] Teacher logits shape: torch.Size([2, 779, 151936]), dtype: torch.float16
[Step 1691] Teacher logits device before move: cuda:0
[Step 1691] Target device (student_logits.device): cuda:1
[Step 1691] GPU 0 memory after moving logits to GPU 1: 16.87 GB
[Step 1691] Teacher logits device after move: cuda:1, shape: torch.Size([2, 779, 151936])
[Step 1691] GPU 0 memory after del: 16.39 GB
[Step 1691] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1691] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.15 GB
[Step 1691] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1691] Sequence length: 779, Batch size: 2
[Step 1691] After KL computation - GPU 1: 39.04 GB
[Step 1691] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1701] ========== MEMORY DEBUG ==========
[Step 1701] Model device: cuda:1
[Step 1701] Input device: cuda:1
[Step 1701] Teacher model device: cuda:0
[Step 1701] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1701] GPU 1 memory: 33.76 GB (reserved: 47.34 GB)
[Step 1701] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1701] Student model device: cuda:1
[Step 1701] GPU 0 memory before teacher forward: 16.39 GB
[Step 1701] GPU 0 memory after moving inputs: 16.39 GB
[Step 1701] GPU 0 memory after teacher forward: 17.01 GB
[Step 1701] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1701] Teacher logits device before move: cuda:0
[Step 1701] Target device (student_logits.device): cuda:1
[Step 1701] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1701] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1701] GPU 0 memory after del: 16.39 GB
[Step 1701] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1701] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1701] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1701] Sequence length: 1024, Batch size: 2
[Step 1701] After KL computation - GPU 1: 40.50 GB
[Step 1701] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1711] ========== MEMORY DEBUG ==========
[Step 1711] Model device: cuda:1
[Step 1711] Input device: cuda:1
[Step 1711] Teacher model device: cuda:0
[Step 1711] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1711] GPU 1 memory: 33.76 GB (reserved: 47.34 GB)
[Step 1711] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1711] Student model device: cuda:1
[Step 1711] GPU 0 memory before teacher forward: 16.39 GB
[Step 1711] GPU 0 memory after moving inputs: 16.39 GB
[Step 1711] GPU 0 memory after teacher forward: 17.01 GB
[Step 1711] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1711] Teacher logits device before move: cuda:0
[Step 1711] Target device (student_logits.device): cuda:1
[Step 1711] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1711] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1711] GPU 0 memory after del: 16.39 GB
[Step 1711] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1711] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1711] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1711] Sequence length: 1024, Batch size: 2
[Step 1711] After KL computation - GPU 1: 40.50 GB
[Step 1711] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1721] ========== MEMORY DEBUG ==========
[Step 1721] Model device: cuda:1
[Step 1721] Input device: cuda:1
[Step 1721] Teacher model device: cuda:0
[Step 1721] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1721] GPU 1 memory: 33.77 GB (reserved: 47.26 GB)
[Step 1721] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1721] Student model device: cuda:1
[Step 1721] GPU 0 memory before teacher forward: 16.39 GB
[Step 1721] GPU 0 memory after moving inputs: 16.39 GB
[Step 1721] GPU 0 memory after teacher forward: 17.01 GB
[Step 1721] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1721] Teacher logits device before move: cuda:0
[Step 1721] Target device (student_logits.device): cuda:1
[Step 1721] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1721] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1721] GPU 0 memory after del: 16.39 GB
[Step 1721] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1721] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1721] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1721] Sequence length: 1024, Batch size: 2
[Step 1721] After KL computation - GPU 1: 40.51 GB
[Step 1721] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1731] ========== MEMORY DEBUG ==========
[Step 1731] Model device: cuda:1
[Step 1731] Input device: cuda:1
[Step 1731] Teacher model device: cuda:0
[Step 1731] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1731] GPU 1 memory: 33.76 GB (reserved: 47.33 GB)
[Step 1731] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1731] Student model device: cuda:1
[Step 1731] GPU 0 memory before teacher forward: 16.39 GB
[Step 1731] GPU 0 memory after moving inputs: 16.39 GB
[Step 1731] GPU 0 memory after teacher forward: 17.01 GB
[Step 1731] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1731] Teacher logits device before move: cuda:0
[Step 1731] Target device (student_logits.device): cuda:1
[Step 1731] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1731] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1731] GPU 0 memory after del: 16.39 GB
[Step 1731] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1731] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1731] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1731] Sequence length: 1024, Batch size: 2
[Step 1731] After KL computation - GPU 1: 40.50 GB
[Step 1731] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1741] ========== MEMORY DEBUG ==========
[Step 1741] Model device: cuda:1
[Step 1741] Input device: cuda:1
[Step 1741] Teacher model device: cuda:0
[Step 1741] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1741] GPU 1 memory: 33.76 GB (reserved: 40.40 GB)
[Step 1741] Student logits device: cuda:1, shape: torch.Size([2, 682, 151936]), dtype: torch.float32
[Step 1741] Student model device: cuda:1
[Step 1741] GPU 0 memory before teacher forward: 16.39 GB
[Step 1741] GPU 0 memory after moving inputs: 16.39 GB
[Step 1741] GPU 0 memory after teacher forward: 16.81 GB
[Step 1741] Teacher logits shape: torch.Size([2, 682, 151936]), dtype: torch.float16
[Step 1741] Teacher logits device before move: cuda:0
[Step 1741] Target device (student_logits.device): cuda:1
[Step 1741] GPU 0 memory after moving logits to GPU 1: 16.81 GB
[Step 1741] Teacher logits device after move: cuda:1, shape: torch.Size([2, 682, 151936])
[Step 1741] GPU 0 memory after del: 16.39 GB
[Step 1741] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1741] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.80 GB
[Step 1741] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1741] Sequence length: 682, Batch size: 2
[Step 1741] After KL computation - GPU 1: 38.46 GB
[Step 1741] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1751] ========== MEMORY DEBUG ==========
[Step 1751] Model device: cuda:1
[Step 1751] Input device: cuda:1
[Step 1751] Teacher model device: cuda:0
[Step 1751] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1751] GPU 1 memory: 33.77 GB (reserved: 47.67 GB)
[Step 1751] Student logits device: cuda:1, shape: torch.Size([2, 331, 151936]), dtype: torch.float32
[Step 1751] Student model device: cuda:1
[Step 1751] GPU 0 memory before teacher forward: 16.39 GB
[Step 1751] GPU 0 memory after moving inputs: 16.39 GB
[Step 1751] GPU 0 memory after teacher forward: 16.59 GB
[Step 1751] Teacher logits shape: torch.Size([2, 331, 151936]), dtype: torch.float16
[Step 1751] Teacher logits device before move: cuda:0
[Step 1751] Target device (student_logits.device): cuda:1
[Step 1751] GPU 0 memory after moving logits to GPU 1: 16.59 GB
[Step 1751] Teacher logits device after move: cuda:1, shape: torch.Size([2, 331, 151936])
[Step 1751] GPU 0 memory after del: 16.39 GB
[Step 1751] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1751] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.58 GB
[Step 1751] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1751] Sequence length: 331, Batch size: 2
[Step 1751] After KL computation - GPU 1: 36.38 GB
[Step 1751] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.995454545454546e-05, 'epoch': 0.01}

[Step 1761] ========== MEMORY DEBUG ==========
[Step 1761] Model device: cuda:1
[Step 1761] Input device: cuda:1
[Step 1761] Teacher model device: cuda:0
[Step 1761] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1761] GPU 1 memory: 25.33 GB (reserved: 47.24 GB)
[Step 1761] Student logits device: cuda:1, shape: torch.Size([2, 664, 151936]), dtype: torch.float32
[Step 1761] Student model device: cuda:1
[Step 1761] GPU 0 memory before teacher forward: 16.39 GB
[Step 1761] GPU 0 memory after moving inputs: 16.39 GB
[Step 1761] GPU 0 memory after teacher forward: 16.80 GB
[Step 1761] Teacher logits shape: torch.Size([2, 664, 151936]), dtype: torch.float16
[Step 1761] Teacher logits device before move: cuda:0
[Step 1761] Target device (student_logits.device): cuda:1
[Step 1761] GPU 0 memory after moving logits to GPU 1: 16.80 GB
[Step 1761] Teacher logits device after move: cuda:1, shape: torch.Size([2, 664, 151936])
[Step 1761] GPU 0 memory after del: 16.39 GB
[Step 1761] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1761] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.30 GB
[Step 1761] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1761] Sequence length: 664, Batch size: 2
[Step 1761] After KL computation - GPU 1: 29.92 GB
[Step 1761] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1771] ========== MEMORY DEBUG ==========
[Step 1771] Model device: cuda:1
[Step 1771] Input device: cuda:1
[Step 1771] Teacher model device: cuda:0
[Step 1771] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1771] GPU 1 memory: 33.76 GB (reserved: 43.29 GB)
[Step 1771] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1771] Student model device: cuda:1
[Step 1771] GPU 0 memory before teacher forward: 16.39 GB
[Step 1771] GPU 0 memory after moving inputs: 16.39 GB
[Step 1771] GPU 0 memory after teacher forward: 17.01 GB
[Step 1771] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1771] Teacher logits device before move: cuda:0
[Step 1771] Target device (student_logits.device): cuda:1
[Step 1771] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1771] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1771] GPU 0 memory after del: 16.39 GB
[Step 1771] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1771] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1771] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1771] Sequence length: 1024, Batch size: 2
[Step 1771] After KL computation - GPU 1: 40.51 GB
[Step 1771] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1781] ========== MEMORY DEBUG ==========
[Step 1781] Model device: cuda:1
[Step 1781] Input device: cuda:1
[Step 1781] Teacher model device: cuda:0
[Step 1781] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1781] GPU 1 memory: 33.76 GB (reserved: 47.60 GB)
[Step 1781] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1781] Student model device: cuda:1
[Step 1781] GPU 0 memory before teacher forward: 16.39 GB
[Step 1781] GPU 0 memory after moving inputs: 16.39 GB
[Step 1781] GPU 0 memory after teacher forward: 17.01 GB
[Step 1781] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1781] Teacher logits device before move: cuda:0
[Step 1781] Target device (student_logits.device): cuda:1
[Step 1781] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1781] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1781] GPU 0 memory after del: 16.39 GB
[Step 1781] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1781] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1781] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1781] Sequence length: 1024, Batch size: 2
[Step 1781] After KL computation - GPU 1: 40.50 GB
[Step 1781] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1791] ========== MEMORY DEBUG ==========
[Step 1791] Model device: cuda:1
[Step 1791] Input device: cuda:1
[Step 1791] Teacher model device: cuda:0
[Step 1791] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1791] GPU 1 memory: 33.76 GB (reserved: 44.55 GB)
[Step 1791] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1791] Student model device: cuda:1
[Step 1791] GPU 0 memory before teacher forward: 16.39 GB
[Step 1791] GPU 0 memory after moving inputs: 16.39 GB
[Step 1791] GPU 0 memory after teacher forward: 17.01 GB
[Step 1791] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1791] Teacher logits device before move: cuda:0
[Step 1791] Target device (student_logits.device): cuda:1
[Step 1791] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1791] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1791] GPU 0 memory after del: 16.39 GB
[Step 1791] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1791] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1791] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1791] Sequence length: 1024, Batch size: 2
[Step 1791] After KL computation - GPU 1: 40.50 GB
[Step 1791] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1801] ========== MEMORY DEBUG ==========
[Step 1801] Model device: cuda:1
[Step 1801] Input device: cuda:1
[Step 1801] Teacher model device: cuda:0
[Step 1801] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1801] GPU 1 memory: 33.77 GB (reserved: 43.26 GB)
[Step 1801] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1801] Student model device: cuda:1
[Step 1801] GPU 0 memory before teacher forward: 16.39 GB
[Step 1801] GPU 0 memory after moving inputs: 16.39 GB
[Step 1801] GPU 0 memory after teacher forward: 17.01 GB
[Step 1801] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1801] Teacher logits device before move: cuda:0
[Step 1801] Target device (student_logits.device): cuda:1
[Step 1801] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1801] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1801] GPU 0 memory after del: 16.39 GB
[Step 1801] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1801] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1801] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1801] Sequence length: 1024, Batch size: 2
[Step 1801] After KL computation - GPU 1: 40.51 GB
[Step 1801] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1811] ========== MEMORY DEBUG ==========
[Step 1811] Model device: cuda:1
[Step 1811] Input device: cuda:1
[Step 1811] Teacher model device: cuda:0
[Step 1811] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1811] GPU 1 memory: 33.76 GB (reserved: 44.84 GB)
[Step 1811] Student logits device: cuda:1, shape: torch.Size([2, 919, 151936]), dtype: torch.float32
[Step 1811] Student model device: cuda:1
[Step 1811] GPU 0 memory before teacher forward: 16.39 GB
[Step 1811] GPU 0 memory after moving inputs: 16.39 GB
[Step 1811] GPU 0 memory after teacher forward: 16.95 GB
[Step 1811] Teacher logits shape: torch.Size([2, 919, 151936]), dtype: torch.float16
[Step 1811] Teacher logits device before move: cuda:0
[Step 1811] Target device (student_logits.device): cuda:1
[Step 1811] GPU 0 memory after moving logits to GPU 1: 16.95 GB
[Step 1811] Teacher logits device after move: cuda:1, shape: torch.Size([2, 919, 151936])
[Step 1811] GPU 0 memory after del: 16.39 GB
[Step 1811] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1811] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.64 GB
[Step 1811] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1811] Sequence length: 919, Batch size: 2
[Step 1811] After KL computation - GPU 1: 39.88 GB
[Step 1811] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1821] ========== MEMORY DEBUG ==========
[Step 1821] Model device: cuda:1
[Step 1821] Input device: cuda:1
[Step 1821] Teacher model device: cuda:0
[Step 1821] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1821] GPU 1 memory: 33.76 GB (reserved: 47.75 GB)
[Step 1821] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1821] Student model device: cuda:1
[Step 1821] GPU 0 memory before teacher forward: 16.39 GB
[Step 1821] GPU 0 memory after moving inputs: 16.39 GB
[Step 1821] GPU 0 memory after teacher forward: 17.01 GB
[Step 1821] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1821] Teacher logits device before move: cuda:0
[Step 1821] Target device (student_logits.device): cuda:1
[Step 1821] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1821] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1821] GPU 0 memory after del: 16.39 GB
[Step 1821] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1821] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1821] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1821] Sequence length: 1024, Batch size: 2
[Step 1821] After KL computation - GPU 1: 40.50 GB
[Step 1821] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1831] ========== MEMORY DEBUG ==========
[Step 1831] Model device: cuda:1
[Step 1831] Input device: cuda:1
[Step 1831] Teacher model device: cuda:0
[Step 1831] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1831] GPU 1 memory: 33.76 GB (reserved: 43.40 GB)
[Step 1831] Student logits device: cuda:1, shape: torch.Size([2, 385, 151936]), dtype: torch.float32
[Step 1831] Student model device: cuda:1
[Step 1831] GPU 0 memory before teacher forward: 16.39 GB
[Step 1831] GPU 0 memory after moving inputs: 16.39 GB
[Step 1831] GPU 0 memory after teacher forward: 16.63 GB
[Step 1831] Teacher logits shape: torch.Size([2, 385, 151936]), dtype: torch.float16
[Step 1831] Teacher logits device before move: cuda:0
[Step 1831] Target device (student_logits.device): cuda:1
[Step 1831] GPU 0 memory after moving logits to GPU 1: 16.63 GB
[Step 1831] Teacher logits device after move: cuda:1, shape: torch.Size([2, 385, 151936])
[Step 1831] GPU 0 memory after del: 16.39 GB
[Step 1831] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1831] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 35.75 GB
[Step 1831] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1831] Sequence length: 385, Batch size: 2
[Step 1831] After KL computation - GPU 1: 36.68 GB
[Step 1831] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1841] ========== MEMORY DEBUG ==========
[Step 1841] Model device: cuda:1
[Step 1841] Input device: cuda:1
[Step 1841] Teacher model device: cuda:0
[Step 1841] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1841] GPU 1 memory: 25.33 GB (reserved: 47.52 GB)
[Step 1841] Student logits device: cuda:1, shape: torch.Size([2, 753, 151936]), dtype: torch.float32
[Step 1841] Student model device: cuda:1
[Step 1841] GPU 0 memory before teacher forward: 16.39 GB
[Step 1841] GPU 0 memory after moving inputs: 16.39 GB
[Step 1841] GPU 0 memory after teacher forward: 16.85 GB
[Step 1841] Teacher logits shape: torch.Size([2, 753, 151936]), dtype: torch.float16
[Step 1841] Teacher logits device before move: cuda:0
[Step 1841] Target device (student_logits.device): cuda:1
[Step 1841] GPU 0 memory after moving logits to GPU 1: 16.85 GB
[Step 1841] Teacher logits device after move: cuda:1, shape: torch.Size([2, 753, 151936])
[Step 1841] GPU 0 memory after del: 16.39 GB
[Step 1841] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1841] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 28.62 GB
[Step 1841] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1841] Sequence length: 753, Batch size: 2
[Step 1841] After KL computation - GPU 1: 30.45 GB
[Step 1841] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1851] ========== MEMORY DEBUG ==========
[Step 1851] Model device: cuda:1
[Step 1851] Input device: cuda:1
[Step 1851] Teacher model device: cuda:0
[Step 1851] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1851] GPU 1 memory: 33.77 GB (reserved: 42.49 GB)
[Step 1851] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1851] Student model device: cuda:1
[Step 1851] GPU 0 memory before teacher forward: 16.39 GB
[Step 1851] GPU 0 memory after moving inputs: 16.39 GB
[Step 1851] GPU 0 memory after teacher forward: 17.01 GB
[Step 1851] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1851] Teacher logits device before move: cuda:0
[Step 1851] Target device (student_logits.device): cuda:1
[Step 1851] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1851] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1851] GPU 0 memory after del: 16.39 GB
[Step 1851] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1851] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1851] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1851] Sequence length: 1024, Batch size: 2
[Step 1851] After KL computation - GPU 1: 40.51 GB
[Step 1851] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1861] ========== MEMORY DEBUG ==========
[Step 1861] Model device: cuda:1
[Step 1861] Input device: cuda:1
[Step 1861] Teacher model device: cuda:0
[Step 1861] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1861] GPU 1 memory: 33.77 GB (reserved: 47.84 GB)
[Step 1861] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1861] Student model device: cuda:1
[Step 1861] GPU 0 memory before teacher forward: 16.39 GB
[Step 1861] GPU 0 memory after moving inputs: 16.39 GB
[Step 1861] GPU 0 memory after teacher forward: 17.01 GB
[Step 1861] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1861] Teacher logits device before move: cuda:0
[Step 1861] Target device (student_logits.device): cuda:1
[Step 1861] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1861] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1861] GPU 0 memory after del: 16.39 GB
[Step 1861] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1861] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1861] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1861] Sequence length: 1024, Batch size: 2
[Step 1861] After KL computation - GPU 1: 40.51 GB
[Step 1861] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1871] ========== MEMORY DEBUG ==========
[Step 1871] Model device: cuda:1
[Step 1871] Input device: cuda:1
[Step 1871] Teacher model device: cuda:0
[Step 1871] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1871] GPU 1 memory: 33.77 GB (reserved: 47.99 GB)
[Step 1871] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1871] Student model device: cuda:1
[Step 1871] GPU 0 memory before teacher forward: 16.39 GB
[Step 1871] GPU 0 memory after moving inputs: 16.39 GB
[Step 1871] GPU 0 memory after teacher forward: 17.01 GB
[Step 1871] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1871] Teacher logits device before move: cuda:0
[Step 1871] Target device (student_logits.device): cuda:1
[Step 1871] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1871] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1871] GPU 0 memory after del: 16.39 GB
[Step 1871] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1871] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1871] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1871] Sequence length: 1024, Batch size: 2
[Step 1871] After KL computation - GPU 1: 40.51 GB
[Step 1871] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1881] ========== MEMORY DEBUG ==========
[Step 1881] Model device: cuda:1
[Step 1881] Input device: cuda:1
[Step 1881] Teacher model device: cuda:0
[Step 1881] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1881] GPU 1 memory: 33.77 GB (reserved: 47.60 GB)
[Step 1881] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1881] Student model device: cuda:1
[Step 1881] GPU 0 memory before teacher forward: 16.39 GB
[Step 1881] GPU 0 memory after moving inputs: 16.39 GB
[Step 1881] GPU 0 memory after teacher forward: 17.01 GB
[Step 1881] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1881] Teacher logits device before move: cuda:0
[Step 1881] Target device (student_logits.device): cuda:1
[Step 1881] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1881] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1881] GPU 0 memory after del: 16.39 GB
[Step 1881] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1881] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.02 GB
[Step 1881] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1881] Sequence length: 1024, Batch size: 2
[Step 1881] After KL computation - GPU 1: 40.51 GB
[Step 1881] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1891] ========== MEMORY DEBUG ==========
[Step 1891] Model device: cuda:1
[Step 1891] Input device: cuda:1
[Step 1891] Teacher model device: cuda:0
[Step 1891] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1891] GPU 1 memory: 33.76 GB (reserved: 46.73 GB)
[Step 1891] Student logits device: cuda:1, shape: torch.Size([2, 145, 151936]), dtype: torch.float32
[Step 1891] Student model device: cuda:1
[Step 1891] GPU 0 memory before teacher forward: 16.39 GB
[Step 1891] GPU 0 memory after moving inputs: 16.39 GB
[Step 1891] GPU 0 memory after teacher forward: 16.48 GB
[Step 1891] Teacher logits shape: torch.Size([2, 145, 151936]), dtype: torch.float16
[Step 1891] Teacher logits device before move: cuda:0
[Step 1891] Target device (student_logits.device): cuda:1
[Step 1891] GPU 0 memory after moving logits to GPU 1: 16.48 GB
[Step 1891] Teacher logits device after move: cuda:1, shape: torch.Size([2, 145, 151936])
[Step 1891] GPU 0 memory after del: 16.39 GB
[Step 1891] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1891] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 34.90 GB
[Step 1891] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1891] Sequence length: 145, Batch size: 2
[Step 1891] After KL computation - GPU 1: 35.25 GB
[Step 1891] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1901] ========== MEMORY DEBUG ==========
[Step 1901] Model device: cuda:1
[Step 1901] Input device: cuda:1
[Step 1901] Teacher model device: cuda:0
[Step 1901] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1901] GPU 1 memory: 33.76 GB (reserved: 47.67 GB)
[Step 1901] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1901] Student model device: cuda:1
[Step 1901] GPU 0 memory before teacher forward: 16.39 GB
[Step 1901] GPU 0 memory after moving inputs: 16.39 GB
[Step 1901] GPU 0 memory after teacher forward: 17.01 GB
[Step 1901] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1901] Teacher logits device before move: cuda:0
[Step 1901] Target device (student_logits.device): cuda:1
[Step 1901] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1901] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1901] GPU 0 memory after del: 16.39 GB
[Step 1901] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1901] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1901] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1901] Sequence length: 1024, Batch size: 2
[Step 1901] After KL computation - GPU 1: 40.50 GB
[Step 1901] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1911] ========== MEMORY DEBUG ==========
[Step 1911] Model device: cuda:1
[Step 1911] Input device: cuda:1
[Step 1911] Teacher model device: cuda:0
[Step 1911] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1911] GPU 1 memory: 33.76 GB (reserved: 47.47 GB)
[Step 1911] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1911] Student model device: cuda:1
[Step 1911] GPU 0 memory before teacher forward: 16.39 GB
[Step 1911] GPU 0 memory after moving inputs: 16.39 GB
[Step 1911] GPU 0 memory after teacher forward: 17.01 GB
[Step 1911] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1911] Teacher logits device before move: cuda:0
[Step 1911] Target device (student_logits.device): cuda:1
[Step 1911] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1911] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1911] GPU 0 memory after del: 16.39 GB
[Step 1911] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1911] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1911] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1911] Sequence length: 1024, Batch size: 2
[Step 1911] After KL computation - GPU 1: 40.50 GB
[Step 1911] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.9904040404040406e-05, 'epoch': 0.01}

[Step 1921] ========== MEMORY DEBUG ==========
[Step 1921] Model device: cuda:1
[Step 1921] Input device: cuda:1
[Step 1921] Teacher model device: cuda:0
[Step 1921] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1921] GPU 1 memory: 25.33 GB (reserved: 42.50 GB)
[Step 1921] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1921] Student model device: cuda:1
[Step 1921] GPU 0 memory before teacher forward: 16.39 GB
[Step 1921] GPU 0 memory after moving inputs: 16.39 GB
[Step 1921] GPU 0 memory after teacher forward: 17.01 GB
[Step 1921] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1921] Teacher logits device before move: cuda:0
[Step 1921] Target device (student_logits.device): cuda:1
[Step 1921] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1921] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1921] GPU 0 memory after del: 16.39 GB
[Step 1921] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1921] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 1921] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1921] Sequence length: 1024, Batch size: 2
[Step 1921] After KL computation - GPU 1: 32.07 GB
[Step 1921] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1931] ========== MEMORY DEBUG ==========
[Step 1931] Model device: cuda:1
[Step 1931] Input device: cuda:1
[Step 1931] Teacher model device: cuda:0
[Step 1931] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1931] GPU 1 memory: 33.76 GB (reserved: 44.50 GB)
[Step 1931] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1931] Student model device: cuda:1
[Step 1931] GPU 0 memory before teacher forward: 16.39 GB
[Step 1931] GPU 0 memory after moving inputs: 16.39 GB
[Step 1931] GPU 0 memory after teacher forward: 17.01 GB
[Step 1931] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1931] Teacher logits device before move: cuda:0
[Step 1931] Target device (student_logits.device): cuda:1
[Step 1931] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1931] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1931] GPU 0 memory after del: 16.39 GB
[Step 1931] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1931] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1931] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1931] Sequence length: 1024, Batch size: 2
[Step 1931] After KL computation - GPU 1: 40.50 GB
[Step 1931] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1941] ========== MEMORY DEBUG ==========
[Step 1941] Model device: cuda:1
[Step 1941] Input device: cuda:1
[Step 1941] Teacher model device: cuda:0
[Step 1941] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1941] GPU 1 memory: 33.76 GB (reserved: 47.63 GB)
[Step 1941] Student logits device: cuda:1, shape: torch.Size([2, 865, 151936]), dtype: torch.float32
[Step 1941] Student model device: cuda:1
[Step 1941] GPU 0 memory before teacher forward: 16.39 GB
[Step 1941] GPU 0 memory after moving inputs: 16.39 GB
[Step 1941] GPU 0 memory after teacher forward: 16.92 GB
[Step 1941] Teacher logits shape: torch.Size([2, 865, 151936]), dtype: torch.float16
[Step 1941] Teacher logits device before move: cuda:0
[Step 1941] Target device (student_logits.device): cuda:1
[Step 1941] GPU 0 memory after moving logits to GPU 1: 16.92 GB
[Step 1941] Teacher logits device after move: cuda:1, shape: torch.Size([2, 865, 151936])
[Step 1941] GPU 0 memory after del: 16.39 GB
[Step 1941] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1941] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.45 GB
[Step 1941] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1941] Sequence length: 865, Batch size: 2
[Step 1941] After KL computation - GPU 1: 39.55 GB
[Step 1941] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1951] ========== MEMORY DEBUG ==========
[Step 1951] Model device: cuda:1
[Step 1951] Input device: cuda:1
[Step 1951] Teacher model device: cuda:0
[Step 1951] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1951] GPU 1 memory: 33.76 GB (reserved: 47.44 GB)
[Step 1951] Student logits device: cuda:1, shape: torch.Size([2, 476, 151936]), dtype: torch.float32
[Step 1951] Student model device: cuda:1
[Step 1951] GPU 0 memory before teacher forward: 16.39 GB
[Step 1951] GPU 0 memory after moving inputs: 16.39 GB
[Step 1951] GPU 0 memory after teacher forward: 16.68 GB
[Step 1951] Teacher logits shape: torch.Size([2, 476, 151936]), dtype: torch.float16
[Step 1951] Teacher logits device before move: cuda:0
[Step 1951] Target device (student_logits.device): cuda:1
[Step 1951] GPU 0 memory after moving logits to GPU 1: 16.68 GB
[Step 1951] Teacher logits device after move: cuda:1, shape: torch.Size([2, 476, 151936])
[Step 1951] GPU 0 memory after del: 16.39 GB
[Step 1951] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1951] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.07 GB
[Step 1951] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1951] Sequence length: 476, Batch size: 2
[Step 1951] After KL computation - GPU 1: 37.23 GB
[Step 1951] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1961] ========== MEMORY DEBUG ==========
[Step 1961] Model device: cuda:1
[Step 1961] Input device: cuda:1
[Step 1961] Teacher model device: cuda:0
[Step 1961] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1961] GPU 1 memory: 33.76 GB (reserved: 46.35 GB)
[Step 1961] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1961] Student model device: cuda:1
[Step 1961] GPU 0 memory before teacher forward: 16.39 GB
[Step 1961] GPU 0 memory after moving inputs: 16.39 GB
[Step 1961] GPU 0 memory after teacher forward: 17.01 GB
[Step 1961] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1961] Teacher logits device before move: cuda:0
[Step 1961] Target device (student_logits.device): cuda:1
[Step 1961] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1961] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1961] GPU 0 memory after del: 16.39 GB
[Step 1961] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1961] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1961] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1961] Sequence length: 1024, Batch size: 2
[Step 1961] After KL computation - GPU 1: 40.50 GB
[Step 1961] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1971] ========== MEMORY DEBUG ==========
[Step 1971] Model device: cuda:1
[Step 1971] Input device: cuda:1
[Step 1971] Teacher model device: cuda:0
[Step 1971] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1971] GPU 1 memory: 33.76 GB (reserved: 47.52 GB)
[Step 1971] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1971] Student model device: cuda:1
[Step 1971] GPU 0 memory before teacher forward: 16.39 GB
[Step 1971] GPU 0 memory after moving inputs: 16.39 GB
[Step 1971] GPU 0 memory after teacher forward: 17.01 GB
[Step 1971] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1971] Teacher logits device before move: cuda:0
[Step 1971] Target device (student_logits.device): cuda:1
[Step 1971] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1971] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1971] GPU 0 memory after del: 16.39 GB
[Step 1971] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1971] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1971] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1971] Sequence length: 1024, Batch size: 2
[Step 1971] After KL computation - GPU 1: 40.50 GB
[Step 1971] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1981] ========== MEMORY DEBUG ==========
[Step 1981] Model device: cuda:1
[Step 1981] Input device: cuda:1
[Step 1981] Teacher model device: cuda:0
[Step 1981] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1981] GPU 1 memory: 33.76 GB (reserved: 48.08 GB)
[Step 1981] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 1981] Student model device: cuda:1
[Step 1981] GPU 0 memory before teacher forward: 16.39 GB
[Step 1981] GPU 0 memory after moving inputs: 16.39 GB
[Step 1981] GPU 0 memory after teacher forward: 17.01 GB
[Step 1981] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 1981] Teacher logits device before move: cuda:0
[Step 1981] Target device (student_logits.device): cuda:1
[Step 1981] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 1981] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 1981] GPU 0 memory after del: 16.39 GB
[Step 1981] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1981] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 1981] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1981] Sequence length: 1024, Batch size: 2
[Step 1981] After KL computation - GPU 1: 40.50 GB
[Step 1981] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 1991] ========== MEMORY DEBUG ==========
[Step 1991] Model device: cuda:1
[Step 1991] Input device: cuda:1
[Step 1991] Teacher model device: cuda:0
[Step 1991] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 1991] GPU 1 memory: 33.76 GB (reserved: 47.83 GB)
[Step 1991] Student logits device: cuda:1, shape: torch.Size([2, 566, 151936]), dtype: torch.float32
[Step 1991] Student model device: cuda:1
[Step 1991] GPU 0 memory before teacher forward: 16.39 GB
[Step 1991] GPU 0 memory after moving inputs: 16.39 GB
[Step 1991] GPU 0 memory after teacher forward: 16.74 GB
[Step 1991] Teacher logits shape: torch.Size([2, 566, 151936]), dtype: torch.float16
[Step 1991] Teacher logits device before move: cuda:0
[Step 1991] Target device (student_logits.device): cuda:1
[Step 1991] GPU 0 memory after moving logits to GPU 1: 16.74 GB
[Step 1991] Teacher logits device after move: cuda:1, shape: torch.Size([2, 566, 151936])
[Step 1991] GPU 0 memory after del: 16.39 GB
[Step 1991] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 1991] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 36.39 GB
[Step 1991] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 1991] Sequence length: 566, Batch size: 2
[Step 1991] After KL computation - GPU 1: 37.77 GB
[Step 1991] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 2001] ========== MEMORY DEBUG ==========
[Step 2001] Model device: cuda:1
[Step 2001] Input device: cuda:1
[Step 2001] Teacher model device: cuda:0
[Step 2001] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 2001] GPU 1 memory: 25.33 GB (reserved: 47.73 GB)
[Step 2001] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 2001] Student model device: cuda:1
[Step 2001] GPU 0 memory before teacher forward: 16.39 GB
[Step 2001] GPU 0 memory after moving inputs: 16.39 GB
[Step 2001] GPU 0 memory after teacher forward: 17.01 GB
[Step 2001] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 2001] Teacher logits device before move: cuda:0
[Step 2001] Target device (student_logits.device): cuda:1
[Step 2001] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 2001] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 2001] GPU 0 memory after del: 16.39 GB
[Step 2001] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 2001] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 29.58 GB
[Step 2001] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 2001] Sequence length: 1024, Batch size: 2
[Step 2001] After KL computation - GPU 1: 32.07 GB
[Step 2001] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 2011] ========== MEMORY DEBUG ==========
[Step 2011] Model device: cuda:1
[Step 2011] Input device: cuda:1
[Step 2011] Teacher model device: cuda:0
[Step 2011] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 2011] GPU 1 memory: 33.76 GB (reserved: 47.42 GB)
[Step 2011] Student logits device: cuda:1, shape: torch.Size([2, 970, 151936]), dtype: torch.float32
[Step 2011] Student model device: cuda:1
[Step 2011] GPU 0 memory before teacher forward: 16.39 GB
[Step 2011] GPU 0 memory after moving inputs: 16.39 GB
[Step 2011] GPU 0 memory after teacher forward: 16.98 GB
[Step 2011] Teacher logits shape: torch.Size([2, 970, 151936]), dtype: torch.float16
[Step 2011] Teacher logits device before move: cuda:0
[Step 2011] Target device (student_logits.device): cuda:1
[Step 2011] GPU 0 memory after moving logits to GPU 1: 16.98 GB
[Step 2011] Teacher logits device after move: cuda:1, shape: torch.Size([2, 970, 151936])
[Step 2011] GPU 0 memory after del: 16.39 GB
[Step 2011] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 2011] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 37.82 GB
[Step 2011] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 2011] Sequence length: 970, Batch size: 2
[Step 2011] After KL computation - GPU 1: 40.18 GB
[Step 2011] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1

[Step 2021] ========== MEMORY DEBUG ==========
[Step 2021] Model device: cuda:1
[Step 2021] Input device: cuda:1
[Step 2021] Teacher model device: cuda:0
[Step 2021] GPU 0 memory: 16.39 GB (reserved: 16.56 GB)
[Step 2021] GPU 1 memory: 33.76 GB (reserved: 47.52 GB)
[Step 2021] Student logits device: cuda:1, shape: torch.Size([2, 1024, 151936]), dtype: torch.float32
[Step 2021] Student model device: cuda:1
[Step 2021] GPU 0 memory before teacher forward: 16.39 GB
[Step 2021] GPU 0 memory after moving inputs: 16.39 GB
[Step 2021] GPU 0 memory after teacher forward: 17.01 GB
[Step 2021] Teacher logits shape: torch.Size([2, 1024, 151936]), dtype: torch.float16
[Step 2021] Teacher logits device before move: cuda:0
[Step 2021] Target device (student_logits.device): cuda:1
[Step 2021] GPU 0 memory after moving logits to GPU 1: 17.01 GB
[Step 2021] Teacher logits device after move: cuda:1, shape: torch.Size([2, 1024, 151936])
[Step 2021] GPU 0 memory after del: 16.39 GB
[Step 2021] GPU 0 memory after cache clear: 16.39 GB (reserved: 16.56 GB)
[Step 2021] Before log_softmax - GPU 0: 16.39 GB, GPU 1: 38.01 GB
[Step 2021] student_logits device: cuda:1, teacher_logits device: cuda:1
[Step 2021] Sequence length: 1024, Batch size: 2
[Step 2021] After KL computation - GPU 1: 40.50 GB
[Step 2021] Loss device: cuda:0, args.device: cuda:0, model device: cuda:1
  File "/workspace/compute-aware-arch-search/distill_videet.py", line 410, in <module>
    trainer.train()
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/distill_videet.py", line 127, in compute_loss
    teacher_outputs = self.teacher_model(
                      ^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 1064, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 410, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 260, in forward
    hidden_states, _ = self.self_attn(
                       ^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 200, in forward
    query_states = self.q_norm(self.q_proj(hidden_states).view(hidden_shape)).transpose(1, 2)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 63, in forward
    hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
