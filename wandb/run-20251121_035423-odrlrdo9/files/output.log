`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.21it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████| 27838/27838 [00:00<00:00, 28642.48it/s]

===== Training layer 1/28 =====
/workspace/compute-aware-arch-search/train.py:186: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
                                                                                                                         
{'loss': 0.0963, 'grad_norm': 0.1552734375, 'learning_rate': 1.1811023622047244e-06, 'epoch': 0.0}
{'loss': 0.0951, 'grad_norm': 0.154296875, 'learning_rate': 2.4934383202099738e-06, 'epoch': 0.0}
{'loss': 0.0952, 'grad_norm': 0.1435546875, 'learning_rate': 3.805774278215223e-06, 'epoch': 0.0}
{'loss': 0.0939, 'grad_norm': 0.142578125, 'learning_rate': 5.118110236220473e-06, 'epoch': 0.01}
{'loss': 0.093, 'grad_norm': 0.1318359375, 'learning_rate': 6.430446194225722e-06, 'epoch': 0.01}
{'loss': 0.088, 'grad_norm': 0.12353515625, 'learning_rate': 7.742782152230973e-06, 'epoch': 0.01}
{'loss': 0.0828, 'grad_norm': 0.11572265625, 'learning_rate': 9.055118110236222e-06, 'epoch': 0.01}
{'loss': 0.0774, 'grad_norm': 0.10400390625, 'learning_rate': 1.0367454068241471e-05, 'epoch': 0.01}
{'loss': 0.0701, 'grad_norm': 0.09423828125, 'learning_rate': 1.167979002624672e-05, 'epoch': 0.01}
{'loss': 0.0625, 'grad_norm': 0.08642578125, 'learning_rate': 1.2992125984251968e-05, 'epoch': 0.01}
{'loss': 0.0568, 'grad_norm': 0.06298828125, 'learning_rate': 1.430446194225722e-05, 'epoch': 0.01}
{'loss': 0.0521, 'grad_norm': 0.04052734375, 'learning_rate': 1.5616797900262467e-05, 'epoch': 0.02}
{'loss': 0.047, 'grad_norm': 0.0260009765625, 'learning_rate': 1.692913385826772e-05, 'epoch': 0.02}
{'loss': 0.0475, 'grad_norm': 0.107421875, 'learning_rate': 1.8241469816272966e-05, 'epoch': 0.02}
{'loss': 0.0471, 'grad_norm': 0.0189208984375, 'learning_rate': 1.9553805774278217e-05, 'epoch': 0.02}
{'loss': 0.0435, 'grad_norm': 0.016845703125, 'learning_rate': 2.0866141732283465e-05, 'epoch': 0.02}
{'loss': 0.0474, 'grad_norm': 0.0162353515625, 'learning_rate': 2.2178477690288716e-05, 'epoch': 0.02}
{'loss': 0.0452, 'grad_norm': 0.01556396484375, 'learning_rate': 2.3490813648293964e-05, 'epoch': 0.02}
{'loss': 0.0466, 'grad_norm': 0.01513671875, 'learning_rate': 2.4803149606299215e-05, 'epoch': 0.02}
{'loss': 0.0441, 'grad_norm': 0.0177001953125, 'learning_rate': 2.6115485564304466e-05, 'epoch': 0.03}
{'loss': 0.046, 'grad_norm': 0.0167236328125, 'learning_rate': 2.742782152230971e-05, 'epoch': 0.03}
{'loss': 0.0442, 'grad_norm': 804.0, 'learning_rate': 2.874015748031496e-05, 'epoch': 0.03}
{'loss': 0.0463, 'grad_norm': 0.0203857421875, 'learning_rate': 3.0052493438320212e-05, 'epoch': 0.03}
{'loss': 0.0454, 'grad_norm': 0.015380859375, 'learning_rate': 3.136482939632546e-05, 'epoch': 0.03}
{'loss': 0.0437, 'grad_norm': 0.017333984375, 'learning_rate': 3.2677165354330704e-05, 'epoch': 0.03}
{'loss': 0.0429, 'grad_norm': 0.0152587890625, 'learning_rate': 3.398950131233596e-05, 'epoch': 0.03}
{'loss': 0.0427, 'grad_norm': 0.0164794921875, 'learning_rate': 3.5301837270341206e-05, 'epoch': 0.04}
{'loss': 0.0437, 'grad_norm': 0.0169677734375, 'learning_rate': 3.661417322834646e-05, 'epoch': 0.04}
{'loss': 0.0442, 'grad_norm': 0.01556396484375, 'learning_rate': 3.79265091863517e-05, 'epoch': 0.04}
{'loss': 0.0421, 'grad_norm': 0.0167236328125, 'learning_rate': 3.9238845144356956e-05, 'epoch': 0.04}
{'loss': 0.0422, 'grad_norm': 0.0224609375, 'learning_rate': 4.0551181102362204e-05, 'epoch': 0.04}
{'loss': 0.0436, 'grad_norm': 0.01611328125, 'learning_rate': 4.186351706036746e-05, 'epoch': 0.04}
{'loss': 0.0409, 'grad_norm': 0.0220947265625, 'learning_rate': 4.31758530183727e-05, 'epoch': 0.04}
{'loss': 0.0402, 'grad_norm': 0.017578125, 'learning_rate': 4.4488188976377954e-05, 'epoch': 0.04}
{'loss': 0.0405, 'grad_norm': 0.019287109375, 'learning_rate': 4.58005249343832e-05, 'epoch': 0.05}
{'loss': 0.0417, 'grad_norm': 0.0179443359375, 'learning_rate': 4.7112860892388456e-05, 'epoch': 0.05}
{'loss': 0.0375, 'grad_norm': 0.017822265625, 'learning_rate': 4.84251968503937e-05, 'epoch': 0.05}
{'loss': 0.0378, 'grad_norm': 0.0177001953125, 'learning_rate': 4.973753280839895e-05, 'epoch': 0.05}
{'loss': 0.0389, 'grad_norm': 0.017822265625, 'learning_rate': 5.1049868766404206e-05, 'epoch': 0.05}
{'loss': 0.0369, 'grad_norm': 0.0184326171875, 'learning_rate': 5.236220472440945e-05, 'epoch': 0.05}
{'loss': 0.0376, 'grad_norm': 0.0186767578125, 'learning_rate': 5.3674540682414695e-05, 'epoch': 0.05}
{'loss': 0.0387, 'grad_norm': 0.0186767578125, 'learning_rate': 5.498687664041995e-05, 'epoch': 0.06}
{'loss': 0.0397, 'grad_norm': 0.01904296875, 'learning_rate': 5.62992125984252e-05, 'epoch': 0.06}
{'loss': 0.0372, 'grad_norm': 0.025634765625, 'learning_rate': 5.761154855643045e-05, 'epoch': 0.06}
{'loss': 0.0374, 'grad_norm': 0.020751953125, 'learning_rate': 5.89238845144357e-05, 'epoch': 0.06}
{'loss': 0.0369, 'grad_norm': 0.0240478515625, 'learning_rate': 6.0236220472440953e-05, 'epoch': 0.06}
{'loss': 0.0363, 'grad_norm': 0.0220947265625, 'learning_rate': 6.154855643044621e-05, 'epoch': 0.06}
{'loss': 0.0354, 'grad_norm': 0.021240234375, 'learning_rate': 6.286089238845144e-05, 'epoch': 0.06}
{'loss': 0.0366, 'grad_norm': 0.0198974609375, 'learning_rate': 6.417322834645669e-05, 'epoch': 0.06}
{'loss': 0.0352, 'grad_norm': 0.0206298828125, 'learning_rate': 6.548556430446194e-05, 'epoch': 0.07}
{'loss': 0.0335, 'grad_norm': 0.0201416015625, 'learning_rate': 6.67979002624672e-05, 'epoch': 0.07}
{'loss': 0.0351, 'grad_norm': 0.0198974609375, 'learning_rate': 6.811023622047245e-05, 'epoch': 0.07}
{'loss': 0.0343, 'grad_norm': 0.0238037109375, 'learning_rate': 6.94225721784777e-05, 'epoch': 0.07}
{'loss': 0.0344, 'grad_norm': 0.023193359375, 'learning_rate': 7.073490813648294e-05, 'epoch': 0.07}
{'loss': 0.0342, 'grad_norm': 0.020751953125, 'learning_rate': 7.20472440944882e-05, 'epoch': 0.07}
{'loss': 0.0346, 'grad_norm': 0.0213623046875, 'learning_rate': 7.335958005249344e-05, 'epoch': 0.07}
{'loss': 0.0343, 'grad_norm': 0.0264892578125, 'learning_rate': 7.467191601049868e-05, 'epoch': 0.07}
{'loss': 0.0345, 'grad_norm': 0.026611328125, 'learning_rate': 7.598425196850393e-05, 'epoch': 0.08}
{'loss': 0.0338, 'grad_norm': 0.026611328125, 'learning_rate': 7.72965879265092e-05, 'epoch': 0.08}
{'loss': 0.0324, 'grad_norm': 0.0238037109375, 'learning_rate': 7.860892388451444e-05, 'epoch': 0.08}
{'loss': 0.0324, 'grad_norm': 0.0301513671875, 'learning_rate': 7.992125984251969e-05, 'epoch': 0.08}
