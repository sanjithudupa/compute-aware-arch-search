Set CUDA current device to: 1 (should be 1)
/workspace/compute-aware-arch-search/distill_videet.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
After Trainer init: Student model on cuda:1, expected cuda:1
Student model gradient check: 349/349 parameter tensors have gradients enabled
Student model size: 2,108,486,272/2,108,486,272 scalar parameters (2108.49M/2108.49M) have gradients enabled
Final check - Student model device: cuda:1
Final check - Trainer args.device: cuda:0 (read-only property)
Final check - CUDA current device: 1
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  0%|                                                                                                                                                          | 0/10000 [00:00<?, ?it/s]/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None

[Step 1] ========== DEBUG INFO ==========
[Step 1] Labels shape: torch.Size([8, 837]), dtype: torch.int64
[Step 1] Labels min: -100, max: 97586, has_nan: False
[Step 1] input_ids shape: torch.Size([8, 837]), dtype: torch.int64, device: cuda:1
[Step 1] attention_mask shape: torch.Size([8, 837]), dtype: torch.int64, device: cuda:1
  warnings.warn(
/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[Step 1] Student logits shape: torch.Size([8, 837, 151936]), dtype: torch.float32, device: cuda:1
[Step 1] Student logits min: nan, max: nan
[Step 1] Student logits has_nan: True, has_inf: False
[Step 1] Teacher logits shape: torch.Size([8, 837, 151936]), dtype: torch.float16, device: cuda:1
[Step 1] Teacher logits min: -29.3438, max: 56.9688
[Step 1] Teacher logits has_nan: False, has_inf: False
[Step 1] CE loss: nan, has_nan: True, has_inf: False
[Step 1] Mask shape: torch.Size([8, 837, 1]), valid tokens: 3175/6696
[Step 1] Student log_probs shape: torch.Size([8, 837, 151936]), min: nan, max: nan
[Step 1] Student log_probs has_nan: True, has_inf: False
[Step 1] Teacher probs shape: torch.Size([8, 837, 151936]), min: 0.0000, max: 0.9810
[Step 1] Teacher probs has_nan: False, has_inf: False
[Step 1] Teacher probs sum check (should be ~1.0): min_sum: 1.0000, max_sum: 1.0000
[Step 1] KL loss (before mask) shape: torch.Size([8, 837]), min: nan, max: nan
[Step 1] KL loss (before mask) has_nan: True, has_inf: False
[Step 1] KL loss (after mask): nan, has_nan: True, has_inf: False
[Step 1] Temperature: 4.0, alpha: 0.5
[Step 1] Final loss: nan, has_nan: True, has_inf: False
[Step 1] ====================================
Traceback (most recent call last):
  File "/workspace/compute-aware-arch-search/distill_videet.py", line 397, in <module>
    streaming=True,
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 4071, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/accelerate/accelerator.py", line 2736, in backward
    self.scaler.scale(loss).backward(**kwargs)
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/workspace/compute-aware-arch-search/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
